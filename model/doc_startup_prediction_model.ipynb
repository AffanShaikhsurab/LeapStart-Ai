{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWUDrHFhmapD",
        "outputId": "50e1d34e-62c4-4e53-b5ba-401ef1ef689d"
      },
      "outputs": [],
      "source": [
        "# pip install pandas numpy scikit-learn tensorflow joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import joblib\n",
        "import os\n",
        "from tensorflow.keras import regularizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIKmMxcOmKP1",
        "outputId": "a7c1854c-a186-40d4-f82e-7f7bc6ab8ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The transformed input-values are:\n",
            "\n",
            " [[ 0.08915953 -0.18514222 -1.91104785 ... -0.69005976 -1.03768249\n",
            "  -1.63025802]\n",
            " [ 1.41067941 -0.20808567  0.63247597 ...  0.05830927  1.17438633\n",
            "   0.75892076]\n",
            " [-0.57160041 -0.19933445 -2.02163584 ... -1.30314011 -0.5881773\n",
            "  -1.07881043]\n",
            " ...\n",
            " [-0.57160041 -0.17726573 -2.39026248 ... -0.69005976  0.60707189\n",
            "   0.11642018]\n",
            " [-1.23236035 -0.19523734 -1.35810788 ...  1.7348614   1.04971441\n",
            "   1.02310263]\n",
            " [-1.56274032 -0.20677441 -1.24751989 ...  1.03101776  0.14841646\n",
            "   0.5870743 ]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model mlp_financial for niche 5...\n",
            "Epoch 1/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5563 - loss: 0.7568 - val_accuracy: 0.8455 - val_loss: 0.5754\n",
            "Epoch 2/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7177 - loss: 0.6197 - val_accuracy: 0.8498 - val_loss: 0.4921\n",
            "Epoch 3/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.5472 - val_accuracy: 0.8541 - val_loss: 0.4516\n",
            "Epoch 4/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.5051 - val_accuracy: 0.8541 - val_loss: 0.4329\n",
            "Epoch 5/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.5430 - val_accuracy: 0.8541 - val_loss: 0.4230\n",
            "Epoch 6/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.5225 - val_accuracy: 0.8541 - val_loss: 0.4187\n",
            "Epoch 7/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8310 - loss: 0.4837 - val_accuracy: 0.8541 - val_loss: 0.4145\n",
            "Epoch 8/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.4753 - val_accuracy: 0.8541 - val_loss: 0.4094\n",
            "Epoch 9/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7768 - loss: 0.5087 - val_accuracy: 0.8541 - val_loss: 0.4066\n",
            "Epoch 10/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.5097 - val_accuracy: 0.8541 - val_loss: 0.4044\n",
            "Epoch 11/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.5021 - val_accuracy: 0.8541 - val_loss: 0.4022\n",
            "Epoch 12/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8128 - loss: 0.4815 - val_accuracy: 0.8541 - val_loss: 0.4008\n",
            "Epoch 13/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8246 - loss: 0.4901 - val_accuracy: 0.8541 - val_loss: 0.3990\n",
            "Epoch 14/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.4950 - val_accuracy: 0.8541 - val_loss: 0.3984\n",
            "Epoch 15/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.4810 - val_accuracy: 0.8541 - val_loss: 0.3978\n",
            "Epoch 16/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.4225 - val_accuracy: 0.8541 - val_loss: 0.3963\n",
            "Epoch 17/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8119 - loss: 0.4655 - val_accuracy: 0.8541 - val_loss: 0.3953\n",
            "Epoch 18/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4736 - val_accuracy: 0.8541 - val_loss: 0.3953\n",
            "Epoch 19/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4422 - val_accuracy: 0.8541 - val_loss: 0.3949\n",
            "Epoch 20/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 0.4495 - val_accuracy: 0.8541 - val_loss: 0.3946\n",
            "Epoch 21/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.4730 - val_accuracy: 0.8541 - val_loss: 0.3941\n",
            "Epoch 22/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.4290 - val_accuracy: 0.8541 - val_loss: 0.3939\n",
            "Epoch 23/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8374 - loss: 0.4240 - val_accuracy: 0.8541 - val_loss: 0.3932\n",
            "Epoch 24/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.4244 - val_accuracy: 0.8541 - val_loss: 0.3926\n",
            "Epoch 25/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8248 - loss: 0.4609 - val_accuracy: 0.8541 - val_loss: 0.3925\n",
            "Epoch 26/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4269 - val_accuracy: 0.8541 - val_loss: 0.3929\n",
            "Epoch 27/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.4279 - val_accuracy: 0.8541 - val_loss: 0.3918\n",
            "Epoch 28/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.4267 - val_accuracy: 0.8541 - val_loss: 0.3908\n",
            "Epoch 29/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8186 - loss: 0.4412 - val_accuracy: 0.8541 - val_loss: 0.3900\n",
            "Epoch 30/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.4560 - val_accuracy: 0.8541 - val_loss: 0.3896\n",
            "Epoch 31/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.4192 - val_accuracy: 0.8541 - val_loss: 0.3895\n",
            "Epoch 32/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.4455 - val_accuracy: 0.8541 - val_loss: 0.3891\n",
            "Epoch 33/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8230 - loss: 0.4321 - val_accuracy: 0.8541 - val_loss: 0.3894\n",
            "Epoch 34/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 0.4337 - val_accuracy: 0.8541 - val_loss: 0.3888\n",
            "Epoch 35/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8171 - loss: 0.4410 - val_accuracy: 0.8541 - val_loss: 0.3892\n",
            "Epoch 36/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.4152 - val_accuracy: 0.8541 - val_loss: 0.3887\n",
            "Epoch 37/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.4260 - val_accuracy: 0.8541 - val_loss: 0.3876\n",
            "Epoch 38/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.4166 - val_accuracy: 0.8541 - val_loss: 0.3866\n",
            "Epoch 39/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 0.4149 - val_accuracy: 0.8541 - val_loss: 0.3859\n",
            "Epoch 40/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.4388 - val_accuracy: 0.8541 - val_loss: 0.3864\n",
            "Epoch 41/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4264 - val_accuracy: 0.8541 - val_loss: 0.3863\n",
            "Epoch 42/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.4506 - val_accuracy: 0.8541 - val_loss: 0.3854\n",
            "Epoch 43/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.4031 - val_accuracy: 0.8541 - val_loss: 0.3850\n",
            "Epoch 44/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.4449 - val_accuracy: 0.8541 - val_loss: 0.3851\n",
            "Epoch 45/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4261 - val_accuracy: 0.8541 - val_loss: 0.3851\n",
            "Epoch 46/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4103 - val_accuracy: 0.8541 - val_loss: 0.3844\n",
            "Epoch 47/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.4202 - val_accuracy: 0.8541 - val_loss: 0.3845\n",
            "Epoch 48/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.4451 - val_accuracy: 0.8541 - val_loss: 0.3841\n",
            "Epoch 49/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.4588 - val_accuracy: 0.8541 - val_loss: 0.3841\n",
            "Epoch 50/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.4167 - val_accuracy: 0.8541 - val_loss: 0.3843\n",
            "Epoch 51/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.4000 - val_accuracy: 0.8541 - val_loss: 0.3847\n",
            "Epoch 52/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.4103 - val_accuracy: 0.8541 - val_loss: 0.3846\n",
            "Epoch 53/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.4002 - val_accuracy: 0.8541 - val_loss: 0.3837\n",
            "Epoch 54/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7937 - loss: 0.4863 - val_accuracy: 0.8541 - val_loss: 0.3833\n",
            "Epoch 55/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.3854 - val_accuracy: 0.8541 - val_loss: 0.3831\n",
            "Epoch 56/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3934 - val_accuracy: 0.8541 - val_loss: 0.3824\n",
            "Epoch 57/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8526 - loss: 0.3878 - val_accuracy: 0.8541 - val_loss: 0.3816\n",
            "Epoch 58/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.4176 - val_accuracy: 0.8541 - val_loss: 0.3821\n",
            "Epoch 59/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8135 - loss: 0.4383 - val_accuracy: 0.8541 - val_loss: 0.3814\n",
            "Epoch 60/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8407 - loss: 0.4059 - val_accuracy: 0.8541 - val_loss: 0.3815\n",
            "Epoch 61/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4206 - val_accuracy: 0.8541 - val_loss: 0.3817\n",
            "Epoch 62/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.4048 - val_accuracy: 0.8541 - val_loss: 0.3825\n",
            "Epoch 63/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4062 - val_accuracy: 0.8541 - val_loss: 0.3833\n",
            "Epoch 64/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.4117 - val_accuracy: 0.8541 - val_loss: 0.3824\n",
            "Epoch 65/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.4041 - val_accuracy: 0.8541 - val_loss: 0.3844\n",
            "Epoch 66/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4387 - val_accuracy: 0.8541 - val_loss: 0.3826\n",
            "Epoch 67/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4633 - val_accuracy: 0.8541 - val_loss: 0.3823\n",
            "Epoch 68/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8267 - loss: 0.4112 - val_accuracy: 0.8541 - val_loss: 0.3821\n",
            "Epoch 69/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.4315 - val_accuracy: 0.8541 - val_loss: 0.3814\n",
            "Epoch 70/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.3973 - val_accuracy: 0.8541 - val_loss: 0.3812\n",
            "Epoch 71/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3957 - val_accuracy: 0.8541 - val_loss: 0.3810\n",
            "Epoch 72/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.4013 - val_accuracy: 0.8541 - val_loss: 0.3811\n",
            "Epoch 73/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4258 - val_accuracy: 0.8541 - val_loss: 0.3812\n",
            "Epoch 74/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.4358 - val_accuracy: 0.8541 - val_loss: 0.3798\n",
            "Epoch 75/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.4393 - val_accuracy: 0.8541 - val_loss: 0.3797\n",
            "Epoch 76/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.4073 - val_accuracy: 0.8541 - val_loss: 0.3805\n",
            "Epoch 77/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.4279 - val_accuracy: 0.8541 - val_loss: 0.3805\n",
            "Epoch 78/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4236 - val_accuracy: 0.8541 - val_loss: 0.3805\n",
            "Epoch 79/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.3883 - val_accuracy: 0.8541 - val_loss: 0.3802\n",
            "Epoch 80/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8175 - loss: 0.4249 - val_accuracy: 0.8541 - val_loss: 0.3802\n",
            "Epoch 81/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.4088 - val_accuracy: 0.8541 - val_loss: 0.3791\n",
            "Epoch 82/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4051 - val_accuracy: 0.8541 - val_loss: 0.3799\n",
            "Epoch 83/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3889 - val_accuracy: 0.8541 - val_loss: 0.3788\n",
            "Epoch 84/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.4191 - val_accuracy: 0.8541 - val_loss: 0.3777\n",
            "Epoch 85/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.3772 - val_accuracy: 0.8541 - val_loss: 0.3790\n",
            "Epoch 86/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3808 - val_accuracy: 0.8541 - val_loss: 0.3789\n",
            "Epoch 87/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.4014 - val_accuracy: 0.8541 - val_loss: 0.3785\n",
            "Epoch 88/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.4124 - val_accuracy: 0.8541 - val_loss: 0.3780\n",
            "Epoch 89/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.4025 - val_accuracy: 0.8541 - val_loss: 0.3780\n",
            "Epoch 90/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4055 - val_accuracy: 0.8541 - val_loss: 0.3789\n",
            "Epoch 91/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.4279 - val_accuracy: 0.8541 - val_loss: 0.3781\n",
            "Epoch 92/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4261 - val_accuracy: 0.8541 - val_loss: 0.3791\n",
            "Epoch 93/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8292 - loss: 0.3843 - val_accuracy: 0.8541 - val_loss: 0.3783\n",
            "Epoch 94/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4048 - val_accuracy: 0.8541 - val_loss: 0.3780\n",
            "Model mlp_financial training complete for niche 5.\n",
            "  Final training loss: 0.4069707691669464\n",
            "  Final validation loss: 0.37800833582878113\n",
            "  Final training accuracy: 0.8225806355476379\n",
            "  Final validation accuracy: 0.8540772795677185\n",
            "Training model mlp_market for niche 5...\n",
            "Epoch 1/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5131 - loss: 0.7962 - val_accuracy: 0.8112 - val_loss: 0.6016\n",
            "Epoch 2/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6795 - loss: 0.6608 - val_accuracy: 0.8541 - val_loss: 0.5173\n",
            "Epoch 3/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7535 - loss: 0.6018 - val_accuracy: 0.8541 - val_loss: 0.4727\n",
            "Epoch 4/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7569 - loss: 0.5693 - val_accuracy: 0.8541 - val_loss: 0.4486\n",
            "Epoch 5/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.5134 - val_accuracy: 0.8541 - val_loss: 0.4314\n",
            "Epoch 6/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.5157 - val_accuracy: 0.8541 - val_loss: 0.4199\n",
            "Epoch 7/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.4980 - val_accuracy: 0.8541 - val_loss: 0.4127\n",
            "Epoch 8/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.4975 - val_accuracy: 0.8541 - val_loss: 0.4061\n",
            "Epoch 9/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.4792 - val_accuracy: 0.8541 - val_loss: 0.4008\n",
            "Epoch 10/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.4637 - val_accuracy: 0.8541 - val_loss: 0.3978\n",
            "Epoch 11/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8211 - loss: 0.4594 - val_accuracy: 0.8541 - val_loss: 0.3961\n",
            "Epoch 12/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.4587 - val_accuracy: 0.8541 - val_loss: 0.3943\n",
            "Epoch 13/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8224 - loss: 0.4553 - val_accuracy: 0.8541 - val_loss: 0.3931\n",
            "Epoch 14/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.4414 - val_accuracy: 0.8541 - val_loss: 0.3925\n",
            "Epoch 15/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.4529 - val_accuracy: 0.8541 - val_loss: 0.3914\n",
            "Epoch 16/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8112 - loss: 0.4778 - val_accuracy: 0.8541 - val_loss: 0.3903\n",
            "Epoch 17/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.4652 - val_accuracy: 0.8541 - val_loss: 0.3891\n",
            "Epoch 18/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.4518 - val_accuracy: 0.8541 - val_loss: 0.3883\n",
            "Epoch 19/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.4377 - val_accuracy: 0.8541 - val_loss: 0.3879\n",
            "Epoch 20/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.4487 - val_accuracy: 0.8541 - val_loss: 0.3872\n",
            "Epoch 21/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4462 - val_accuracy: 0.8541 - val_loss: 0.3866\n",
            "Epoch 22/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8379 - loss: 0.4273 - val_accuracy: 0.8541 - val_loss: 0.3861\n",
            "Epoch 23/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 0.4391 - val_accuracy: 0.8541 - val_loss: 0.3853\n",
            "Epoch 24/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.4554 - val_accuracy: 0.8541 - val_loss: 0.3845\n",
            "Epoch 25/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 0.4418 - val_accuracy: 0.8541 - val_loss: 0.3838\n",
            "Epoch 26/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8305 - loss: 0.4442 - val_accuracy: 0.8541 - val_loss: 0.3837\n",
            "Epoch 27/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.4582 - val_accuracy: 0.8541 - val_loss: 0.3835\n",
            "Epoch 28/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4743 - val_accuracy: 0.8541 - val_loss: 0.3826\n",
            "Epoch 29/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8340 - loss: 0.4155 - val_accuracy: 0.8541 - val_loss: 0.3821\n",
            "Epoch 30/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8394 - loss: 0.4241 - val_accuracy: 0.8541 - val_loss: 0.3815\n",
            "Epoch 31/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8342 - loss: 0.4133 - val_accuracy: 0.8541 - val_loss: 0.3812\n",
            "Epoch 32/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.4533 - val_accuracy: 0.8541 - val_loss: 0.3809\n",
            "Epoch 33/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.4661 - val_accuracy: 0.8541 - val_loss: 0.3807\n",
            "Epoch 34/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.4291 - val_accuracy: 0.8541 - val_loss: 0.3803\n",
            "Epoch 35/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8180 - loss: 0.4361 - val_accuracy: 0.8541 - val_loss: 0.3802\n",
            "Epoch 36/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8179 - loss: 0.4363 - val_accuracy: 0.8541 - val_loss: 0.3802\n",
            "Epoch 37/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 0.4079 - val_accuracy: 0.8541 - val_loss: 0.3798\n",
            "Epoch 38/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8186 - loss: 0.4600 - val_accuracy: 0.8541 - val_loss: 0.3793\n",
            "Epoch 39/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.4247 - val_accuracy: 0.8541 - val_loss: 0.3793\n",
            "Epoch 40/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4530 - val_accuracy: 0.8541 - val_loss: 0.3785\n",
            "Epoch 41/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 0.4028 - val_accuracy: 0.8541 - val_loss: 0.3779\n",
            "Epoch 42/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.4455 - val_accuracy: 0.8541 - val_loss: 0.3770\n",
            "Epoch 43/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8234 - loss: 0.4323 - val_accuracy: 0.8541 - val_loss: 0.3768\n",
            "Epoch 44/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.4090 - val_accuracy: 0.8541 - val_loss: 0.3767\n",
            "Epoch 45/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8229 - loss: 0.4156 - val_accuracy: 0.8541 - val_loss: 0.3766\n",
            "Epoch 46/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4578 - val_accuracy: 0.8541 - val_loss: 0.3763\n",
            "Epoch 47/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.4276 - val_accuracy: 0.8541 - val_loss: 0.3760\n",
            "Epoch 48/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8413 - loss: 0.4067 - val_accuracy: 0.8541 - val_loss: 0.3757\n",
            "Epoch 49/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.4116 - val_accuracy: 0.8541 - val_loss: 0.3762\n",
            "Epoch 50/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.4252 - val_accuracy: 0.8541 - val_loss: 0.3757\n",
            "Epoch 51/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.4324 - val_accuracy: 0.8541 - val_loss: 0.3761\n",
            "Epoch 52/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.4156 - val_accuracy: 0.8541 - val_loss: 0.3758\n",
            "Epoch 53/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8280 - loss: 0.4088 - val_accuracy: 0.8541 - val_loss: 0.3761\n",
            "Epoch 54/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.4243 - val_accuracy: 0.8541 - val_loss: 0.3748\n",
            "Epoch 55/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.4279 - val_accuracy: 0.8541 - val_loss: 0.3752\n",
            "Epoch 56/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.4066 - val_accuracy: 0.8541 - val_loss: 0.3749\n",
            "Epoch 57/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.4165 - val_accuracy: 0.8541 - val_loss: 0.3744\n",
            "Epoch 58/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 0.4074 - val_accuracy: 0.8541 - val_loss: 0.3748\n",
            "Epoch 59/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4206 - val_accuracy: 0.8541 - val_loss: 0.3744\n",
            "Epoch 60/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8170 - loss: 0.4305 - val_accuracy: 0.8541 - val_loss: 0.3741\n",
            "Epoch 61/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4230 - val_accuracy: 0.8541 - val_loss: 0.3741\n",
            "Epoch 62/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4172 - val_accuracy: 0.8541 - val_loss: 0.3737\n",
            "Epoch 63/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4239 - val_accuracy: 0.8541 - val_loss: 0.3735\n",
            "Epoch 64/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4539 - val_accuracy: 0.8541 - val_loss: 0.3739\n",
            "Epoch 65/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.4134 - val_accuracy: 0.8541 - val_loss: 0.3743\n",
            "Epoch 66/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3926 - val_accuracy: 0.8541 - val_loss: 0.3740\n",
            "Epoch 67/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4276 - val_accuracy: 0.8541 - val_loss: 0.3729\n",
            "Epoch 68/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.4028 - val_accuracy: 0.8541 - val_loss: 0.3727\n",
            "Epoch 69/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3828 - val_accuracy: 0.8541 - val_loss: 0.3723\n",
            "Epoch 70/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3980 - val_accuracy: 0.8541 - val_loss: 0.3720\n",
            "Epoch 71/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4472 - val_accuracy: 0.8541 - val_loss: 0.3721\n",
            "Epoch 72/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.4181 - val_accuracy: 0.8541 - val_loss: 0.3710\n",
            "Epoch 73/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.4163 - val_accuracy: 0.8541 - val_loss: 0.3707\n",
            "Epoch 74/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.3906 - val_accuracy: 0.8541 - val_loss: 0.3714\n",
            "Epoch 75/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.4110 - val_accuracy: 0.8541 - val_loss: 0.3711\n",
            "Epoch 76/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.4281 - val_accuracy: 0.8541 - val_loss: 0.3704\n",
            "Epoch 77/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.4138 - val_accuracy: 0.8541 - val_loss: 0.3704\n",
            "Epoch 78/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.4080 - val_accuracy: 0.8541 - val_loss: 0.3708\n",
            "Epoch 79/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.4118 - val_accuracy: 0.8541 - val_loss: 0.3705\n",
            "Epoch 80/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8395 - loss: 0.3943 - val_accuracy: 0.8541 - val_loss: 0.3700\n",
            "Epoch 81/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8222 - loss: 0.4319 - val_accuracy: 0.8541 - val_loss: 0.3691\n",
            "Epoch 82/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.4009 - val_accuracy: 0.8541 - val_loss: 0.3690\n",
            "Epoch 83/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.3829 - val_accuracy: 0.8541 - val_loss: 0.3691\n",
            "Epoch 84/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.4250 - val_accuracy: 0.8541 - val_loss: 0.3687\n",
            "Epoch 85/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.4038 - val_accuracy: 0.8541 - val_loss: 0.3688\n",
            "Epoch 86/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.4226 - val_accuracy: 0.8541 - val_loss: 0.3682\n",
            "Epoch 87/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4270 - val_accuracy: 0.8541 - val_loss: 0.3674\n",
            "Epoch 88/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.4249 - val_accuracy: 0.8541 - val_loss: 0.3673\n",
            "Epoch 89/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.4137 - val_accuracy: 0.8541 - val_loss: 0.3674\n",
            "Epoch 90/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3811 - val_accuracy: 0.8541 - val_loss: 0.3675\n",
            "Epoch 91/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.4067 - val_accuracy: 0.8541 - val_loss: 0.3674\n",
            "Epoch 92/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3772 - val_accuracy: 0.8541 - val_loss: 0.3673\n",
            "Epoch 93/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.3773 - val_accuracy: 0.8541 - val_loss: 0.3679\n",
            "Epoch 94/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3813 - val_accuracy: 0.8541 - val_loss: 0.3682\n",
            "Epoch 95/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.4088 - val_accuracy: 0.8541 - val_loss: 0.3676\n",
            "Epoch 96/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.4143 - val_accuracy: 0.8541 - val_loss: 0.3673\n",
            "Epoch 97/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4310 - val_accuracy: 0.8541 - val_loss: 0.3675\n",
            "Epoch 98/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.4435 - val_accuracy: 0.8541 - val_loss: 0.3680\n",
            "Model mlp_market training complete for niche 5.\n",
            "  Final training loss: 0.41179361939430237\n",
            "  Final validation loss: 0.3680112659931183\n",
            "  Final training accuracy: 0.8225806355476379\n",
            "  Final validation accuracy: 0.8540772795677185\n",
            "Training model lstm for niche 5...\n",
            "Epoch 1/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6309 - loss: 0.6786 - val_accuracy: 0.8541 - val_loss: 0.6353\n",
            "Epoch 2/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7869 - loss: 0.6300 - val_accuracy: 0.8541 - val_loss: 0.5452\n",
            "Epoch 3/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.5225 - val_accuracy: 0.8541 - val_loss: 0.3996\n",
            "Epoch 4/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8273 - loss: 0.4450 - val_accuracy: 0.8541 - val_loss: 0.3950\n",
            "Epoch 5/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.4266 - val_accuracy: 0.8541 - val_loss: 0.3932\n",
            "Epoch 6/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8114 - loss: 0.4522 - val_accuracy: 0.8541 - val_loss: 0.3895\n",
            "Epoch 7/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8085 - loss: 0.4669 - val_accuracy: 0.8541 - val_loss: 0.3892\n",
            "Epoch 8/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8246 - loss: 0.4501 - val_accuracy: 0.8541 - val_loss: 0.3864\n",
            "Epoch 9/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8200 - loss: 0.4544 - val_accuracy: 0.8541 - val_loss: 0.3831\n",
            "Epoch 10/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8250 - loss: 0.4437 - val_accuracy: 0.8541 - val_loss: 0.3876\n",
            "Epoch 11/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7977 - loss: 0.4524 - val_accuracy: 0.8541 - val_loss: 0.3812\n",
            "Epoch 12/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8233 - loss: 0.4367 - val_accuracy: 0.8541 - val_loss: 0.3838\n",
            "Epoch 13/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.4336 - val_accuracy: 0.8541 - val_loss: 0.3805\n",
            "Epoch 14/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8310 - loss: 0.4170 - val_accuracy: 0.8541 - val_loss: 0.3816\n",
            "Epoch 15/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8147 - loss: 0.4471 - val_accuracy: 0.8541 - val_loss: 0.3791\n",
            "Epoch 16/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8217 - loss: 0.4204 - val_accuracy: 0.8541 - val_loss: 0.3805\n",
            "Epoch 17/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7793 - loss: 0.4932 - val_accuracy: 0.8541 - val_loss: 0.3775\n",
            "Epoch 18/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8263 - loss: 0.4563 - val_accuracy: 0.8541 - val_loss: 0.3806\n",
            "Epoch 19/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8285 - loss: 0.4364 - val_accuracy: 0.8541 - val_loss: 0.3765\n",
            "Epoch 20/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.4406 - val_accuracy: 0.8541 - val_loss: 0.3791\n",
            "Epoch 21/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8231 - loss: 0.4284 - val_accuracy: 0.8541 - val_loss: 0.3775\n",
            "Epoch 22/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.4205 - val_accuracy: 0.8541 - val_loss: 0.3766\n",
            "Epoch 23/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.4515 - val_accuracy: 0.8541 - val_loss: 0.3772\n",
            "Epoch 24/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8379 - loss: 0.4146 - val_accuracy: 0.8541 - val_loss: 0.3767\n",
            "Epoch 25/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 0.4560 - val_accuracy: 0.8541 - val_loss: 0.3750\n",
            "Epoch 26/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.4325 - val_accuracy: 0.8541 - val_loss: 0.3747\n",
            "Epoch 27/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.4127 - val_accuracy: 0.8541 - val_loss: 0.3743\n",
            "Epoch 28/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8196 - loss: 0.4268 - val_accuracy: 0.8541 - val_loss: 0.3728\n",
            "Epoch 29/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4395 - val_accuracy: 0.8541 - val_loss: 0.3731\n",
            "Epoch 30/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.4383 - val_accuracy: 0.8541 - val_loss: 0.3733\n",
            "Epoch 31/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.4271 - val_accuracy: 0.8541 - val_loss: 0.3738\n",
            "Epoch 32/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8353 - loss: 0.4022 - val_accuracy: 0.8541 - val_loss: 0.3727\n",
            "Epoch 33/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.4128 - val_accuracy: 0.8541 - val_loss: 0.3720\n",
            "Epoch 34/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.4358 - val_accuracy: 0.8541 - val_loss: 0.3719\n",
            "Epoch 35/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8312 - loss: 0.4089 - val_accuracy: 0.8541 - val_loss: 0.3718\n",
            "Epoch 36/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.4088 - val_accuracy: 0.8541 - val_loss: 0.3706\n",
            "Epoch 37/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.4298 - val_accuracy: 0.8541 - val_loss: 0.3702\n",
            "Epoch 38/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.4242 - val_accuracy: 0.8541 - val_loss: 0.3698\n",
            "Epoch 39/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4370 - val_accuracy: 0.8541 - val_loss: 0.3695\n",
            "Epoch 40/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8334 - loss: 0.3991 - val_accuracy: 0.8541 - val_loss: 0.3691\n",
            "Epoch 41/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8248 - loss: 0.4300 - val_accuracy: 0.8541 - val_loss: 0.3702\n",
            "Epoch 42/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8430 - loss: 0.3950 - val_accuracy: 0.8541 - val_loss: 0.3693\n",
            "Epoch 43/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.4294 - val_accuracy: 0.8541 - val_loss: 0.3694\n",
            "Epoch 44/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.4016 - val_accuracy: 0.8541 - val_loss: 0.3691\n",
            "Epoch 45/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8284 - loss: 0.4126 - val_accuracy: 0.8541 - val_loss: 0.3686\n",
            "Epoch 46/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8162 - loss: 0.4241 - val_accuracy: 0.8541 - val_loss: 0.3683\n",
            "Epoch 47/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8223 - loss: 0.4243 - val_accuracy: 0.8541 - val_loss: 0.3683\n",
            "Epoch 48/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8272 - loss: 0.4079 - val_accuracy: 0.8541 - val_loss: 0.3681\n",
            "Epoch 49/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8413 - loss: 0.3961 - val_accuracy: 0.8541 - val_loss: 0.3684\n",
            "Epoch 50/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.4030 - val_accuracy: 0.8541 - val_loss: 0.3678\n",
            "Epoch 51/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4395 - val_accuracy: 0.8541 - val_loss: 0.3681\n",
            "Epoch 52/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.4166 - val_accuracy: 0.8541 - val_loss: 0.3674\n",
            "Epoch 53/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 0.3845 - val_accuracy: 0.8541 - val_loss: 0.3673\n",
            "Epoch 54/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8178 - loss: 0.4158 - val_accuracy: 0.8541 - val_loss: 0.3672\n",
            "Epoch 55/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.4049 - val_accuracy: 0.8541 - val_loss: 0.3670\n",
            "Epoch 56/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4356 - val_accuracy: 0.8541 - val_loss: 0.3668\n",
            "Epoch 57/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4340 - val_accuracy: 0.8541 - val_loss: 0.3668\n",
            "Epoch 58/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7969 - loss: 0.4407 - val_accuracy: 0.8541 - val_loss: 0.3663\n",
            "Epoch 59/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.4332 - val_accuracy: 0.8541 - val_loss: 0.3664\n",
            "Epoch 60/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.4309 - val_accuracy: 0.8541 - val_loss: 0.3665\n",
            "Epoch 61/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.3908 - val_accuracy: 0.8541 - val_loss: 0.3664\n",
            "Epoch 62/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8340 - loss: 0.4154 - val_accuracy: 0.8541 - val_loss: 0.3657\n",
            "Epoch 63/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.4006 - val_accuracy: 0.8541 - val_loss: 0.3658\n",
            "Epoch 64/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8146 - loss: 0.4355 - val_accuracy: 0.8541 - val_loss: 0.3661\n",
            "Epoch 65/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.3984 - val_accuracy: 0.8541 - val_loss: 0.3662\n",
            "Epoch 66/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.4043 - val_accuracy: 0.8541 - val_loss: 0.3661\n",
            "Epoch 67/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8276 - loss: 0.4298 - val_accuracy: 0.8541 - val_loss: 0.3653\n",
            "Epoch 68/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4332 - val_accuracy: 0.8541 - val_loss: 0.3664\n",
            "Epoch 69/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.4295 - val_accuracy: 0.8541 - val_loss: 0.3653\n",
            "Epoch 70/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3748 - val_accuracy: 0.8541 - val_loss: 0.3652\n",
            "Epoch 71/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8230 - loss: 0.3994 - val_accuracy: 0.8541 - val_loss: 0.3652\n",
            "Epoch 72/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.3997 - val_accuracy: 0.8541 - val_loss: 0.3648\n",
            "Epoch 73/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3994 - val_accuracy: 0.8541 - val_loss: 0.3645\n",
            "Epoch 74/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.4135 - val_accuracy: 0.8541 - val_loss: 0.3643\n",
            "Epoch 75/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8155 - loss: 0.4287 - val_accuracy: 0.8541 - val_loss: 0.3644\n",
            "Epoch 76/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8138 - loss: 0.4216 - val_accuracy: 0.8541 - val_loss: 0.3641\n",
            "Epoch 77/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7820 - loss: 0.4509 - val_accuracy: 0.8541 - val_loss: 0.3642\n",
            "Epoch 78/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8196 - loss: 0.4091 - val_accuracy: 0.8541 - val_loss: 0.3637\n",
            "Epoch 79/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8047 - loss: 0.4445 - val_accuracy: 0.8541 - val_loss: 0.3635\n",
            "Epoch 80/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4255 - val_accuracy: 0.8541 - val_loss: 0.3635\n",
            "Epoch 81/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.4156 - val_accuracy: 0.8541 - val_loss: 0.3640\n",
            "Epoch 82/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8214 - loss: 0.4062 - val_accuracy: 0.8541 - val_loss: 0.3637\n",
            "Epoch 83/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.3902 - val_accuracy: 0.8541 - val_loss: 0.3637\n",
            "Epoch 84/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.4163 - val_accuracy: 0.8541 - val_loss: 0.3639\n",
            "Epoch 85/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8254 - loss: 0.3910 - val_accuracy: 0.8541 - val_loss: 0.3633\n",
            "Epoch 86/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4321 - val_accuracy: 0.8541 - val_loss: 0.3627\n",
            "Epoch 87/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.3956 - val_accuracy: 0.8541 - val_loss: 0.3634\n",
            "Epoch 88/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.4058 - val_accuracy: 0.8541 - val_loss: 0.3634\n",
            "Epoch 89/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.4020 - val_accuracy: 0.8541 - val_loss: 0.3630\n",
            "Epoch 90/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.4006 - val_accuracy: 0.8541 - val_loss: 0.3643\n",
            "Epoch 91/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8376 - loss: 0.3783 - val_accuracy: 0.8541 - val_loss: 0.3633\n",
            "Epoch 92/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8327 - loss: 0.3866 - val_accuracy: 0.8541 - val_loss: 0.3626\n",
            "Epoch 93/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4248 - val_accuracy: 0.8541 - val_loss: 0.3637\n",
            "Epoch 94/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.3812 - val_accuracy: 0.8541 - val_loss: 0.3634\n",
            "Epoch 95/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.4139 - val_accuracy: 0.8541 - val_loss: 0.3626\n",
            "Epoch 96/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.4021 - val_accuracy: 0.8541 - val_loss: 0.3626\n",
            "Epoch 97/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.4048 - val_accuracy: 0.8541 - val_loss: 0.3627\n",
            "Epoch 98/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4243 - val_accuracy: 0.8541 - val_loss: 0.3630\n",
            "Epoch 99/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.4004 - val_accuracy: 0.8541 - val_loss: 0.3650\n",
            "Epoch 100/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4114 - val_accuracy: 0.8541 - val_loss: 0.3635\n",
            "Epoch 101/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.3697 - val_accuracy: 0.8541 - val_loss: 0.3631\n",
            "Epoch 102/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8143 - loss: 0.4201 - val_accuracy: 0.8541 - val_loss: 0.3630\n",
            "Epoch 103/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8308 - loss: 0.4010 - val_accuracy: 0.8541 - val_loss: 0.3648\n",
            "Epoch 104/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.3805 - val_accuracy: 0.8541 - val_loss: 0.3659\n",
            "Epoch 105/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 0.3876 - val_accuracy: 0.8541 - val_loss: 0.3633\n",
            "Epoch 106/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.4159 - val_accuracy: 0.8541 - val_loss: 0.3632\n",
            "Model lstm training complete for niche 5.\n",
            "  Final training loss: 0.4072229862213135\n",
            "  Final validation loss: 0.3631666600704193\n",
            "  Final training accuracy: 0.8225806355476379\n",
            "  Final validation accuracy: 0.8540772795677185\n",
            "Training model cnn for niche 5...\n",
            "Epoch 1/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5921 - loss: 0.6752 - val_accuracy: 0.8541 - val_loss: 0.5475\n",
            "Epoch 2/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7761 - loss: 0.5605 - val_accuracy: 0.8541 - val_loss: 0.4731\n",
            "Epoch 3/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.4846 - val_accuracy: 0.8541 - val_loss: 0.4350\n",
            "Epoch 4/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 0.4678 - val_accuracy: 0.8541 - val_loss: 0.4157\n",
            "Epoch 5/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4522 - val_accuracy: 0.8541 - val_loss: 0.4036\n",
            "Epoch 6/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4697 - val_accuracy: 0.8541 - val_loss: 0.3956\n",
            "Epoch 7/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8209 - loss: 0.4539 - val_accuracy: 0.8541 - val_loss: 0.3901\n",
            "Epoch 8/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 0.4597 - val_accuracy: 0.8541 - val_loss: 0.3856\n",
            "Epoch 9/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8211 - loss: 0.4309 - val_accuracy: 0.8541 - val_loss: 0.3819\n",
            "Epoch 10/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.4249 - val_accuracy: 0.8541 - val_loss: 0.3792\n",
            "Epoch 11/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.4341 - val_accuracy: 0.8541 - val_loss: 0.3770\n",
            "Epoch 12/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.4298 - val_accuracy: 0.8541 - val_loss: 0.3751\n",
            "Epoch 13/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8203 - loss: 0.4106 - val_accuracy: 0.8541 - val_loss: 0.3723\n",
            "Epoch 14/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.4264 - val_accuracy: 0.8541 - val_loss: 0.3704\n",
            "Epoch 15/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.4350 - val_accuracy: 0.8541 - val_loss: 0.3697\n",
            "Epoch 16/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.4033 - val_accuracy: 0.8541 - val_loss: 0.3677\n",
            "Epoch 17/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.4112 - val_accuracy: 0.8541 - val_loss: 0.3670\n",
            "Epoch 18/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4266 - val_accuracy: 0.8541 - val_loss: 0.3662\n",
            "Epoch 19/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.3992 - val_accuracy: 0.8541 - val_loss: 0.3652\n",
            "Epoch 20/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.4236 - val_accuracy: 0.8541 - val_loss: 0.3651\n",
            "Epoch 21/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8163 - loss: 0.4307 - val_accuracy: 0.8541 - val_loss: 0.3643\n",
            "Epoch 22/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8528 - loss: 0.3893 - val_accuracy: 0.8541 - val_loss: 0.3640\n",
            "Epoch 23/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.4241 - val_accuracy: 0.8541 - val_loss: 0.3636\n",
            "Epoch 24/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4227 - val_accuracy: 0.8541 - val_loss: 0.3633\n",
            "Epoch 25/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8228 - loss: 0.4075 - val_accuracy: 0.8541 - val_loss: 0.3623\n",
            "Epoch 26/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8325 - loss: 0.4075 - val_accuracy: 0.8541 - val_loss: 0.3619\n",
            "Epoch 27/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.4025 - val_accuracy: 0.8541 - val_loss: 0.3618\n",
            "Epoch 28/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 0.3928 - val_accuracy: 0.8541 - val_loss: 0.3608\n",
            "Epoch 29/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8344 - loss: 0.3894 - val_accuracy: 0.8541 - val_loss: 0.3606\n",
            "Epoch 30/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.3917 - val_accuracy: 0.8541 - val_loss: 0.3601\n",
            "Epoch 31/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.3954 - val_accuracy: 0.8541 - val_loss: 0.3595\n",
            "Epoch 32/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4648 - val_accuracy: 0.8541 - val_loss: 0.3590\n",
            "Epoch 33/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.4192 - val_accuracy: 0.8541 - val_loss: 0.3587\n",
            "Epoch 34/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.4061 - val_accuracy: 0.8541 - val_loss: 0.3587\n",
            "Epoch 35/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.3790 - val_accuracy: 0.8541 - val_loss: 0.3586\n",
            "Epoch 36/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8174 - loss: 0.4050 - val_accuracy: 0.8541 - val_loss: 0.3582\n",
            "Epoch 37/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.4212 - val_accuracy: 0.8541 - val_loss: 0.3581\n",
            "Epoch 38/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4112 - val_accuracy: 0.8541 - val_loss: 0.3576\n",
            "Epoch 39/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4120 - val_accuracy: 0.8541 - val_loss: 0.3582\n",
            "Epoch 40/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.4004 - val_accuracy: 0.8541 - val_loss: 0.3578\n",
            "Epoch 41/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.3809 - val_accuracy: 0.8541 - val_loss: 0.3578\n",
            "Epoch 42/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.4427 - val_accuracy: 0.8541 - val_loss: 0.3584\n",
            "Epoch 43/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8373 - loss: 0.3738 - val_accuracy: 0.8541 - val_loss: 0.3575\n",
            "Epoch 44/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4147 - val_accuracy: 0.8541 - val_loss: 0.3579\n",
            "Epoch 45/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.4028 - val_accuracy: 0.8541 - val_loss: 0.3577\n",
            "Epoch 46/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.4131 - val_accuracy: 0.8541 - val_loss: 0.3576\n",
            "Epoch 47/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8401 - loss: 0.3664 - val_accuracy: 0.8541 - val_loss: 0.3568\n",
            "Epoch 48/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.3864 - val_accuracy: 0.8541 - val_loss: 0.3571\n",
            "Epoch 49/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.3865 - val_accuracy: 0.8541 - val_loss: 0.3572\n",
            "Epoch 50/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.3781 - val_accuracy: 0.8541 - val_loss: 0.3566\n",
            "Epoch 51/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.3887 - val_accuracy: 0.8541 - val_loss: 0.3565\n",
            "Epoch 52/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.3805 - val_accuracy: 0.8541 - val_loss: 0.3567\n",
            "Epoch 53/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8144 - loss: 0.4006 - val_accuracy: 0.8541 - val_loss: 0.3570\n",
            "Epoch 54/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.4417 - val_accuracy: 0.8541 - val_loss: 0.3573\n",
            "Epoch 55/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.3964 - val_accuracy: 0.8541 - val_loss: 0.3568\n",
            "Epoch 56/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.4063 - val_accuracy: 0.8541 - val_loss: 0.3573\n",
            "Epoch 57/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.4248 - val_accuracy: 0.8541 - val_loss: 0.3572\n",
            "Epoch 58/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.3778 - val_accuracy: 0.8541 - val_loss: 0.3566\n",
            "Epoch 59/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4143 - val_accuracy: 0.8541 - val_loss: 0.3569\n",
            "Epoch 60/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.4155 - val_accuracy: 0.8541 - val_loss: 0.3566\n",
            "Epoch 61/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.4035 - val_accuracy: 0.8541 - val_loss: 0.3564\n",
            "Epoch 62/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8236 - loss: 0.3890 - val_accuracy: 0.8541 - val_loss: 0.3567\n",
            "Epoch 63/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8170 - loss: 0.4109 - val_accuracy: 0.8541 - val_loss: 0.3569\n",
            "Epoch 64/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.3891 - val_accuracy: 0.8541 - val_loss: 0.3565\n",
            "Epoch 65/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.3861 - val_accuracy: 0.8541 - val_loss: 0.3564\n",
            "Epoch 66/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.3977 - val_accuracy: 0.8541 - val_loss: 0.3566\n",
            "Epoch 67/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.3889 - val_accuracy: 0.8541 - val_loss: 0.3573\n",
            "Epoch 68/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.3787 - val_accuracy: 0.8541 - val_loss: 0.3572\n",
            "Epoch 69/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8252 - loss: 0.3995 - val_accuracy: 0.8541 - val_loss: 0.3566\n",
            "Epoch 70/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.3885 - val_accuracy: 0.8541 - val_loss: 0.3562\n",
            "Epoch 71/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4320 - val_accuracy: 0.8541 - val_loss: 0.3558\n",
            "Epoch 72/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.3902 - val_accuracy: 0.8541 - val_loss: 0.3566\n",
            "Epoch 73/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8325 - loss: 0.3812 - val_accuracy: 0.8541 - val_loss: 0.3567\n",
            "Epoch 74/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.4151 - val_accuracy: 0.8541 - val_loss: 0.3565\n",
            "Epoch 75/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8205 - loss: 0.3939 - val_accuracy: 0.8541 - val_loss: 0.3566\n",
            "Epoch 76/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4035 - val_accuracy: 0.8541 - val_loss: 0.3562\n",
            "Epoch 77/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.3661 - val_accuracy: 0.8541 - val_loss: 0.3561\n",
            "Epoch 78/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3945 - val_accuracy: 0.8541 - val_loss: 0.3562\n",
            "Epoch 79/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.3981 - val_accuracy: 0.8541 - val_loss: 0.3565\n",
            "Epoch 80/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.4035 - val_accuracy: 0.8541 - val_loss: 0.3564\n",
            "Epoch 81/1000\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.3819 - val_accuracy: 0.8541 - val_loss: 0.3561\n",
            "Model cnn training complete for niche 5.\n",
            "  Final training loss: 0.3912702202796936\n",
            "  Final validation loss: 0.35614797472953796\n",
            "  Final training accuracy: 0.8204300999641418\n",
            "  Final validation accuracy: 0.8540772795677185\n",
            "Training model random_forest for niche 5...\n",
            "Training model mlp_financial for niche 9...\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4633 - loss: 0.8790 - val_accuracy: 0.9266 - val_loss: 0.4517\n",
            "Epoch 2/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.4796 - val_accuracy: 0.9266 - val_loss: 0.3273\n",
            "Epoch 3/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.3752 - val_accuracy: 0.9266 - val_loss: 0.2939\n",
            "Epoch 4/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.3631 - val_accuracy: 0.9266 - val_loss: 0.2821\n",
            "Epoch 5/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.3528 - val_accuracy: 0.9266 - val_loss: 0.2780\n",
            "Epoch 6/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.3315 - val_accuracy: 0.9266 - val_loss: 0.2745\n",
            "Epoch 7/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.3402 - val_accuracy: 0.9266 - val_loss: 0.2745\n",
            "Epoch 8/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.3353 - val_accuracy: 0.9266 - val_loss: 0.2732\n",
            "Epoch 9/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.3192 - val_accuracy: 0.9266 - val_loss: 0.2745\n",
            "Epoch 10/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.3072 - val_accuracy: 0.9266 - val_loss: 0.2744\n",
            "Epoch 11/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.3193 - val_accuracy: 0.9266 - val_loss: 0.2729\n",
            "Epoch 12/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.3237 - val_accuracy: 0.9266 - val_loss: 0.2705\n",
            "Epoch 13/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.3005 - val_accuracy: 0.9266 - val_loss: 0.2691\n",
            "Epoch 14/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.2639 - val_accuracy: 0.9266 - val_loss: 0.2685\n",
            "Epoch 15/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.2848 - val_accuracy: 0.9266 - val_loss: 0.2676\n",
            "Epoch 16/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2947 - val_accuracy: 0.9266 - val_loss: 0.2678\n",
            "Epoch 17/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.2834 - val_accuracy: 0.9266 - val_loss: 0.2671\n",
            "Epoch 18/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2991 - val_accuracy: 0.9266 - val_loss: 0.2653\n",
            "Epoch 19/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2941 - val_accuracy: 0.9266 - val_loss: 0.2646\n",
            "Epoch 20/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.2963 - val_accuracy: 0.9266 - val_loss: 0.2636\n",
            "Epoch 21/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.3145 - val_accuracy: 0.9266 - val_loss: 0.2631\n",
            "Epoch 22/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2779 - val_accuracy: 0.9266 - val_loss: 0.2640\n",
            "Epoch 23/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9380 - loss: 0.2671 - val_accuracy: 0.9266 - val_loss: 0.2634\n",
            "Epoch 24/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.2771 - val_accuracy: 0.9266 - val_loss: 0.2620\n",
            "Epoch 25/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.2704 - val_accuracy: 0.9266 - val_loss: 0.2615\n",
            "Epoch 26/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9339 - loss: 0.2689 - val_accuracy: 0.9266 - val_loss: 0.2612\n",
            "Epoch 27/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2792 - val_accuracy: 0.9266 - val_loss: 0.2611\n",
            "Epoch 28/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2899 - val_accuracy: 0.9266 - val_loss: 0.2606\n",
            "Epoch 29/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.2382 - val_accuracy: 0.9266 - val_loss: 0.2606\n",
            "Epoch 30/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.2526 - val_accuracy: 0.9266 - val_loss: 0.2603\n",
            "Epoch 31/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2852 - val_accuracy: 0.9266 - val_loss: 0.2602\n",
            "Epoch 32/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9325 - loss: 0.2568 - val_accuracy: 0.9266 - val_loss: 0.2595\n",
            "Epoch 33/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2609 - val_accuracy: 0.9266 - val_loss: 0.2587\n",
            "Epoch 34/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.2465 - val_accuracy: 0.9266 - val_loss: 0.2587\n",
            "Epoch 35/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2574 - val_accuracy: 0.9266 - val_loss: 0.2574\n",
            "Epoch 36/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.2351 - val_accuracy: 0.9266 - val_loss: 0.2582\n",
            "Epoch 37/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2576 - val_accuracy: 0.9266 - val_loss: 0.2586\n",
            "Epoch 38/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2634 - val_accuracy: 0.9266 - val_loss: 0.2588\n",
            "Epoch 39/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.2540 - val_accuracy: 0.9266 - val_loss: 0.2581\n",
            "Epoch 40/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.2541 - val_accuracy: 0.9266 - val_loss: 0.2573\n",
            "Epoch 41/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.2504 - val_accuracy: 0.9266 - val_loss: 0.2574\n",
            "Epoch 42/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2157 - val_accuracy: 0.9266 - val_loss: 0.2577\n",
            "Epoch 43/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2728 - val_accuracy: 0.9266 - val_loss: 0.2584\n",
            "Epoch 44/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9325 - loss: 0.2625 - val_accuracy: 0.9266 - val_loss: 0.2582\n",
            "Epoch 45/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2568 - val_accuracy: 0.9266 - val_loss: 0.2580\n",
            "Epoch 46/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.2435 - val_accuracy: 0.9266 - val_loss: 0.2575\n",
            "Epoch 47/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.2647 - val_accuracy: 0.9266 - val_loss: 0.2574\n",
            "Epoch 48/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.2489 - val_accuracy: 0.9266 - val_loss: 0.2575\n",
            "Epoch 49/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.2402 - val_accuracy: 0.9266 - val_loss: 0.2571\n",
            "Epoch 50/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.2569 - val_accuracy: 0.9266 - val_loss: 0.2574\n",
            "Epoch 51/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.2239 - val_accuracy: 0.9266 - val_loss: 0.2579\n",
            "Epoch 52/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.2463 - val_accuracy: 0.9266 - val_loss: 0.2577\n",
            "Epoch 53/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9303 - loss: 0.2500 - val_accuracy: 0.9266 - val_loss: 0.2583\n",
            "Epoch 54/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9288 - loss: 0.2612 - val_accuracy: 0.9266 - val_loss: 0.2566\n",
            "Epoch 55/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2679 - val_accuracy: 0.9266 - val_loss: 0.2572\n",
            "Epoch 56/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.2353 - val_accuracy: 0.9266 - val_loss: 0.2576\n",
            "Epoch 57/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.2346 - val_accuracy: 0.9266 - val_loss: 0.2574\n",
            "Epoch 58/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2755 - val_accuracy: 0.9266 - val_loss: 0.2560\n",
            "Epoch 59/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.2536 - val_accuracy: 0.9266 - val_loss: 0.2556\n",
            "Epoch 60/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2511 - val_accuracy: 0.9266 - val_loss: 0.2557\n",
            "Epoch 61/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2608 - val_accuracy: 0.9266 - val_loss: 0.2553\n",
            "Epoch 62/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2482 - val_accuracy: 0.9266 - val_loss: 0.2547\n",
            "Epoch 63/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.2561 - val_accuracy: 0.9266 - val_loss: 0.2536\n",
            "Epoch 64/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.2181 - val_accuracy: 0.9266 - val_loss: 0.2536\n",
            "Epoch 65/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.2430 - val_accuracy: 0.9266 - val_loss: 0.2525\n",
            "Epoch 66/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.2588 - val_accuracy: 0.9266 - val_loss: 0.2526\n",
            "Epoch 67/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9334 - loss: 0.2437 - val_accuracy: 0.9266 - val_loss: 0.2522\n",
            "Epoch 68/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2512 - val_accuracy: 0.9266 - val_loss: 0.2523\n",
            "Epoch 69/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.2433 - val_accuracy: 0.9266 - val_loss: 0.2527\n",
            "Epoch 70/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.2490 - val_accuracy: 0.9266 - val_loss: 0.2527\n",
            "Epoch 71/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2545 - val_accuracy: 0.9266 - val_loss: 0.2528\n",
            "Epoch 72/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.2439 - val_accuracy: 0.9266 - val_loss: 0.2533\n",
            "Epoch 73/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2408 - val_accuracy: 0.9266 - val_loss: 0.2527\n",
            "Epoch 74/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.2173 - val_accuracy: 0.9266 - val_loss: 0.2524\n",
            "Epoch 75/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2505 - val_accuracy: 0.9266 - val_loss: 0.2519\n",
            "Epoch 76/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.2380 - val_accuracy: 0.9266 - val_loss: 0.2516\n",
            "Epoch 77/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2402 - val_accuracy: 0.9266 - val_loss: 0.2522\n",
            "Epoch 78/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2640 - val_accuracy: 0.9266 - val_loss: 0.2521\n",
            "Epoch 79/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9380 - loss: 0.2277 - val_accuracy: 0.9266 - val_loss: 0.2518\n",
            "Epoch 80/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2393 - val_accuracy: 0.9266 - val_loss: 0.2522\n",
            "Epoch 81/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.2427 - val_accuracy: 0.9266 - val_loss: 0.2531\n",
            "Epoch 82/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2434 - val_accuracy: 0.9266 - val_loss: 0.2532\n",
            "Epoch 83/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9333 - loss: 0.2292 - val_accuracy: 0.9266 - val_loss: 0.2521\n",
            "Epoch 84/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.2300 - val_accuracy: 0.9266 - val_loss: 0.2514\n",
            "Epoch 85/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.2178 - val_accuracy: 0.9266 - val_loss: 0.2509\n",
            "Epoch 86/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2193 - val_accuracy: 0.9266 - val_loss: 0.2514\n",
            "Epoch 87/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2411 - val_accuracy: 0.9266 - val_loss: 0.2515\n",
            "Epoch 88/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2406 - val_accuracy: 0.9266 - val_loss: 0.2510\n",
            "Epoch 89/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.2319 - val_accuracy: 0.9266 - val_loss: 0.2511\n",
            "Epoch 90/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2575 - val_accuracy: 0.9266 - val_loss: 0.2520\n",
            "Epoch 91/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2210 - val_accuracy: 0.9266 - val_loss: 0.2522\n",
            "Epoch 92/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.2434 - val_accuracy: 0.9266 - val_loss: 0.2524\n",
            "Epoch 93/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.2200 - val_accuracy: 0.9266 - val_loss: 0.2522\n",
            "Epoch 94/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2493 - val_accuracy: 0.9266 - val_loss: 0.2519\n",
            "Epoch 95/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9306 - loss: 0.2471 - val_accuracy: 0.9266 - val_loss: 0.2524\n",
            "Model mlp_financial training complete for niche 9.\n",
            "  Final training loss: 0.2450152486562729\n",
            "  Final validation loss: 0.25235143303871155\n",
            "  Final training accuracy: 0.9317269325256348\n",
            "  Final validation accuracy: 0.9266055226325989\n",
            "Training model mlp_market for niche 9...\n",
            "Epoch 1/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.5906 - val_accuracy: 0.9266 - val_loss: 0.3897\n",
            "Epoch 2/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.4166 - val_accuracy: 0.9266 - val_loss: 0.3253\n",
            "Epoch 3/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.3957 - val_accuracy: 0.9266 - val_loss: 0.3008\n",
            "Epoch 4/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.3540 - val_accuracy: 0.9266 - val_loss: 0.2905\n",
            "Epoch 5/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.3654 - val_accuracy: 0.9266 - val_loss: 0.2852\n",
            "Epoch 6/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.3509 - val_accuracy: 0.9266 - val_loss: 0.2819\n",
            "Epoch 7/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.2879 - val_accuracy: 0.9266 - val_loss: 0.2799\n",
            "Epoch 8/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9379 - loss: 0.2756 - val_accuracy: 0.9266 - val_loss: 0.2783\n",
            "Epoch 9/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.3239 - val_accuracy: 0.9266 - val_loss: 0.2764\n",
            "Epoch 10/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.2865 - val_accuracy: 0.9266 - val_loss: 0.2756\n",
            "Epoch 11/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.2903 - val_accuracy: 0.9266 - val_loss: 0.2736\n",
            "Epoch 12/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.3177 - val_accuracy: 0.9266 - val_loss: 0.2719\n",
            "Epoch 13/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9358 - loss: 0.2714 - val_accuracy: 0.9266 - val_loss: 0.2716\n",
            "Epoch 14/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.3184 - val_accuracy: 0.9266 - val_loss: 0.2701\n",
            "Epoch 15/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.2735 - val_accuracy: 0.9266 - val_loss: 0.2692\n",
            "Epoch 16/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.2818 - val_accuracy: 0.9266 - val_loss: 0.2686\n",
            "Epoch 17/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.2744 - val_accuracy: 0.9266 - val_loss: 0.2674\n",
            "Epoch 18/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.2626 - val_accuracy: 0.9266 - val_loss: 0.2679\n",
            "Epoch 19/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2583 - val_accuracy: 0.9266 - val_loss: 0.2667\n",
            "Epoch 20/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9332 - loss: 0.2848 - val_accuracy: 0.9266 - val_loss: 0.2661\n",
            "Epoch 21/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.2504 - val_accuracy: 0.9266 - val_loss: 0.2658\n",
            "Epoch 22/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.2565 - val_accuracy: 0.9266 - val_loss: 0.2648\n",
            "Epoch 23/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2974 - val_accuracy: 0.9266 - val_loss: 0.2636\n",
            "Epoch 24/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2626 - val_accuracy: 0.9266 - val_loss: 0.2626\n",
            "Epoch 25/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2934 - val_accuracy: 0.9266 - val_loss: 0.2614\n",
            "Epoch 26/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2686 - val_accuracy: 0.9266 - val_loss: 0.2605\n",
            "Epoch 27/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9264 - loss: 0.2650 - val_accuracy: 0.9266 - val_loss: 0.2604\n",
            "Epoch 28/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2682 - val_accuracy: 0.9266 - val_loss: 0.2604\n",
            "Epoch 29/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9379 - loss: 0.2339 - val_accuracy: 0.9266 - val_loss: 0.2595\n",
            "Epoch 30/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.2599 - val_accuracy: 0.9266 - val_loss: 0.2594\n",
            "Epoch 31/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.2608 - val_accuracy: 0.9266 - val_loss: 0.2587\n",
            "Epoch 32/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9306 - loss: 0.2700 - val_accuracy: 0.9266 - val_loss: 0.2587\n",
            "Epoch 33/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.2711 - val_accuracy: 0.9266 - val_loss: 0.2580\n",
            "Epoch 34/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2694 - val_accuracy: 0.9266 - val_loss: 0.2582\n",
            "Epoch 35/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.2511 - val_accuracy: 0.9266 - val_loss: 0.2581\n",
            "Epoch 36/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.2578 - val_accuracy: 0.9266 - val_loss: 0.2577\n",
            "Epoch 37/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.2447 - val_accuracy: 0.9266 - val_loss: 0.2566\n",
            "Epoch 38/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2681 - val_accuracy: 0.9266 - val_loss: 0.2564\n",
            "Epoch 39/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.2464 - val_accuracy: 0.9266 - val_loss: 0.2564\n",
            "Epoch 40/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2703 - val_accuracy: 0.9266 - val_loss: 0.2559\n",
            "Epoch 41/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.2393 - val_accuracy: 0.9266 - val_loss: 0.2558\n",
            "Epoch 42/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.2594 - val_accuracy: 0.9266 - val_loss: 0.2551\n",
            "Epoch 43/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9383 - loss: 0.2477 - val_accuracy: 0.9266 - val_loss: 0.2549\n",
            "Epoch 44/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2529 - val_accuracy: 0.9266 - val_loss: 0.2552\n",
            "Epoch 45/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2465 - val_accuracy: 0.9266 - val_loss: 0.2552\n",
            "Epoch 46/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.2501 - val_accuracy: 0.9266 - val_loss: 0.2546\n",
            "Epoch 47/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2511 - val_accuracy: 0.9266 - val_loss: 0.2547\n",
            "Epoch 48/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.2505 - val_accuracy: 0.9266 - val_loss: 0.2549\n",
            "Epoch 49/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.2368 - val_accuracy: 0.9266 - val_loss: 0.2547\n",
            "Epoch 50/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2833 - val_accuracy: 0.9266 - val_loss: 0.2529\n",
            "Epoch 51/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.2398 - val_accuracy: 0.9266 - val_loss: 0.2529\n",
            "Epoch 52/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.2537 - val_accuracy: 0.9266 - val_loss: 0.2523\n",
            "Epoch 53/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.2521 - val_accuracy: 0.9266 - val_loss: 0.2524\n",
            "Epoch 54/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2687 - val_accuracy: 0.9266 - val_loss: 0.2522\n",
            "Epoch 55/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.2423 - val_accuracy: 0.9266 - val_loss: 0.2523\n",
            "Epoch 56/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.2420 - val_accuracy: 0.9266 - val_loss: 0.2521\n",
            "Epoch 57/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2896 - val_accuracy: 0.9266 - val_loss: 0.2524\n",
            "Epoch 58/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2492 - val_accuracy: 0.9266 - val_loss: 0.2521\n",
            "Epoch 59/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2530 - val_accuracy: 0.9266 - val_loss: 0.2516\n",
            "Epoch 60/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.2362 - val_accuracy: 0.9266 - val_loss: 0.2517\n",
            "Epoch 61/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2547 - val_accuracy: 0.9266 - val_loss: 0.2523\n",
            "Epoch 62/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2456 - val_accuracy: 0.9266 - val_loss: 0.2528\n",
            "Epoch 63/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2554 - val_accuracy: 0.9266 - val_loss: 0.2531\n",
            "Epoch 64/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2213 - val_accuracy: 0.9266 - val_loss: 0.2531\n",
            "Epoch 65/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.2671 - val_accuracy: 0.9266 - val_loss: 0.2524\n",
            "Epoch 66/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2595 - val_accuracy: 0.9266 - val_loss: 0.2525\n",
            "Epoch 67/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2553 - val_accuracy: 0.9266 - val_loss: 0.2519\n",
            "Epoch 68/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9309 - loss: 0.2409 - val_accuracy: 0.9266 - val_loss: 0.2512\n",
            "Epoch 69/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2445 - val_accuracy: 0.9266 - val_loss: 0.2517\n",
            "Epoch 70/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.2321 - val_accuracy: 0.9266 - val_loss: 0.2515\n",
            "Epoch 71/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2360 - val_accuracy: 0.9266 - val_loss: 0.2512\n",
            "Epoch 72/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.2416 - val_accuracy: 0.9266 - val_loss: 0.2507\n",
            "Epoch 73/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2461 - val_accuracy: 0.9266 - val_loss: 0.2505\n",
            "Epoch 74/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.2290 - val_accuracy: 0.9266 - val_loss: 0.2513\n",
            "Epoch 75/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.2402 - val_accuracy: 0.9266 - val_loss: 0.2514\n",
            "Epoch 76/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9337 - loss: 0.2267 - val_accuracy: 0.9266 - val_loss: 0.2513\n",
            "Epoch 77/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.2528 - val_accuracy: 0.9266 - val_loss: 0.2507\n",
            "Epoch 78/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.2241 - val_accuracy: 0.9266 - val_loss: 0.2502\n",
            "Epoch 79/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.2338 - val_accuracy: 0.9266 - val_loss: 0.2502\n",
            "Epoch 80/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2235 - val_accuracy: 0.9266 - val_loss: 0.2505\n",
            "Epoch 81/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2394 - val_accuracy: 0.9266 - val_loss: 0.2512\n",
            "Epoch 82/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2547 - val_accuracy: 0.9266 - val_loss: 0.2509\n",
            "Epoch 83/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2577 - val_accuracy: 0.9266 - val_loss: 0.2505\n",
            "Epoch 84/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2527 - val_accuracy: 0.9266 - val_loss: 0.2503\n",
            "Epoch 85/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.2444 - val_accuracy: 0.9266 - val_loss: 0.2508\n",
            "Epoch 86/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2558 - val_accuracy: 0.9266 - val_loss: 0.2512\n",
            "Epoch 87/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.2472 - val_accuracy: 0.9266 - val_loss: 0.2513\n",
            "Epoch 88/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2507 - val_accuracy: 0.9266 - val_loss: 0.2512\n",
            "Epoch 89/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.2455 - val_accuracy: 0.9266 - val_loss: 0.2511\n",
            "Model mlp_market training complete for niche 9.\n",
            "  Final training loss: 0.24108853936195374\n",
            "  Final validation loss: 0.2510625123977661\n",
            "  Final training accuracy: 0.9317269325256348\n",
            "  Final validation accuracy: 0.9266055226325989\n",
            "Training model lstm for niche 9...\n",
            "Epoch 1/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6790 - loss: 0.6657 - val_accuracy: 0.9266 - val_loss: 0.4792\n",
            "Epoch 2/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.3941 - val_accuracy: 0.9266 - val_loss: 0.2520\n",
            "Epoch 3/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.3194 - val_accuracy: 0.9266 - val_loss: 0.2522\n",
            "Epoch 4/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9299 - loss: 0.2960 - val_accuracy: 0.9266 - val_loss: 0.2520\n",
            "Epoch 5/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.2758 - val_accuracy: 0.9266 - val_loss: 0.2531\n",
            "Epoch 6/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.2572 - val_accuracy: 0.9266 - val_loss: 0.2520\n",
            "Epoch 7/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.2731 - val_accuracy: 0.9266 - val_loss: 0.2508\n",
            "Epoch 8/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.2923 - val_accuracy: 0.9266 - val_loss: 0.2549\n",
            "Epoch 9/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9308 - loss: 0.2623 - val_accuracy: 0.9266 - val_loss: 0.2503\n",
            "Epoch 10/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9311 - loss: 0.2635 - val_accuracy: 0.9266 - val_loss: 0.2515\n",
            "Epoch 11/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.2715 - val_accuracy: 0.9266 - val_loss: 0.2504\n",
            "Epoch 12/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.2476 - val_accuracy: 0.9266 - val_loss: 0.2506\n",
            "Epoch 13/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9222 - loss: 0.2760 - val_accuracy: 0.9266 - val_loss: 0.2498\n",
            "Epoch 14/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.2453 - val_accuracy: 0.9266 - val_loss: 0.2499\n",
            "Epoch 15/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.2547 - val_accuracy: 0.9266 - val_loss: 0.2498\n",
            "Epoch 16/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.2379 - val_accuracy: 0.9266 - val_loss: 0.2497\n",
            "Epoch 17/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.2661 - val_accuracy: 0.9266 - val_loss: 0.2479\n",
            "Epoch 18/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 0.2421 - val_accuracy: 0.9266 - val_loss: 0.2496\n",
            "Epoch 19/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.2476 - val_accuracy: 0.9266 - val_loss: 0.2496\n",
            "Epoch 20/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9342 - loss: 0.2436 - val_accuracy: 0.9266 - val_loss: 0.2501\n",
            "Epoch 21/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.2492 - val_accuracy: 0.9266 - val_loss: 0.2500\n",
            "Epoch 22/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9324 - loss: 0.2487 - val_accuracy: 0.9266 - val_loss: 0.2477\n",
            "Epoch 23/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.2680 - val_accuracy: 0.9266 - val_loss: 0.2511\n",
            "Epoch 24/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9269 - loss: 0.2726 - val_accuracy: 0.9266 - val_loss: 0.2496\n",
            "Epoch 25/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.2452 - val_accuracy: 0.9266 - val_loss: 0.2498\n",
            "Epoch 26/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.2424 - val_accuracy: 0.9266 - val_loss: 0.2489\n",
            "Epoch 27/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.2504 - val_accuracy: 0.9266 - val_loss: 0.2493\n",
            "Epoch 28/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9328 - loss: 0.2526 - val_accuracy: 0.9266 - val_loss: 0.2488\n",
            "Epoch 29/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9236 - loss: 0.2734 - val_accuracy: 0.9266 - val_loss: 0.2486\n",
            "Epoch 30/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 0.2535 - val_accuracy: 0.9266 - val_loss: 0.2499\n",
            "Epoch 31/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9322 - loss: 0.2413 - val_accuracy: 0.9266 - val_loss: 0.2495\n",
            "Epoch 32/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.2438 - val_accuracy: 0.9266 - val_loss: 0.2495\n",
            "Model lstm training complete for niche 9.\n",
            "  Final training loss: 0.2510737478733063\n",
            "  Final validation loss: 0.24949988722801208\n",
            "  Final training accuracy: 0.9317269325256348\n",
            "  Final validation accuracy: 0.9266055226325989\n",
            "Training model cnn for niche 9...\n",
            "Epoch 1/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7317 - loss: 0.5912 - val_accuracy: 0.9266 - val_loss: 0.3555\n",
            "Epoch 2/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.3422 - val_accuracy: 0.9266 - val_loss: 0.2705\n",
            "Epoch 3/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.2656 - val_accuracy: 0.9266 - val_loss: 0.2573\n",
            "Epoch 4/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2679 - val_accuracy: 0.9266 - val_loss: 0.2548\n",
            "Epoch 5/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9308 - loss: 0.2637 - val_accuracy: 0.9266 - val_loss: 0.2534\n",
            "Epoch 6/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.2548 - val_accuracy: 0.9266 - val_loss: 0.2524\n",
            "Epoch 7/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.2449 - val_accuracy: 0.9266 - val_loss: 0.2515\n",
            "Epoch 8/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.2611 - val_accuracy: 0.9266 - val_loss: 0.2511\n",
            "Epoch 9/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.2426 - val_accuracy: 0.9266 - val_loss: 0.2507\n",
            "Epoch 10/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.2340 - val_accuracy: 0.9266 - val_loss: 0.2502\n",
            "Epoch 11/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.2586 - val_accuracy: 0.9266 - val_loss: 0.2498\n",
            "Epoch 12/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.2452 - val_accuracy: 0.9266 - val_loss: 0.2497\n",
            "Epoch 13/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.2356 - val_accuracy: 0.9266 - val_loss: 0.2487\n",
            "Epoch 14/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 0.2331 - val_accuracy: 0.9266 - val_loss: 0.2492\n",
            "Epoch 15/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.2322 - val_accuracy: 0.9266 - val_loss: 0.2487\n",
            "Epoch 16/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.2562 - val_accuracy: 0.9266 - val_loss: 0.2483\n",
            "Epoch 17/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.2692 - val_accuracy: 0.9266 - val_loss: 0.2484\n",
            "Epoch 18/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2242 - val_accuracy: 0.9266 - val_loss: 0.2480\n",
            "Epoch 19/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2608 - val_accuracy: 0.9266 - val_loss: 0.2482\n",
            "Epoch 20/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.2499 - val_accuracy: 0.9266 - val_loss: 0.2478\n",
            "Epoch 21/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2559 - val_accuracy: 0.9266 - val_loss: 0.2476\n",
            "Epoch 22/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.2350 - val_accuracy: 0.9266 - val_loss: 0.2472\n",
            "Epoch 23/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2672 - val_accuracy: 0.9266 - val_loss: 0.2473\n",
            "Epoch 24/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2763 - val_accuracy: 0.9266 - val_loss: 0.2470\n",
            "Epoch 25/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2176 - val_accuracy: 0.9266 - val_loss: 0.2472\n",
            "Epoch 26/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.2143 - val_accuracy: 0.9266 - val_loss: 0.2468\n",
            "Epoch 27/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.2523 - val_accuracy: 0.9266 - val_loss: 0.2471\n",
            "Epoch 28/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.2142 - val_accuracy: 0.9266 - val_loss: 0.2468\n",
            "Epoch 29/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2279 - val_accuracy: 0.9266 - val_loss: 0.2464\n",
            "Epoch 30/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2496 - val_accuracy: 0.9266 - val_loss: 0.2469\n",
            "Epoch 31/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9331 - loss: 0.2325 - val_accuracy: 0.9266 - val_loss: 0.2468\n",
            "Epoch 32/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2393 - val_accuracy: 0.9266 - val_loss: 0.2468\n",
            "Epoch 33/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9332 - loss: 0.2412 - val_accuracy: 0.9266 - val_loss: 0.2472\n",
            "Epoch 34/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2520 - val_accuracy: 0.9266 - val_loss: 0.2471\n",
            "Epoch 35/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.2220 - val_accuracy: 0.9266 - val_loss: 0.2469\n",
            "Epoch 36/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.2294 - val_accuracy: 0.9266 - val_loss: 0.2470\n",
            "Epoch 37/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.2509 - val_accuracy: 0.9266 - val_loss: 0.2469\n",
            "Epoch 38/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.2576 - val_accuracy: 0.9266 - val_loss: 0.2468\n",
            "Epoch 39/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.2172 - val_accuracy: 0.9266 - val_loss: 0.2470\n",
            "Model cnn training complete for niche 9.\n",
            "  Final training loss: 0.2310667634010315\n",
            "  Final validation loss: 0.24697627127170563\n",
            "  Final training accuracy: 0.9317269325256348\n",
            "  Final validation accuracy: 0.9266055226325989\n",
            "Training model random_forest for niche 9...\n",
            "Training model mlp_financial for niche 3...\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6820 - loss: 0.6565 - val_accuracy: 0.9807 - val_loss: 0.3411\n",
            "Epoch 2/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.3881 - val_accuracy: 0.9807 - val_loss: 0.1978\n",
            "Epoch 3/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.2988 - val_accuracy: 0.9807 - val_loss: 0.1527\n",
            "Epoch 4/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.2874 - val_accuracy: 0.9807 - val_loss: 0.1387\n",
            "Epoch 5/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.2709 - val_accuracy: 0.9807 - val_loss: 0.1366\n",
            "Epoch 6/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.2880 - val_accuracy: 0.9807 - val_loss: 0.1321\n",
            "Epoch 7/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9553 - loss: 0.2532 - val_accuracy: 0.9807 - val_loss: 0.1283\n",
            "Epoch 8/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.2527 - val_accuracy: 0.9807 - val_loss: 0.1278\n",
            "Epoch 9/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.2665 - val_accuracy: 0.9807 - val_loss: 0.1272\n",
            "Epoch 10/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.2741 - val_accuracy: 0.9807 - val_loss: 0.1266\n",
            "Epoch 11/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.2579 - val_accuracy: 0.9807 - val_loss: 0.1251\n",
            "Epoch 12/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.2261 - val_accuracy: 0.9807 - val_loss: 0.1236\n",
            "Epoch 13/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.2146 - val_accuracy: 0.9807 - val_loss: 0.1243\n",
            "Epoch 14/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.2014 - val_accuracy: 0.9807 - val_loss: 0.1241\n",
            "Epoch 15/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.2260 - val_accuracy: 0.9807 - val_loss: 0.1244\n",
            "Epoch 16/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.2189 - val_accuracy: 0.9807 - val_loss: 0.1220\n",
            "Epoch 17/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.2209 - val_accuracy: 0.9807 - val_loss: 0.1229\n",
            "Epoch 18/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.2074 - val_accuracy: 0.9807 - val_loss: 0.1209\n",
            "Epoch 19/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.2221 - val_accuracy: 0.9807 - val_loss: 0.1232\n",
            "Epoch 20/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.2106 - val_accuracy: 0.9807 - val_loss: 0.1215\n",
            "Epoch 21/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.2069 - val_accuracy: 0.9807 - val_loss: 0.1220\n",
            "Epoch 22/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2396 - val_accuracy: 0.9807 - val_loss: 0.1202\n",
            "Epoch 23/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.2486 - val_accuracy: 0.9807 - val_loss: 0.1196\n",
            "Epoch 24/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.2097 - val_accuracy: 0.9807 - val_loss: 0.1212\n",
            "Epoch 25/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.2296 - val_accuracy: 0.9807 - val_loss: 0.1201\n",
            "Epoch 26/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.2121 - val_accuracy: 0.9807 - val_loss: 0.1182\n",
            "Epoch 27/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.2141 - val_accuracy: 0.9807 - val_loss: 0.1185\n",
            "Epoch 28/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.2011 - val_accuracy: 0.9807 - val_loss: 0.1165\n",
            "Epoch 29/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.2029 - val_accuracy: 0.9807 - val_loss: 0.1145\n",
            "Epoch 30/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.2154 - val_accuracy: 0.9807 - val_loss: 0.1167\n",
            "Epoch 31/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1952 - val_accuracy: 0.9807 - val_loss: 0.1161\n",
            "Epoch 32/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.1945 - val_accuracy: 0.9807 - val_loss: 0.1169\n",
            "Epoch 33/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.2183 - val_accuracy: 0.9807 - val_loss: 0.1171\n",
            "Epoch 34/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1924 - val_accuracy: 0.9807 - val_loss: 0.1157\n",
            "Epoch 35/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1965 - val_accuracy: 0.9807 - val_loss: 0.1145\n",
            "Epoch 36/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1872 - val_accuracy: 0.9807 - val_loss: 0.1139\n",
            "Epoch 37/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1830 - val_accuracy: 0.9807 - val_loss: 0.1152\n",
            "Epoch 38/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9638 - loss: 0.1801 - val_accuracy: 0.9807 - val_loss: 0.1149\n",
            "Epoch 39/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1900 - val_accuracy: 0.9807 - val_loss: 0.1125\n",
            "Epoch 40/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.1790 - val_accuracy: 0.9807 - val_loss: 0.1128\n",
            "Epoch 41/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.2160 - val_accuracy: 0.9807 - val_loss: 0.1138\n",
            "Epoch 42/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1959 - val_accuracy: 0.9807 - val_loss: 0.1131\n",
            "Epoch 43/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2098 - val_accuracy: 0.9807 - val_loss: 0.1124\n",
            "Epoch 44/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.2045 - val_accuracy: 0.9807 - val_loss: 0.1122\n",
            "Epoch 45/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1695 - val_accuracy: 0.9807 - val_loss: 0.1125\n",
            "Epoch 46/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1811 - val_accuracy: 0.9807 - val_loss: 0.1128\n",
            "Epoch 47/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1771 - val_accuracy: 0.9807 - val_loss: 0.1114\n",
            "Epoch 48/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1942 - val_accuracy: 0.9807 - val_loss: 0.1113\n",
            "Epoch 49/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.2058 - val_accuracy: 0.9807 - val_loss: 0.1107\n",
            "Epoch 50/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1681 - val_accuracy: 0.9807 - val_loss: 0.1109\n",
            "Epoch 51/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9580 - loss: 0.1792 - val_accuracy: 0.9807 - val_loss: 0.1110\n",
            "Epoch 52/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9580 - loss: 0.1796 - val_accuracy: 0.9807 - val_loss: 0.1109\n",
            "Epoch 53/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1911 - val_accuracy: 0.9807 - val_loss: 0.1110\n",
            "Epoch 54/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1837 - val_accuracy: 0.9807 - val_loss: 0.1087\n",
            "Epoch 55/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1901 - val_accuracy: 0.9807 - val_loss: 0.1084\n",
            "Epoch 56/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.2029 - val_accuracy: 0.9807 - val_loss: 0.1087\n",
            "Epoch 57/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.1722 - val_accuracy: 0.9807 - val_loss: 0.1090\n",
            "Epoch 58/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1941 - val_accuracy: 0.9807 - val_loss: 0.1090\n",
            "Epoch 59/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.2047 - val_accuracy: 0.9807 - val_loss: 0.1083\n",
            "Epoch 60/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1783 - val_accuracy: 0.9807 - val_loss: 0.1088\n",
            "Epoch 61/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1932 - val_accuracy: 0.9807 - val_loss: 0.1081\n",
            "Epoch 62/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1831 - val_accuracy: 0.9807 - val_loss: 0.1089\n",
            "Epoch 63/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.2066 - val_accuracy: 0.9807 - val_loss: 0.1080\n",
            "Epoch 64/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.2035 - val_accuracy: 0.9807 - val_loss: 0.1066\n",
            "Epoch 65/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1771 - val_accuracy: 0.9807 - val_loss: 0.1084\n",
            "Epoch 66/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9547 - loss: 0.1794 - val_accuracy: 0.9807 - val_loss: 0.1076\n",
            "Epoch 67/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1811 - val_accuracy: 0.9807 - val_loss: 0.1067\n",
            "Epoch 68/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1847 - val_accuracy: 0.9807 - val_loss: 0.1079\n",
            "Epoch 69/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1838 - val_accuracy: 0.9807 - val_loss: 0.1082\n",
            "Epoch 70/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.1767 - val_accuracy: 0.9807 - val_loss: 0.1067\n",
            "Epoch 71/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9518 - loss: 0.1956 - val_accuracy: 0.9807 - val_loss: 0.1075\n",
            "Epoch 72/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1842 - val_accuracy: 0.9807 - val_loss: 0.1094\n",
            "Epoch 73/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1819 - val_accuracy: 0.9807 - val_loss: 0.1077\n",
            "Epoch 74/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1979 - val_accuracy: 0.9807 - val_loss: 0.1066\n",
            "Epoch 75/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1684 - val_accuracy: 0.9807 - val_loss: 0.1080\n",
            "Epoch 76/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.1873 - val_accuracy: 0.9807 - val_loss: 0.1065\n",
            "Epoch 77/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1687 - val_accuracy: 0.9807 - val_loss: 0.1064\n",
            "Epoch 78/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1627 - val_accuracy: 0.9807 - val_loss: 0.1062\n",
            "Epoch 79/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1845 - val_accuracy: 0.9807 - val_loss: 0.1060\n",
            "Epoch 80/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9473 - loss: 0.1990 - val_accuracy: 0.9807 - val_loss: 0.1051\n",
            "Epoch 81/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1766 - val_accuracy: 0.9807 - val_loss: 0.1037\n",
            "Epoch 82/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1801 - val_accuracy: 0.9807 - val_loss: 0.1052\n",
            "Epoch 83/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1691 - val_accuracy: 0.9807 - val_loss: 0.1061\n",
            "Epoch 84/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1689 - val_accuracy: 0.9807 - val_loss: 0.1063\n",
            "Epoch 85/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9603 - loss: 0.1668 - val_accuracy: 0.9807 - val_loss: 0.1071\n",
            "Epoch 86/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1583 - val_accuracy: 0.9807 - val_loss: 0.1053\n",
            "Epoch 87/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1778 - val_accuracy: 0.9807 - val_loss: 0.1062\n",
            "Epoch 88/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1802 - val_accuracy: 0.9807 - val_loss: 0.1061\n",
            "Epoch 89/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1946 - val_accuracy: 0.9807 - val_loss: 0.1058\n",
            "Epoch 90/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1888 - val_accuracy: 0.9807 - val_loss: 0.1057\n",
            "Epoch 91/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1895 - val_accuracy: 0.9807 - val_loss: 0.1055\n",
            "Model mlp_financial training complete for niche 3.\n",
            "  Final training loss: 0.17875373363494873\n",
            "  Final validation loss: 0.1054505854845047\n",
            "  Final training accuracy: 0.9547101259231567\n",
            "  Final validation accuracy: 0.9806763529777527\n",
            "Training model mlp_market for niche 3...\n",
            "Epoch 1/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7753 - loss: 0.5623 - val_accuracy: 0.9807 - val_loss: 0.3196\n",
            "Epoch 2/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.3880 - val_accuracy: 0.9807 - val_loss: 0.1972\n",
            "Epoch 3/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9371 - loss: 0.3088 - val_accuracy: 0.9807 - val_loss: 0.1525\n",
            "Epoch 4/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.2905 - val_accuracy: 0.9807 - val_loss: 0.1385\n",
            "Epoch 5/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9522 - loss: 0.2675 - val_accuracy: 0.9807 - val_loss: 0.1324\n",
            "Epoch 6/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.2608 - val_accuracy: 0.9807 - val_loss: 0.1336\n",
            "Epoch 7/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.2485 - val_accuracy: 0.9807 - val_loss: 0.1288\n",
            "Epoch 8/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.2552 - val_accuracy: 0.9807 - val_loss: 0.1295\n",
            "Epoch 9/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9493 - loss: 0.2622 - val_accuracy: 0.9807 - val_loss: 0.1265\n",
            "Epoch 10/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.2218 - val_accuracy: 0.9807 - val_loss: 0.1251\n",
            "Epoch 11/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.2333 - val_accuracy: 0.9807 - val_loss: 0.1257\n",
            "Epoch 12/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.2326 - val_accuracy: 0.9807 - val_loss: 0.1256\n",
            "Epoch 13/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.2221 - val_accuracy: 0.9807 - val_loss: 0.1217\n",
            "Epoch 14/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.2315 - val_accuracy: 0.9807 - val_loss: 0.1232\n",
            "Epoch 15/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.2500 - val_accuracy: 0.9807 - val_loss: 0.1229\n",
            "Epoch 16/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.2253 - val_accuracy: 0.9807 - val_loss: 0.1221\n",
            "Epoch 17/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.2330 - val_accuracy: 0.9807 - val_loss: 0.1206\n",
            "Epoch 18/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.2368 - val_accuracy: 0.9807 - val_loss: 0.1199\n",
            "Epoch 19/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.2274 - val_accuracy: 0.9807 - val_loss: 0.1188\n",
            "Epoch 20/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.2247 - val_accuracy: 0.9807 - val_loss: 0.1173\n",
            "Epoch 21/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.2039 - val_accuracy: 0.9807 - val_loss: 0.1170\n",
            "Epoch 22/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.2018 - val_accuracy: 0.9807 - val_loss: 0.1175\n",
            "Epoch 23/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9573 - loss: 0.1989 - val_accuracy: 0.9807 - val_loss: 0.1172\n",
            "Epoch 24/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.2105 - val_accuracy: 0.9807 - val_loss: 0.1155\n",
            "Epoch 25/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.2028 - val_accuracy: 0.9807 - val_loss: 0.1149\n",
            "Epoch 26/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.1947 - val_accuracy: 0.9807 - val_loss: 0.1139\n",
            "Epoch 27/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1939 - val_accuracy: 0.9807 - val_loss: 0.1145\n",
            "Epoch 28/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.2055 - val_accuracy: 0.9807 - val_loss: 0.1124\n",
            "Epoch 29/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.2322 - val_accuracy: 0.9807 - val_loss: 0.1138\n",
            "Epoch 30/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.2006 - val_accuracy: 0.9807 - val_loss: 0.1129\n",
            "Epoch 31/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.2060 - val_accuracy: 0.9807 - val_loss: 0.1136\n",
            "Epoch 32/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9522 - loss: 0.2206 - val_accuracy: 0.9807 - val_loss: 0.1143\n",
            "Epoch 33/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.2341 - val_accuracy: 0.9807 - val_loss: 0.1138\n",
            "Epoch 34/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.2120 - val_accuracy: 0.9807 - val_loss: 0.1119\n",
            "Epoch 35/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1855 - val_accuracy: 0.9807 - val_loss: 0.1121\n",
            "Epoch 36/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1891 - val_accuracy: 0.9807 - val_loss: 0.1121\n",
            "Epoch 37/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1954 - val_accuracy: 0.9807 - val_loss: 0.1117\n",
            "Epoch 38/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.2106 - val_accuracy: 0.9807 - val_loss: 0.1107\n",
            "Epoch 39/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1880 - val_accuracy: 0.9807 - val_loss: 0.1119\n",
            "Epoch 40/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1993 - val_accuracy: 0.9807 - val_loss: 0.1098\n",
            "Epoch 41/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.2062 - val_accuracy: 0.9807 - val_loss: 0.1095\n",
            "Epoch 42/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.1716 - val_accuracy: 0.9807 - val_loss: 0.1102\n",
            "Epoch 43/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.2050 - val_accuracy: 0.9807 - val_loss: 0.1091\n",
            "Epoch 44/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1956 - val_accuracy: 0.9807 - val_loss: 0.1101\n",
            "Epoch 45/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.2071 - val_accuracy: 0.9807 - val_loss: 0.1095\n",
            "Epoch 46/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1742 - val_accuracy: 0.9807 - val_loss: 0.1084\n",
            "Epoch 47/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1857 - val_accuracy: 0.9807 - val_loss: 0.1088\n",
            "Epoch 48/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.1897 - val_accuracy: 0.9807 - val_loss: 0.1092\n",
            "Epoch 49/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.2104 - val_accuracy: 0.9807 - val_loss: 0.1092\n",
            "Epoch 50/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.2017 - val_accuracy: 0.9807 - val_loss: 0.1087\n",
            "Epoch 51/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1891 - val_accuracy: 0.9807 - val_loss: 0.1080\n",
            "Epoch 52/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1923 - val_accuracy: 0.9807 - val_loss: 0.1079\n",
            "Epoch 53/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1921 - val_accuracy: 0.9807 - val_loss: 0.1068\n",
            "Epoch 54/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1985 - val_accuracy: 0.9807 - val_loss: 0.1074\n",
            "Epoch 55/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1950 - val_accuracy: 0.9807 - val_loss: 0.1071\n",
            "Epoch 56/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1827 - val_accuracy: 0.9807 - val_loss: 0.1069\n",
            "Epoch 57/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1718 - val_accuracy: 0.9807 - val_loss: 0.1066\n",
            "Epoch 58/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.2040 - val_accuracy: 0.9807 - val_loss: 0.1065\n",
            "Epoch 59/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1981 - val_accuracy: 0.9807 - val_loss: 0.1063\n",
            "Epoch 60/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1737 - val_accuracy: 0.9807 - val_loss: 0.1050\n",
            "Epoch 61/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1887 - val_accuracy: 0.9807 - val_loss: 0.1055\n",
            "Epoch 62/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1763 - val_accuracy: 0.9807 - val_loss: 0.1054\n",
            "Epoch 63/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1857 - val_accuracy: 0.9807 - val_loss: 0.1045\n",
            "Epoch 64/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1844 - val_accuracy: 0.9807 - val_loss: 0.1037\n",
            "Epoch 65/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1642 - val_accuracy: 0.9807 - val_loss: 0.1034\n",
            "Epoch 66/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1974 - val_accuracy: 0.9807 - val_loss: 0.1031\n",
            "Epoch 67/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1839 - val_accuracy: 0.9807 - val_loss: 0.1035\n",
            "Epoch 68/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1728 - val_accuracy: 0.9807 - val_loss: 0.1036\n",
            "Epoch 69/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.1906 - val_accuracy: 0.9807 - val_loss: 0.1026\n",
            "Epoch 70/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.1644 - val_accuracy: 0.9807 - val_loss: 0.1034\n",
            "Epoch 71/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.1909 - val_accuracy: 0.9807 - val_loss: 0.1026\n",
            "Epoch 72/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.1673 - val_accuracy: 0.9807 - val_loss: 0.1024\n",
            "Epoch 73/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1681 - val_accuracy: 0.9807 - val_loss: 0.1039\n",
            "Epoch 74/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1882 - val_accuracy: 0.9807 - val_loss: 0.1048\n",
            "Epoch 75/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1970 - val_accuracy: 0.9807 - val_loss: 0.1045\n",
            "Epoch 76/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1801 - val_accuracy: 0.9807 - val_loss: 0.1031\n",
            "Epoch 77/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1721 - val_accuracy: 0.9807 - val_loss: 0.1049\n",
            "Epoch 78/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1693 - val_accuracy: 0.9807 - val_loss: 0.1047\n",
            "Epoch 79/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1724 - val_accuracy: 0.9807 - val_loss: 0.1045\n",
            "Epoch 80/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1956 - val_accuracy: 0.9807 - val_loss: 0.1041\n",
            "Epoch 81/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1851 - val_accuracy: 0.9807 - val_loss: 0.1032\n",
            "Epoch 82/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.2022 - val_accuracy: 0.9807 - val_loss: 0.1058\n",
            "Model mlp_market training complete for niche 3.\n",
            "  Final training loss: 0.17934103310108185\n",
            "  Final validation loss: 0.10581549257040024\n",
            "  Final training accuracy: 0.9547101259231567\n",
            "  Final validation accuracy: 0.9806763529777527\n",
            "Training model lstm for niche 3...\n",
            "Epoch 1/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4955 - loss: 0.6979 - val_accuracy: 0.9734 - val_loss: 0.5353\n",
            "Epoch 2/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9402 - loss: 0.4526 - val_accuracy: 0.9807 - val_loss: 0.2013\n",
            "Epoch 3/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9487 - loss: 0.3017 - val_accuracy: 0.9807 - val_loss: 0.1784\n",
            "Epoch 4/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.2754 - val_accuracy: 0.9807 - val_loss: 0.1150\n",
            "Epoch 5/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9584 - loss: 0.1967 - val_accuracy: 0.9807 - val_loss: 0.1197\n",
            "Epoch 6/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9504 - loss: 0.2486 - val_accuracy: 0.9807 - val_loss: 0.1267\n",
            "Epoch 7/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9552 - loss: 0.2214 - val_accuracy: 0.9807 - val_loss: 0.1098\n",
            "Epoch 8/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9583 - loss: 0.1983 - val_accuracy: 0.9807 - val_loss: 0.1123\n",
            "Epoch 9/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.2108 - val_accuracy: 0.9807 - val_loss: 0.1056\n",
            "Epoch 10/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9557 - loss: 0.1935 - val_accuracy: 0.9807 - val_loss: 0.1020\n",
            "Epoch 11/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.1750 - val_accuracy: 0.9807 - val_loss: 0.1141\n",
            "Epoch 12/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9573 - loss: 0.2124 - val_accuracy: 0.9807 - val_loss: 0.1063\n",
            "Epoch 13/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9611 - loss: 0.1885 - val_accuracy: 0.9807 - val_loss: 0.1126\n",
            "Epoch 14/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9579 - loss: 0.1923 - val_accuracy: 0.9807 - val_loss: 0.1075\n",
            "Epoch 15/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9502 - loss: 0.1952 - val_accuracy: 0.9807 - val_loss: 0.1036\n",
            "Epoch 16/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9520 - loss: 0.1955 - val_accuracy: 0.9807 - val_loss: 0.1040\n",
            "Epoch 17/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9527 - loss: 0.2061 - val_accuracy: 0.9807 - val_loss: 0.1057\n",
            "Epoch 18/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9504 - loss: 0.2071 - val_accuracy: 0.9807 - val_loss: 0.1008\n",
            "Epoch 19/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9598 - loss: 0.1825 - val_accuracy: 0.9807 - val_loss: 0.1152\n",
            "Epoch 20/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9557 - loss: 0.1964 - val_accuracy: 0.9807 - val_loss: 0.1045\n",
            "Epoch 21/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9522 - loss: 0.2177 - val_accuracy: 0.9807 - val_loss: 0.1074\n",
            "Epoch 22/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.1774 - val_accuracy: 0.9807 - val_loss: 0.1033\n",
            "Epoch 23/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9580 - loss: 0.1980 - val_accuracy: 0.9807 - val_loss: 0.1068\n",
            "Epoch 24/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9537 - loss: 0.1975 - val_accuracy: 0.9807 - val_loss: 0.1007\n",
            "Epoch 25/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.2001 - val_accuracy: 0.9807 - val_loss: 0.1024\n",
            "Epoch 26/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9490 - loss: 0.2048 - val_accuracy: 0.9807 - val_loss: 0.1006\n",
            "Epoch 27/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9506 - loss: 0.2124 - val_accuracy: 0.9807 - val_loss: 0.1056\n",
            "Epoch 28/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.2247 - val_accuracy: 0.9807 - val_loss: 0.0993\n",
            "Epoch 29/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9585 - loss: 0.2021 - val_accuracy: 0.9807 - val_loss: 0.1040\n",
            "Epoch 30/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9569 - loss: 0.1853 - val_accuracy: 0.9807 - val_loss: 0.1084\n",
            "Epoch 31/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9587 - loss: 0.1783 - val_accuracy: 0.9807 - val_loss: 0.1118\n",
            "Epoch 32/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9525 - loss: 0.2074 - val_accuracy: 0.9807 - val_loss: 0.1008\n",
            "Epoch 33/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9611 - loss: 0.1867 - val_accuracy: 0.9807 - val_loss: 0.1002\n",
            "Epoch 34/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.1779 - val_accuracy: 0.9807 - val_loss: 0.1077\n",
            "Epoch 35/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9558 - loss: 0.1888 - val_accuracy: 0.9807 - val_loss: 0.1055\n",
            "Epoch 36/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.1948 - val_accuracy: 0.9807 - val_loss: 0.1067\n",
            "Epoch 37/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9533 - loss: 0.1970 - val_accuracy: 0.9807 - val_loss: 0.0989\n",
            "Epoch 38/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.2015 - val_accuracy: 0.9807 - val_loss: 0.1013\n",
            "Epoch 39/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9558 - loss: 0.1862 - val_accuracy: 0.9807 - val_loss: 0.1004\n",
            "Epoch 40/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9660 - loss: 0.1594 - val_accuracy: 0.9807 - val_loss: 0.1117\n",
            "Epoch 41/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9601 - loss: 0.1791 - val_accuracy: 0.9807 - val_loss: 0.1062\n",
            "Epoch 42/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9437 - loss: 0.2076 - val_accuracy: 0.9807 - val_loss: 0.1021\n",
            "Epoch 43/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.1997 - val_accuracy: 0.9807 - val_loss: 0.0988\n",
            "Epoch 44/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9536 - loss: 0.2060 - val_accuracy: 0.9807 - val_loss: 0.1040\n",
            "Epoch 45/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9588 - loss: 0.1780 - val_accuracy: 0.9807 - val_loss: 0.1041\n",
            "Epoch 46/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.1959 - val_accuracy: 0.9807 - val_loss: 0.1066\n",
            "Epoch 47/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.1723 - val_accuracy: 0.9807 - val_loss: 0.1078\n",
            "Epoch 48/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9560 - loss: 0.1828 - val_accuracy: 0.9807 - val_loss: 0.1003\n",
            "Epoch 49/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9517 - loss: 0.1953 - val_accuracy: 0.9807 - val_loss: 0.1001\n",
            "Epoch 50/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1883 - val_accuracy: 0.9807 - val_loss: 0.1033\n",
            "Epoch 51/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9534 - loss: 0.1857 - val_accuracy: 0.9807 - val_loss: 0.1035\n",
            "Epoch 52/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1808 - val_accuracy: 0.9807 - val_loss: 0.1040\n",
            "Epoch 53/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1946 - val_accuracy: 0.9807 - val_loss: 0.1076\n",
            "Model lstm training complete for niche 3.\n",
            "  Final training loss: 0.18590812385082245\n",
            "  Final validation loss: 0.10762626677751541\n",
            "  Final training accuracy: 0.9547101259231567\n",
            "  Final validation accuracy: 0.9806763529777527\n",
            "Training model cnn for niche 3...\n",
            "Epoch 1/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7641 - loss: 0.5649 - val_accuracy: 0.9807 - val_loss: 0.3006\n",
            "Epoch 2/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.3012 - val_accuracy: 0.9807 - val_loss: 0.1637\n",
            "Epoch 3/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.2334 - val_accuracy: 0.9807 - val_loss: 0.1248\n",
            "Epoch 4/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.2015 - val_accuracy: 0.9807 - val_loss: 0.1138\n",
            "Epoch 5/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.2100 - val_accuracy: 0.9807 - val_loss: 0.1088\n",
            "Epoch 6/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9501 - loss: 0.2051 - val_accuracy: 0.9807 - val_loss: 0.1063\n",
            "Epoch 7/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1664 - val_accuracy: 0.9807 - val_loss: 0.1061\n",
            "Epoch 8/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1812 - val_accuracy: 0.9807 - val_loss: 0.1061\n",
            "Epoch 9/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.2050 - val_accuracy: 0.9807 - val_loss: 0.1043\n",
            "Epoch 10/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1790 - val_accuracy: 0.9807 - val_loss: 0.1059\n",
            "Epoch 11/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.1490 - val_accuracy: 0.9807 - val_loss: 0.1054\n",
            "Epoch 12/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1801 - val_accuracy: 0.9807 - val_loss: 0.1065\n",
            "Epoch 13/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1698 - val_accuracy: 0.9807 - val_loss: 0.1057\n",
            "Epoch 14/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1864 - val_accuracy: 0.9807 - val_loss: 0.1053\n",
            "Epoch 15/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9534 - loss: 0.1865 - val_accuracy: 0.9807 - val_loss: 0.1032\n",
            "Epoch 16/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.2035 - val_accuracy: 0.9807 - val_loss: 0.1043\n",
            "Epoch 17/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1656 - val_accuracy: 0.9807 - val_loss: 0.1038\n",
            "Epoch 18/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1741 - val_accuracy: 0.9807 - val_loss: 0.1044\n",
            "Epoch 19/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.1916 - val_accuracy: 0.9807 - val_loss: 0.1043\n",
            "Epoch 20/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1775 - val_accuracy: 0.9807 - val_loss: 0.1047\n",
            "Epoch 21/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1974 - val_accuracy: 0.9807 - val_loss: 0.1039\n",
            "Epoch 22/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1785 - val_accuracy: 0.9807 - val_loss: 0.1037\n",
            "Epoch 23/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9527 - loss: 0.1806 - val_accuracy: 0.9807 - val_loss: 0.1031\n",
            "Epoch 24/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.1887 - val_accuracy: 0.9807 - val_loss: 0.1027\n",
            "Epoch 25/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.1766 - val_accuracy: 0.9807 - val_loss: 0.1028\n",
            "Epoch 26/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9522 - loss: 0.1909 - val_accuracy: 0.9807 - val_loss: 0.1043\n",
            "Epoch 27/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1726 - val_accuracy: 0.9807 - val_loss: 0.1037\n",
            "Epoch 28/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1685 - val_accuracy: 0.9807 - val_loss: 0.1030\n",
            "Epoch 29/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9522 - loss: 0.1908 - val_accuracy: 0.9807 - val_loss: 0.1032\n",
            "Epoch 30/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9529 - loss: 0.1886 - val_accuracy: 0.9807 - val_loss: 0.1020\n",
            "Epoch 31/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1958 - val_accuracy: 0.9807 - val_loss: 0.1026\n",
            "Epoch 32/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1817 - val_accuracy: 0.9807 - val_loss: 0.1023\n",
            "Epoch 33/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1761 - val_accuracy: 0.9807 - val_loss: 0.1029\n",
            "Epoch 34/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9541 - loss: 0.1819 - val_accuracy: 0.9807 - val_loss: 0.1022\n",
            "Epoch 35/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.2058 - val_accuracy: 0.9807 - val_loss: 0.1007\n",
            "Epoch 36/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1986 - val_accuracy: 0.9807 - val_loss: 0.1021\n",
            "Epoch 37/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1910 - val_accuracy: 0.9807 - val_loss: 0.1006\n",
            "Epoch 38/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 0.1655 - val_accuracy: 0.9807 - val_loss: 0.1004\n",
            "Epoch 39/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1950 - val_accuracy: 0.9807 - val_loss: 0.1022\n",
            "Epoch 40/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1512 - val_accuracy: 0.9807 - val_loss: 0.1026\n",
            "Epoch 41/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.2081 - val_accuracy: 0.9807 - val_loss: 0.1017\n",
            "Epoch 42/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1595 - val_accuracy: 0.9807 - val_loss: 0.1019\n",
            "Epoch 43/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1979 - val_accuracy: 0.9807 - val_loss: 0.1017\n",
            "Epoch 44/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1866 - val_accuracy: 0.9807 - val_loss: 0.1022\n",
            "Epoch 45/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1573 - val_accuracy: 0.9807 - val_loss: 0.1019\n",
            "Epoch 46/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.1841 - val_accuracy: 0.9807 - val_loss: 0.1027\n",
            "Epoch 47/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1734 - val_accuracy: 0.9807 - val_loss: 0.1022\n",
            "Epoch 48/1000\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1810 - val_accuracy: 0.9807 - val_loss: 0.1009\n",
            "Model cnn training complete for niche 3.\n",
            "  Final training loss: 0.17536775767803192\n",
            "  Final validation loss: 0.1009078174829483\n",
            "  Final training accuracy: 0.9547101259231567\n",
            "  Final validation accuracy: 0.9806763529777527\n",
            "Training model random_forest for niche 3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model mlp_financial for niche 1...\n",
            "Epoch 1/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7679 - loss: 0.5801 - val_accuracy: 0.9684 - val_loss: 0.4067\n",
            "Epoch 2/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9049 - loss: 0.4309 - val_accuracy: 0.9684 - val_loss: 0.2888\n",
            "Epoch 3/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.3663 - val_accuracy: 0.9684 - val_loss: 0.2277\n",
            "Epoch 4/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 0.2941 - val_accuracy: 0.9684 - val_loss: 0.1970\n",
            "Epoch 5/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.2866 - val_accuracy: 0.9684 - val_loss: 0.1834\n",
            "Epoch 6/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9477 - loss: 0.3094 - val_accuracy: 0.9684 - val_loss: 0.1797\n",
            "Epoch 7/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.2481 - val_accuracy: 0.9684 - val_loss: 0.1775\n",
            "Epoch 8/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.2588 - val_accuracy: 0.9684 - val_loss: 0.1775\n",
            "Epoch 9/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9544 - loss: 0.2409 - val_accuracy: 0.9684 - val_loss: 0.1781\n",
            "Epoch 10/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.2405 - val_accuracy: 0.9684 - val_loss: 0.1782\n",
            "Epoch 11/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.2735 - val_accuracy: 0.9684 - val_loss: 0.1789\n",
            "Epoch 12/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.2365 - val_accuracy: 0.9684 - val_loss: 0.1787\n",
            "Epoch 13/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.2568 - val_accuracy: 0.9684 - val_loss: 0.1777\n",
            "Epoch 14/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.2715 - val_accuracy: 0.9684 - val_loss: 0.1776\n",
            "Epoch 15/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.2776 - val_accuracy: 0.9684 - val_loss: 0.1775\n",
            "Epoch 16/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9587 - loss: 0.2375 - val_accuracy: 0.9684 - val_loss: 0.1785\n",
            "Epoch 17/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9550 - loss: 0.2546 - val_accuracy: 0.9684 - val_loss: 0.1792\n",
            "Epoch 18/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9489 - loss: 0.2377 - val_accuracy: 0.9684 - val_loss: 0.1793\n",
            "Epoch 19/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.1924 - val_accuracy: 0.9684 - val_loss: 0.1791\n",
            "Epoch 20/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.2142 - val_accuracy: 0.9684 - val_loss: 0.1807\n",
            "Epoch 21/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.2016 - val_accuracy: 0.9684 - val_loss: 0.1815\n",
            "Epoch 22/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.2457 - val_accuracy: 0.9684 - val_loss: 0.1820\n",
            "Epoch 23/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.2222 - val_accuracy: 0.9684 - val_loss: 0.1829\n",
            "Epoch 24/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.2318 - val_accuracy: 0.9684 - val_loss: 0.1832\n",
            "Epoch 25/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1862 - val_accuracy: 0.9684 - val_loss: 0.1836\n",
            "Model mlp_financial training complete for niche 1.\n",
            "  Final training loss: 0.2019919753074646\n",
            "  Final validation loss: 0.1836417019367218\n",
            "  Final training accuracy: 0.9578392505645752\n",
            "  Final validation accuracy: 0.9684210419654846\n",
            "Training model mlp_market for niche 1...\n",
            "Epoch 1/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8398 - loss: 0.5030 - val_accuracy: 0.9684 - val_loss: 0.3937\n",
            "Epoch 2/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9392 - loss: 0.3869 - val_accuracy: 0.9684 - val_loss: 0.3076\n",
            "Epoch 3/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.3439 - val_accuracy: 0.9684 - val_loss: 0.2608\n",
            "Epoch 4/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9558 - loss: 0.2694 - val_accuracy: 0.9684 - val_loss: 0.2347\n",
            "Epoch 5/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.2529 - val_accuracy: 0.9684 - val_loss: 0.2220\n",
            "Epoch 6/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9668 - loss: 0.2525 - val_accuracy: 0.9684 - val_loss: 0.2141\n",
            "Epoch 7/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9485 - loss: 0.3293 - val_accuracy: 0.9684 - val_loss: 0.2095\n",
            "Epoch 8/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9400 - loss: 0.3267 - val_accuracy: 0.9684 - val_loss: 0.2072\n",
            "Epoch 9/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.2507 - val_accuracy: 0.9684 - val_loss: 0.2051\n",
            "Epoch 10/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9612 - loss: 0.2160 - val_accuracy: 0.9684 - val_loss: 0.2029\n",
            "Epoch 11/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9553 - loss: 0.2341 - val_accuracy: 0.9684 - val_loss: 0.2010\n",
            "Epoch 12/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9652 - loss: 0.2366 - val_accuracy: 0.9684 - val_loss: 0.1982\n",
            "Epoch 13/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.2096 - val_accuracy: 0.9684 - val_loss: 0.1965\n",
            "Epoch 14/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.2239 - val_accuracy: 0.9684 - val_loss: 0.1963\n",
            "Epoch 15/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9650 - loss: 0.2008 - val_accuracy: 0.9684 - val_loss: 0.1960\n",
            "Epoch 16/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1739 - val_accuracy: 0.9684 - val_loss: 0.1974\n",
            "Epoch 17/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1831 - val_accuracy: 0.9684 - val_loss: 0.1972\n",
            "Epoch 18/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.2767 - val_accuracy: 0.9684 - val_loss: 0.1955\n",
            "Epoch 19/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.2156 - val_accuracy: 0.9684 - val_loss: 0.1953\n",
            "Epoch 20/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9602 - loss: 0.2218 - val_accuracy: 0.9684 - val_loss: 0.1952\n",
            "Epoch 21/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9591 - loss: 0.1989 - val_accuracy: 0.9684 - val_loss: 0.1911\n",
            "Epoch 22/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9458 - loss: 0.2390 - val_accuracy: 0.9684 - val_loss: 0.1918\n",
            "Epoch 23/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1841 - val_accuracy: 0.9684 - val_loss: 0.1909\n",
            "Epoch 24/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.2155 - val_accuracy: 0.9684 - val_loss: 0.1914\n",
            "Epoch 25/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1952 - val_accuracy: 0.9684 - val_loss: 0.1913\n",
            "Epoch 26/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.2008 - val_accuracy: 0.9684 - val_loss: 0.1917\n",
            "Epoch 27/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.2016 - val_accuracy: 0.9684 - val_loss: 0.1921\n",
            "Epoch 28/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9695 - loss: 0.1618 - val_accuracy: 0.9684 - val_loss: 0.1941\n",
            "Epoch 29/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.1946 - val_accuracy: 0.9684 - val_loss: 0.1938\n",
            "Epoch 30/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9539 - loss: 0.2129 - val_accuracy: 0.9684 - val_loss: 0.1934\n",
            "Epoch 31/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1811 - val_accuracy: 0.9684 - val_loss: 0.1929\n",
            "Epoch 32/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1834 - val_accuracy: 0.9684 - val_loss: 0.1920\n",
            "Epoch 33/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.2307 - val_accuracy: 0.9684 - val_loss: 0.1919\n",
            "Model mlp_market training complete for niche 1.\n",
            "  Final training loss: 0.19404509663581848\n",
            "  Final validation loss: 0.19192181527614594\n",
            "  Final training accuracy: 0.9578392505645752\n",
            "  Final validation accuracy: 0.9684210419654846\n",
            "Training model lstm for niche 1...\n",
            "Epoch 1/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5958 - loss: 0.6818 - val_accuracy: 0.9684 - val_loss: 0.6260\n",
            "Epoch 2/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9449 - loss: 0.6039 - val_accuracy: 0.9684 - val_loss: 0.5370\n",
            "Epoch 3/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9718 - loss: 0.5038 - val_accuracy: 0.9684 - val_loss: 0.2948\n",
            "Epoch 4/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9679 - loss: 0.2547 - val_accuracy: 0.9684 - val_loss: 0.1633\n",
            "Epoch 5/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.2591 - val_accuracy: 0.9684 - val_loss: 0.1640\n",
            "Epoch 6/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9568 - loss: 0.2132 - val_accuracy: 0.9684 - val_loss: 0.1499\n",
            "Epoch 7/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9554 - loss: 0.2206 - val_accuracy: 0.9684 - val_loss: 0.1510\n",
            "Epoch 8/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9615 - loss: 0.2046 - val_accuracy: 0.9684 - val_loss: 0.1513\n",
            "Epoch 9/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.2201 - val_accuracy: 0.9684 - val_loss: 0.1500\n",
            "Epoch 10/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.2182 - val_accuracy: 0.9684 - val_loss: 0.1507\n",
            "Epoch 11/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9541 - loss: 0.2160 - val_accuracy: 0.9684 - val_loss: 0.1506\n",
            "Epoch 12/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9604 - loss: 0.2085 - val_accuracy: 0.9684 - val_loss: 0.1472\n",
            "Epoch 13/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9464 - loss: 0.2429 - val_accuracy: 0.9684 - val_loss: 0.1471\n",
            "Epoch 14/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9505 - loss: 0.2270 - val_accuracy: 0.9684 - val_loss: 0.1468\n",
            "Epoch 15/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.1778 - val_accuracy: 0.9684 - val_loss: 0.1477\n",
            "Epoch 16/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9612 - loss: 0.1936 - val_accuracy: 0.9684 - val_loss: 0.1485\n",
            "Epoch 17/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9553 - loss: 0.2135 - val_accuracy: 0.9684 - val_loss: 0.1463\n",
            "Epoch 18/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.2287 - val_accuracy: 0.9684 - val_loss: 0.1464\n",
            "Epoch 19/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9690 - loss: 0.1596 - val_accuracy: 0.9684 - val_loss: 0.1489\n",
            "Epoch 20/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9578 - loss: 0.1785 - val_accuracy: 0.9684 - val_loss: 0.1475\n",
            "Epoch 21/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.1941 - val_accuracy: 0.9684 - val_loss: 0.1482\n",
            "Epoch 22/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9488 - loss: 0.2217 - val_accuracy: 0.9684 - val_loss: 0.1467\n",
            "Epoch 23/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.2170 - val_accuracy: 0.9684 - val_loss: 0.1465\n",
            "Epoch 24/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9622 - loss: 0.2207 - val_accuracy: 0.9684 - val_loss: 0.1449\n",
            "Epoch 25/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9623 - loss: 0.1818 - val_accuracy: 0.9684 - val_loss: 0.1439\n",
            "Epoch 26/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9621 - loss: 0.1919 - val_accuracy: 0.9684 - val_loss: 0.1440\n",
            "Epoch 27/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.2222 - val_accuracy: 0.9684 - val_loss: 0.1444\n",
            "Epoch 28/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9593 - loss: 0.1888 - val_accuracy: 0.9684 - val_loss: 0.1460\n",
            "Epoch 29/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9649 - loss: 0.1756 - val_accuracy: 0.9684 - val_loss: 0.1451\n",
            "Epoch 30/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.2081 - val_accuracy: 0.9684 - val_loss: 0.1486\n",
            "Epoch 31/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9718 - loss: 0.1426 - val_accuracy: 0.9684 - val_loss: 0.1475\n",
            "Epoch 32/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.1512 - val_accuracy: 0.9684 - val_loss: 0.1484\n",
            "Epoch 33/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9564 - loss: 0.1995 - val_accuracy: 0.9684 - val_loss: 0.1460\n",
            "Epoch 34/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.1920 - val_accuracy: 0.9684 - val_loss: 0.1452\n",
            "Epoch 35/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9584 - loss: 0.1819 - val_accuracy: 0.9684 - val_loss: 0.1444\n",
            "Model lstm training complete for niche 1.\n",
            "  Final training loss: 0.1863589882850647\n",
            "  Final validation loss: 0.14444968104362488\n",
            "  Final training accuracy: 0.9578392505645752\n",
            "  Final validation accuracy: 0.9684210419654846\n",
            "Training model cnn for niche 1...\n",
            "Epoch 1/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4391 - loss: 0.7672 - val_accuracy: 0.9421 - val_loss: 0.5452\n",
            "Epoch 2/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.5421 - val_accuracy: 0.9684 - val_loss: 0.3911\n",
            "Epoch 3/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.3928 - val_accuracy: 0.9684 - val_loss: 0.2917\n",
            "Epoch 4/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9599 - loss: 0.3117 - val_accuracy: 0.9684 - val_loss: 0.2281\n",
            "Epoch 5/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9619 - loss: 0.2559 - val_accuracy: 0.9684 - val_loss: 0.1912\n",
            "Epoch 6/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.2108 - val_accuracy: 0.9684 - val_loss: 0.1724\n",
            "Epoch 7/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9570 - loss: 0.2015 - val_accuracy: 0.9684 - val_loss: 0.1633\n",
            "Epoch 8/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9592 - loss: 0.1994 - val_accuracy: 0.9684 - val_loss: 0.1579\n",
            "Epoch 9/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9603 - loss: 0.1780 - val_accuracy: 0.9684 - val_loss: 0.1554\n",
            "Epoch 10/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9595 - loss: 0.1776 - val_accuracy: 0.9684 - val_loss: 0.1545\n",
            "Epoch 11/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9622 - loss: 0.1734 - val_accuracy: 0.9684 - val_loss: 0.1542\n",
            "Epoch 12/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9484 - loss: 0.2161 - val_accuracy: 0.9684 - val_loss: 0.1538\n",
            "Epoch 13/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.2028 - val_accuracy: 0.9684 - val_loss: 0.1528\n",
            "Epoch 14/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.1808 - val_accuracy: 0.9684 - val_loss: 0.1520\n",
            "Epoch 15/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9713 - loss: 0.1346 - val_accuracy: 0.9684 - val_loss: 0.1516\n",
            "Epoch 16/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9614 - loss: 0.1614 - val_accuracy: 0.9684 - val_loss: 0.1513\n",
            "Epoch 17/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.1570 - val_accuracy: 0.9684 - val_loss: 0.1511\n",
            "Epoch 18/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9501 - loss: 0.1997 - val_accuracy: 0.9684 - val_loss: 0.1514\n",
            "Epoch 19/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9695 - loss: 0.1366 - val_accuracy: 0.9684 - val_loss: 0.1509\n",
            "Epoch 20/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9522 - loss: 0.1866 - val_accuracy: 0.9684 - val_loss: 0.1507\n",
            "Epoch 21/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.1560 - val_accuracy: 0.9684 - val_loss: 0.1507\n",
            "Epoch 22/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9597 - loss: 0.1599 - val_accuracy: 0.9684 - val_loss: 0.1504\n",
            "Epoch 23/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1622 - val_accuracy: 0.9684 - val_loss: 0.1506\n",
            "Epoch 24/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9503 - loss: 0.2031 - val_accuracy: 0.9684 - val_loss: 0.1506\n",
            "Epoch 25/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9609 - loss: 0.1610 - val_accuracy: 0.9684 - val_loss: 0.1503\n",
            "Epoch 26/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9519 - loss: 0.1954 - val_accuracy: 0.9684 - val_loss: 0.1501\n",
            "Epoch 27/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.2137 - val_accuracy: 0.9684 - val_loss: 0.1502\n",
            "Epoch 28/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9619 - loss: 0.1547 - val_accuracy: 0.9684 - val_loss: 0.1499\n",
            "Epoch 29/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9544 - loss: 0.1856 - val_accuracy: 0.9684 - val_loss: 0.1502\n",
            "Epoch 30/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.2085 - val_accuracy: 0.9684 - val_loss: 0.1503\n",
            "Epoch 31/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9586 - loss: 0.1755 - val_accuracy: 0.9684 - val_loss: 0.1504\n",
            "Epoch 32/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1853 - val_accuracy: 0.9684 - val_loss: 0.1504\n",
            "Epoch 33/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9586 - loss: 0.1647 - val_accuracy: 0.9684 - val_loss: 0.1499\n",
            "Epoch 34/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9502 - loss: 0.2099 - val_accuracy: 0.9684 - val_loss: 0.1498\n",
            "Epoch 35/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 0.1754 - val_accuracy: 0.9684 - val_loss: 0.1499\n",
            "Epoch 36/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9584 - loss: 0.1592 - val_accuracy: 0.9684 - val_loss: 0.1501\n",
            "Epoch 37/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9540 - loss: 0.1760 - val_accuracy: 0.9684 - val_loss: 0.1502\n",
            "Epoch 38/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9652 - loss: 0.1417 - val_accuracy: 0.9684 - val_loss: 0.1498\n",
            "Epoch 39/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9547 - loss: 0.1804 - val_accuracy: 0.9684 - val_loss: 0.1501\n",
            "Epoch 40/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9528 - loss: 0.1784 - val_accuracy: 0.9684 - val_loss: 0.1504\n",
            "Epoch 41/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9576 - loss: 0.1667 - val_accuracy: 0.9684 - val_loss: 0.1503\n",
            "Epoch 42/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9592 - loss: 0.1584 - val_accuracy: 0.9684 - val_loss: 0.1498\n",
            "Epoch 43/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1604 - val_accuracy: 0.9684 - val_loss: 0.1499\n",
            "Epoch 44/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9580 - loss: 0.1635 - val_accuracy: 0.9684 - val_loss: 0.1500\n",
            "Epoch 45/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.2078 - val_accuracy: 0.9684 - val_loss: 0.1502\n",
            "Epoch 46/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.1513 - val_accuracy: 0.9684 - val_loss: 0.1506\n",
            "Epoch 47/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9431 - loss: 0.2004 - val_accuracy: 0.9684 - val_loss: 0.1507\n",
            "Epoch 48/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9677 - loss: 0.1505 - val_accuracy: 0.9684 - val_loss: 0.1504\n",
            "Epoch 49/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9502 - loss: 0.1827 - val_accuracy: 0.9684 - val_loss: 0.1507\n",
            "Epoch 50/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9656 - loss: 0.1579 - val_accuracy: 0.9684 - val_loss: 0.1505\n",
            "Epoch 51/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9659 - loss: 0.1462 - val_accuracy: 0.9684 - val_loss: 0.1508\n",
            "Epoch 52/1000\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.1919 - val_accuracy: 0.9684 - val_loss: 0.1515\n",
            "Model cnn training complete for niche 1.\n",
            "  Final training loss: 0.16660362482070923\n",
            "  Final validation loss: 0.15152406692504883\n",
            "  Final training accuracy: 0.9578392505645752\n",
            "  Final validation accuracy: 0.9684210419654846\n",
            "Training model random_forest for niche 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model mlp_financial for niche 8...\n",
            "Epoch 1/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6157 - loss: 0.7482 - val_accuracy: 0.8580 - val_loss: 0.5825\n",
            "Epoch 2/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7571 - loss: 0.5819 - val_accuracy: 0.8977 - val_loss: 0.4720\n",
            "Epoch 3/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8291 - loss: 0.4993 - val_accuracy: 0.8977 - val_loss: 0.4143\n",
            "Epoch 4/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8499 - loss: 0.4426 - val_accuracy: 0.8977 - val_loss: 0.3833\n",
            "Epoch 5/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.3802 - val_accuracy: 0.8977 - val_loss: 0.3680\n",
            "Epoch 6/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8828 - loss: 0.4066 - val_accuracy: 0.8977 - val_loss: 0.3639\n",
            "Epoch 7/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9166 - loss: 0.3722 - val_accuracy: 0.8977 - val_loss: 0.3633\n",
            "Epoch 8/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9190 - loss: 0.3274 - val_accuracy: 0.8977 - val_loss: 0.3628\n",
            "Epoch 9/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8989 - loss: 0.3716 - val_accuracy: 0.8977 - val_loss: 0.3626\n",
            "Epoch 10/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8905 - loss: 0.3790 - val_accuracy: 0.8977 - val_loss: 0.3618\n",
            "Epoch 11/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9090 - loss: 0.3536 - val_accuracy: 0.8977 - val_loss: 0.3613\n",
            "Epoch 12/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.3267 - val_accuracy: 0.8977 - val_loss: 0.3626\n",
            "Epoch 13/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9201 - loss: 0.3070 - val_accuracy: 0.8977 - val_loss: 0.3634\n",
            "Epoch 14/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9059 - loss: 0.3157 - val_accuracy: 0.8977 - val_loss: 0.3643\n",
            "Epoch 15/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9084 - loss: 0.3544 - val_accuracy: 0.8977 - val_loss: 0.3645\n",
            "Epoch 16/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9035 - loss: 0.3229 - val_accuracy: 0.8977 - val_loss: 0.3663\n",
            "Epoch 17/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9041 - loss: 0.3794 - val_accuracy: 0.8977 - val_loss: 0.3641\n",
            "Epoch 18/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9197 - loss: 0.3054 - val_accuracy: 0.8977 - val_loss: 0.3646\n",
            "Epoch 19/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.3570 - val_accuracy: 0.8977 - val_loss: 0.3642\n",
            "Epoch 20/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.3922 - val_accuracy: 0.8977 - val_loss: 0.3637\n",
            "Epoch 21/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9150 - loss: 0.3011 - val_accuracy: 0.8977 - val_loss: 0.3637\n",
            "Model mlp_financial training complete for niche 8.\n",
            "  Final training loss: 0.32125017046928406\n",
            "  Final validation loss: 0.3636970520019531\n",
            "  Final training accuracy: 0.9089615941047668\n",
            "  Final validation accuracy: 0.8977272510528564\n",
            "Training model mlp_market for niche 8...\n",
            "Epoch 1/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.4541 - loss: 0.9264 - val_accuracy: 0.6761 - val_loss: 0.6687\n",
            "Epoch 2/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6271 - loss: 0.7389 - val_accuracy: 0.8409 - val_loss: 0.5574\n",
            "Epoch 3/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7462 - loss: 0.5966 - val_accuracy: 0.8977 - val_loss: 0.4783\n",
            "Epoch 4/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 0.4971 - val_accuracy: 0.8977 - val_loss: 0.4235\n",
            "Epoch 5/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8578 - loss: 0.4775 - val_accuracy: 0.8977 - val_loss: 0.3915\n",
            "Epoch 6/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8849 - loss: 0.4320 - val_accuracy: 0.8977 - val_loss: 0.3735\n",
            "Epoch 7/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8739 - loss: 0.4597 - val_accuracy: 0.8977 - val_loss: 0.3637\n",
            "Epoch 8/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.3920 - val_accuracy: 0.8977 - val_loss: 0.3535\n",
            "Epoch 9/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8772 - loss: 0.4345 - val_accuracy: 0.8977 - val_loss: 0.3478\n",
            "Epoch 10/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.3759 - val_accuracy: 0.8977 - val_loss: 0.3435\n",
            "Epoch 11/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8890 - loss: 0.3948 - val_accuracy: 0.8977 - val_loss: 0.3410\n",
            "Epoch 12/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8992 - loss: 0.3970 - val_accuracy: 0.8977 - val_loss: 0.3394\n",
            "Epoch 13/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8994 - loss: 0.3782 - val_accuracy: 0.8977 - val_loss: 0.3385\n",
            "Epoch 14/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.3491 - val_accuracy: 0.8977 - val_loss: 0.3372\n",
            "Epoch 15/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9101 - loss: 0.3622 - val_accuracy: 0.8977 - val_loss: 0.3369\n",
            "Epoch 16/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.3520 - val_accuracy: 0.8977 - val_loss: 0.3363\n",
            "Epoch 17/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.3656 - val_accuracy: 0.8977 - val_loss: 0.3368\n",
            "Epoch 18/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8942 - loss: 0.3495 - val_accuracy: 0.8977 - val_loss: 0.3366\n",
            "Epoch 19/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8886 - loss: 0.3575 - val_accuracy: 0.8977 - val_loss: 0.3359\n",
            "Epoch 20/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.3384 - val_accuracy: 0.8977 - val_loss: 0.3351\n",
            "Epoch 21/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 0.3942 - val_accuracy: 0.8977 - val_loss: 0.3352\n",
            "Epoch 22/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9347 - loss: 0.2975 - val_accuracy: 0.8977 - val_loss: 0.3349\n",
            "Epoch 23/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9135 - loss: 0.3469 - val_accuracy: 0.8977 - val_loss: 0.3342\n",
            "Epoch 24/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9156 - loss: 0.3287 - val_accuracy: 0.8977 - val_loss: 0.3340\n",
            "Epoch 25/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9041 - loss: 0.3931 - val_accuracy: 0.8977 - val_loss: 0.3338\n",
            "Epoch 26/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9087 - loss: 0.3430 - val_accuracy: 0.8977 - val_loss: 0.3341\n",
            "Epoch 27/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.3410 - val_accuracy: 0.8977 - val_loss: 0.3347\n",
            "Epoch 28/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.3628 - val_accuracy: 0.8977 - val_loss: 0.3352\n",
            "Epoch 29/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.3094 - val_accuracy: 0.8977 - val_loss: 0.3352\n",
            "Epoch 30/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9073 - loss: 0.3097 - val_accuracy: 0.8977 - val_loss: 0.3351\n",
            "Epoch 31/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.2900 - val_accuracy: 0.8977 - val_loss: 0.3348\n",
            "Epoch 32/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.3430 - val_accuracy: 0.8977 - val_loss: 0.3346\n",
            "Epoch 33/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8986 - loss: 0.3848 - val_accuracy: 0.8977 - val_loss: 0.3340\n",
            "Epoch 34/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.2812 - val_accuracy: 0.8977 - val_loss: 0.3334\n",
            "Epoch 35/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9147 - loss: 0.3208 - val_accuracy: 0.8977 - val_loss: 0.3333\n",
            "Epoch 36/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.3408 - val_accuracy: 0.8977 - val_loss: 0.3329\n",
            "Epoch 37/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.3332 - val_accuracy: 0.8977 - val_loss: 0.3333\n",
            "Epoch 38/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9082 - loss: 0.3045 - val_accuracy: 0.8977 - val_loss: 0.3337\n",
            "Epoch 39/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8992 - loss: 0.3538 - val_accuracy: 0.8977 - val_loss: 0.3332\n",
            "Epoch 40/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.3076 - val_accuracy: 0.8977 - val_loss: 0.3325\n",
            "Epoch 41/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.3206 - val_accuracy: 0.8977 - val_loss: 0.3329\n",
            "Epoch 42/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.3194 - val_accuracy: 0.8977 - val_loss: 0.3324\n",
            "Epoch 43/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9084 - loss: 0.3444 - val_accuracy: 0.8977 - val_loss: 0.3322\n",
            "Epoch 44/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.3979 - val_accuracy: 0.8977 - val_loss: 0.3320\n",
            "Epoch 45/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.3219 - val_accuracy: 0.8977 - val_loss: 0.3317\n",
            "Epoch 46/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.2731 - val_accuracy: 0.8977 - val_loss: 0.3314\n",
            "Epoch 47/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2916 - val_accuracy: 0.8977 - val_loss: 0.3315\n",
            "Epoch 48/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.3284 - val_accuracy: 0.8977 - val_loss: 0.3315\n",
            "Epoch 49/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9082 - loss: 0.2916 - val_accuracy: 0.8977 - val_loss: 0.3321\n",
            "Epoch 50/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9021 - loss: 0.3135 - val_accuracy: 0.8977 - val_loss: 0.3315\n",
            "Epoch 51/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8958 - loss: 0.3292 - val_accuracy: 0.8977 - val_loss: 0.3325\n",
            "Epoch 52/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.3165 - val_accuracy: 0.8977 - val_loss: 0.3332\n",
            "Epoch 53/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.3220 - val_accuracy: 0.8977 - val_loss: 0.3338\n",
            "Epoch 54/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.3251 - val_accuracy: 0.8977 - val_loss: 0.3345\n",
            "Epoch 55/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9056 - loss: 0.3091 - val_accuracy: 0.8977 - val_loss: 0.3335\n",
            "Epoch 56/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9207 - loss: 0.2705 - val_accuracy: 0.8977 - val_loss: 0.3336\n",
            "Model mlp_market training complete for niche 8.\n",
            "  Final training loss: 0.2985151708126068\n",
            "  Final validation loss: 0.3335728347301483\n",
            "  Final training accuracy: 0.9103840589523315\n",
            "  Final validation accuracy: 0.8977272510528564\n",
            "Training model lstm for niche 8...\n",
            "Epoch 1/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4487 - loss: 0.7071 - val_accuracy: 0.8182 - val_loss: 0.6507\n",
            "Epoch 2/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8005 - loss: 0.6317 - val_accuracy: 0.8977 - val_loss: 0.5646\n",
            "Epoch 3/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8900 - loss: 0.5286 - val_accuracy: 0.8977 - val_loss: 0.3956\n",
            "Epoch 4/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9089 - loss: 0.3890 - val_accuracy: 0.8977 - val_loss: 0.3216\n",
            "Epoch 5/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9201 - loss: 0.3421 - val_accuracy: 0.8977 - val_loss: 0.3213\n",
            "Epoch 6/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9035 - loss: 0.3780 - val_accuracy: 0.8977 - val_loss: 0.3109\n",
            "Epoch 7/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8923 - loss: 0.3628 - val_accuracy: 0.8977 - val_loss: 0.3055\n",
            "Epoch 8/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9005 - loss: 0.3635 - val_accuracy: 0.8977 - val_loss: 0.3041\n",
            "Epoch 9/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.3471 - val_accuracy: 0.8977 - val_loss: 0.3043\n",
            "Epoch 10/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9096 - loss: 0.3115 - val_accuracy: 0.8977 - val_loss: 0.3064\n",
            "Epoch 11/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9004 - loss: 0.3617 - val_accuracy: 0.8977 - val_loss: 0.3035\n",
            "Epoch 12/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8969 - loss: 0.3297 - val_accuracy: 0.8977 - val_loss: 0.3030\n",
            "Epoch 13/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9045 - loss: 0.3450 - val_accuracy: 0.8977 - val_loss: 0.3035\n",
            "Epoch 14/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9227 - loss: 0.3021 - val_accuracy: 0.8977 - val_loss: 0.3035\n",
            "Epoch 15/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9162 - loss: 0.3126 - val_accuracy: 0.8977 - val_loss: 0.3024\n",
            "Epoch 16/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9304 - loss: 0.2688 - val_accuracy: 0.8977 - val_loss: 0.3028\n",
            "Epoch 17/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9086 - loss: 0.3252 - val_accuracy: 0.8977 - val_loss: 0.3055\n",
            "Epoch 18/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2837 - val_accuracy: 0.8977 - val_loss: 0.3011\n",
            "Epoch 19/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9204 - loss: 0.2778 - val_accuracy: 0.8977 - val_loss: 0.3033\n",
            "Epoch 20/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9026 - loss: 0.3536 - val_accuracy: 0.8977 - val_loss: 0.3000\n",
            "Epoch 21/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9255 - loss: 0.3037 - val_accuracy: 0.8977 - val_loss: 0.3020\n",
            "Epoch 22/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.3009 - val_accuracy: 0.8977 - val_loss: 0.3057\n",
            "Epoch 23/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.3435 - val_accuracy: 0.8977 - val_loss: 0.3023\n",
            "Epoch 24/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.2837 - val_accuracy: 0.8977 - val_loss: 0.3023\n",
            "Epoch 25/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9140 - loss: 0.3220 - val_accuracy: 0.8977 - val_loss: 0.3034\n",
            "Epoch 26/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.3328 - val_accuracy: 0.8977 - val_loss: 0.3010\n",
            "Epoch 27/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9184 - loss: 0.2922 - val_accuracy: 0.8977 - val_loss: 0.3022\n",
            "Epoch 28/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9119 - loss: 0.2899 - val_accuracy: 0.8977 - val_loss: 0.3018\n",
            "Epoch 29/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2960 - val_accuracy: 0.8977 - val_loss: 0.3023\n",
            "Epoch 30/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9167 - loss: 0.2829 - val_accuracy: 0.8977 - val_loss: 0.3012\n",
            "Model lstm training complete for niche 8.\n",
            "  Final training loss: 0.3011942207813263\n",
            "  Final validation loss: 0.301231324672699\n",
            "  Final training accuracy: 0.9103840589523315\n",
            "  Final validation accuracy: 0.8977272510528564\n",
            "Training model cnn for niche 8...\n",
            "Epoch 1/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6706 - loss: 0.6379 - val_accuracy: 0.8636 - val_loss: 0.5255\n",
            "Epoch 2/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.4880 - val_accuracy: 0.8864 - val_loss: 0.4340\n",
            "Epoch 3/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8905 - loss: 0.4067 - val_accuracy: 0.8920 - val_loss: 0.3793\n",
            "Epoch 4/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.3640 - val_accuracy: 0.8977 - val_loss: 0.3494\n",
            "Epoch 5/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.3116 - val_accuracy: 0.8977 - val_loss: 0.3355\n",
            "Epoch 6/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.3044 - val_accuracy: 0.8977 - val_loss: 0.3300\n",
            "Epoch 7/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.3264 - val_accuracy: 0.8977 - val_loss: 0.3267\n",
            "Epoch 8/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9014 - loss: 0.3355 - val_accuracy: 0.8977 - val_loss: 0.3245\n",
            "Epoch 9/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9097 - loss: 0.3057 - val_accuracy: 0.8977 - val_loss: 0.3238\n",
            "Epoch 10/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8990 - loss: 0.3345 - val_accuracy: 0.8977 - val_loss: 0.3223\n",
            "Epoch 11/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.3023 - val_accuracy: 0.8977 - val_loss: 0.3216\n",
            "Epoch 12/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9038 - loss: 0.3243 - val_accuracy: 0.8977 - val_loss: 0.3204\n",
            "Epoch 13/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9124 - loss: 0.2951 - val_accuracy: 0.8977 - val_loss: 0.3191\n",
            "Epoch 14/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9050 - loss: 0.3069 - val_accuracy: 0.8977 - val_loss: 0.3186\n",
            "Epoch 15/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.2729 - val_accuracy: 0.8977 - val_loss: 0.3180\n",
            "Epoch 16/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8970 - loss: 0.3159 - val_accuracy: 0.8977 - val_loss: 0.3172\n",
            "Epoch 17/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.3079 - val_accuracy: 0.8977 - val_loss: 0.3162\n",
            "Epoch 18/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2527 - val_accuracy: 0.8977 - val_loss: 0.3158\n",
            "Epoch 19/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.2514 - val_accuracy: 0.8977 - val_loss: 0.3157\n",
            "Epoch 20/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9048 - loss: 0.2873 - val_accuracy: 0.8977 - val_loss: 0.3152\n",
            "Epoch 21/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9135 - loss: 0.2833 - val_accuracy: 0.8977 - val_loss: 0.3148\n",
            "Epoch 22/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9161 - loss: 0.2727 - val_accuracy: 0.8977 - val_loss: 0.3140\n",
            "Epoch 23/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9096 - loss: 0.2952 - val_accuracy: 0.8977 - val_loss: 0.3135\n",
            "Epoch 24/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.3254 - val_accuracy: 0.8977 - val_loss: 0.3138\n",
            "Epoch 25/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2692 - val_accuracy: 0.8977 - val_loss: 0.3139\n",
            "Epoch 26/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9260 - loss: 0.2530 - val_accuracy: 0.8977 - val_loss: 0.3134\n",
            "Epoch 27/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2766 - val_accuracy: 0.8977 - val_loss: 0.3129\n",
            "Epoch 28/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9264 - loss: 0.2539 - val_accuracy: 0.8977 - val_loss: 0.3132\n",
            "Epoch 29/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.2928 - val_accuracy: 0.8977 - val_loss: 0.3125\n",
            "Epoch 30/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.2845 - val_accuracy: 0.8977 - val_loss: 0.3131\n",
            "Epoch 31/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.2757 - val_accuracy: 0.8977 - val_loss: 0.3126\n",
            "Epoch 32/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9311 - loss: 0.2429 - val_accuracy: 0.8977 - val_loss: 0.3115\n",
            "Epoch 33/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 0.2680 - val_accuracy: 0.8977 - val_loss: 0.3121\n",
            "Epoch 34/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.2891 - val_accuracy: 0.8977 - val_loss: 0.3123\n",
            "Epoch 35/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9046 - loss: 0.2905 - val_accuracy: 0.8977 - val_loss: 0.3132\n",
            "Epoch 36/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.3078 - val_accuracy: 0.8977 - val_loss: 0.3127\n",
            "Epoch 37/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.2758 - val_accuracy: 0.8977 - val_loss: 0.3133\n",
            "Epoch 38/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.2765 - val_accuracy: 0.8977 - val_loss: 0.3132\n",
            "Epoch 39/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.2899 - val_accuracy: 0.8977 - val_loss: 0.3126\n",
            "Epoch 40/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2607 - val_accuracy: 0.8977 - val_loss: 0.3131\n",
            "Epoch 41/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9135 - loss: 0.2777 - val_accuracy: 0.8977 - val_loss: 0.3135\n",
            "Epoch 42/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9202 - loss: 0.2626 - val_accuracy: 0.8977 - val_loss: 0.3138\n",
            "Model cnn training complete for niche 8.\n",
            "  Final training loss: 0.28681713342666626\n",
            "  Final validation loss: 0.313847154378891\n",
            "  Final training accuracy: 0.9103840589523315\n",
            "  Final validation accuracy: 0.8977272510528564\n",
            "Training model random_forest for niche 8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model mlp_financial for niche 6...\n",
            "Epoch 1/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5337 - loss: 0.8000 - val_accuracy: 0.9085 - val_loss: 0.4897\n",
            "Epoch 2/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.5241 - val_accuracy: 0.9120 - val_loss: 0.3747\n",
            "Epoch 3/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8963 - loss: 0.4211 - val_accuracy: 0.9120 - val_loss: 0.3370\n",
            "Epoch 4/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8790 - loss: 0.4136 - val_accuracy: 0.9120 - val_loss: 0.3270\n",
            "Epoch 5/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.3724 - val_accuracy: 0.9120 - val_loss: 0.3241\n",
            "Epoch 6/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.3746 - val_accuracy: 0.9120 - val_loss: 0.3240\n",
            "Epoch 7/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9231 - loss: 0.3326 - val_accuracy: 0.9120 - val_loss: 0.3229\n",
            "Epoch 8/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.3378 - val_accuracy: 0.9120 - val_loss: 0.3230\n",
            "Epoch 9/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.3396 - val_accuracy: 0.9120 - val_loss: 0.3231\n",
            "Epoch 10/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.3289 - val_accuracy: 0.9120 - val_loss: 0.3218\n",
            "Epoch 11/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.3221 - val_accuracy: 0.9120 - val_loss: 0.3207\n",
            "Epoch 12/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9237 - loss: 0.3199 - val_accuracy: 0.9120 - val_loss: 0.3197\n",
            "Epoch 13/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9211 - loss: 0.3103 - val_accuracy: 0.9120 - val_loss: 0.3192\n",
            "Epoch 14/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9194 - loss: 0.3169 - val_accuracy: 0.9120 - val_loss: 0.3179\n",
            "Epoch 15/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9152 - loss: 0.3473 - val_accuracy: 0.9120 - val_loss: 0.3165\n",
            "Epoch 16/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9150 - loss: 0.3300 - val_accuracy: 0.9120 - val_loss: 0.3158\n",
            "Epoch 17/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.3070 - val_accuracy: 0.9120 - val_loss: 0.3164\n",
            "Epoch 18/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.3243 - val_accuracy: 0.9120 - val_loss: 0.3165\n",
            "Epoch 19/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.3145 - val_accuracy: 0.9120 - val_loss: 0.3171\n",
            "Epoch 20/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2997 - val_accuracy: 0.9120 - val_loss: 0.3160\n",
            "Epoch 21/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2850 - val_accuracy: 0.9120 - val_loss: 0.3162\n",
            "Epoch 22/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.3364 - val_accuracy: 0.9120 - val_loss: 0.3135\n",
            "Epoch 23/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2896 - val_accuracy: 0.9120 - val_loss: 0.3131\n",
            "Epoch 24/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.3087 - val_accuracy: 0.9120 - val_loss: 0.3112\n",
            "Epoch 25/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.3147 - val_accuracy: 0.9120 - val_loss: 0.3121\n",
            "Epoch 26/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9232 - loss: 0.2940 - val_accuracy: 0.9120 - val_loss: 0.3115\n",
            "Epoch 27/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.3189 - val_accuracy: 0.9120 - val_loss: 0.3106\n",
            "Epoch 28/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.2907 - val_accuracy: 0.9120 - val_loss: 0.3109\n",
            "Epoch 29/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.3051 - val_accuracy: 0.9120 - val_loss: 0.3105\n",
            "Epoch 30/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.2716 - val_accuracy: 0.9120 - val_loss: 0.3104\n",
            "Epoch 31/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9231 - loss: 0.2762 - val_accuracy: 0.9120 - val_loss: 0.3094\n",
            "Epoch 32/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.3065 - val_accuracy: 0.9120 - val_loss: 0.3079\n",
            "Epoch 33/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9155 - loss: 0.2818 - val_accuracy: 0.9120 - val_loss: 0.3077\n",
            "Epoch 34/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9226 - loss: 0.2771 - val_accuracy: 0.9120 - val_loss: 0.3071\n",
            "Epoch 35/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.2657 - val_accuracy: 0.9120 - val_loss: 0.3080\n",
            "Epoch 36/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.3359 - val_accuracy: 0.9120 - val_loss: 0.3065\n",
            "Epoch 37/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.3149 - val_accuracy: 0.9120 - val_loss: 0.3061\n",
            "Epoch 38/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2982 - val_accuracy: 0.9120 - val_loss: 0.3069\n",
            "Epoch 39/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9154 - loss: 0.2854 - val_accuracy: 0.9120 - val_loss: 0.3057\n",
            "Epoch 40/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9035 - loss: 0.3289 - val_accuracy: 0.9120 - val_loss: 0.3053\n",
            "Epoch 41/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.2621 - val_accuracy: 0.9120 - val_loss: 0.3053\n",
            "Epoch 42/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2899 - val_accuracy: 0.9120 - val_loss: 0.3045\n",
            "Epoch 43/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.3029 - val_accuracy: 0.9120 - val_loss: 0.3035\n",
            "Epoch 44/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2713 - val_accuracy: 0.9120 - val_loss: 0.3040\n",
            "Epoch 45/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.2581 - val_accuracy: 0.9120 - val_loss: 0.3031\n",
            "Epoch 46/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2954 - val_accuracy: 0.9120 - val_loss: 0.3029\n",
            "Epoch 47/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2809 - val_accuracy: 0.9120 - val_loss: 0.3024\n",
            "Epoch 48/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.2756 - val_accuracy: 0.9120 - val_loss: 0.3027\n",
            "Epoch 49/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.2448 - val_accuracy: 0.9120 - val_loss: 0.3022\n",
            "Epoch 50/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.2996 - val_accuracy: 0.9120 - val_loss: 0.3007\n",
            "Epoch 51/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2847 - val_accuracy: 0.9120 - val_loss: 0.3007\n",
            "Epoch 52/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2793 - val_accuracy: 0.9120 - val_loss: 0.2998\n",
            "Epoch 53/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.2852 - val_accuracy: 0.9120 - val_loss: 0.3002\n",
            "Epoch 54/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.2875 - val_accuracy: 0.9120 - val_loss: 0.3004\n",
            "Epoch 55/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.2832 - val_accuracy: 0.9120 - val_loss: 0.2999\n",
            "Epoch 56/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2792 - val_accuracy: 0.9120 - val_loss: 0.2990\n",
            "Epoch 57/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.2928 - val_accuracy: 0.9120 - val_loss: 0.2986\n",
            "Epoch 58/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2809 - val_accuracy: 0.9120 - val_loss: 0.2987\n",
            "Epoch 59/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2949 - val_accuracy: 0.9120 - val_loss: 0.2979\n",
            "Epoch 60/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.2621 - val_accuracy: 0.9120 - val_loss: 0.2981\n",
            "Epoch 61/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2704 - val_accuracy: 0.9120 - val_loss: 0.2980\n",
            "Epoch 62/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9157 - loss: 0.2792 - val_accuracy: 0.9120 - val_loss: 0.2975\n",
            "Epoch 63/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9200 - loss: 0.2664 - val_accuracy: 0.9120 - val_loss: 0.2972\n",
            "Epoch 64/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.2482 - val_accuracy: 0.9120 - val_loss: 0.2982\n",
            "Epoch 65/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2729 - val_accuracy: 0.9120 - val_loss: 0.2980\n",
            "Epoch 66/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2626 - val_accuracy: 0.9120 - val_loss: 0.2977\n",
            "Epoch 67/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2675 - val_accuracy: 0.9120 - val_loss: 0.2968\n",
            "Epoch 68/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2779 - val_accuracy: 0.9120 - val_loss: 0.2974\n",
            "Epoch 69/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.2488 - val_accuracy: 0.9120 - val_loss: 0.2970\n",
            "Epoch 70/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9111 - loss: 0.2834 - val_accuracy: 0.9120 - val_loss: 0.2962\n",
            "Epoch 71/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9232 - loss: 0.2698 - val_accuracy: 0.9120 - val_loss: 0.2959\n",
            "Epoch 72/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2656 - val_accuracy: 0.9120 - val_loss: 0.2958\n",
            "Epoch 73/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.2627 - val_accuracy: 0.9120 - val_loss: 0.2963\n",
            "Epoch 74/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9081 - loss: 0.2778 - val_accuracy: 0.9120 - val_loss: 0.2958\n",
            "Epoch 75/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2821 - val_accuracy: 0.9120 - val_loss: 0.2956\n",
            "Epoch 76/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2811 - val_accuracy: 0.9120 - val_loss: 0.2952\n",
            "Epoch 77/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.2733 - val_accuracy: 0.9120 - val_loss: 0.2945\n",
            "Epoch 78/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2778 - val_accuracy: 0.9120 - val_loss: 0.2953\n",
            "Epoch 79/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2938 - val_accuracy: 0.9120 - val_loss: 0.2952\n",
            "Epoch 80/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2495 - val_accuracy: 0.9120 - val_loss: 0.2954\n",
            "Epoch 81/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2720 - val_accuracy: 0.9120 - val_loss: 0.2949\n",
            "Epoch 82/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2821 - val_accuracy: 0.9120 - val_loss: 0.2957\n",
            "Epoch 83/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.2643 - val_accuracy: 0.9120 - val_loss: 0.2953\n",
            "Epoch 84/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2799 - val_accuracy: 0.9120 - val_loss: 0.2951\n",
            "Epoch 85/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2771 - val_accuracy: 0.9120 - val_loss: 0.2948\n",
            "Epoch 86/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.2616 - val_accuracy: 0.9120 - val_loss: 0.2958\n",
            "Epoch 87/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2757 - val_accuracy: 0.9120 - val_loss: 0.2958\n",
            "Model mlp_financial training complete for niche 6.\n",
            "  Final training loss: 0.27001097798347473\n",
            "  Final validation loss: 0.29583290219306946\n",
            "  Final training accuracy: 0.917180597782135\n",
            "  Final validation accuracy: 0.9119718074798584\n",
            "Training model mlp_market for niche 6...\n",
            "Epoch 1/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6055 - loss: 0.7439 - val_accuracy: 0.8979 - val_loss: 0.4540\n",
            "Epoch 2/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7592 - loss: 0.5405 - val_accuracy: 0.9120 - val_loss: 0.3661\n",
            "Epoch 3/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.4784 - val_accuracy: 0.9120 - val_loss: 0.3338\n",
            "Epoch 4/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8653 - loss: 0.4369 - val_accuracy: 0.9120 - val_loss: 0.3191\n",
            "Epoch 5/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.4275 - val_accuracy: 0.9120 - val_loss: 0.3132\n",
            "Epoch 6/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8889 - loss: 0.3936 - val_accuracy: 0.9120 - val_loss: 0.3088\n",
            "Epoch 7/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.3724 - val_accuracy: 0.9120 - val_loss: 0.3071\n",
            "Epoch 8/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.3885 - val_accuracy: 0.9120 - val_loss: 0.3052\n",
            "Epoch 9/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.3401 - val_accuracy: 0.9120 - val_loss: 0.3029\n",
            "Epoch 10/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9101 - loss: 0.3797 - val_accuracy: 0.9120 - val_loss: 0.3015\n",
            "Epoch 11/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9204 - loss: 0.3463 - val_accuracy: 0.9120 - val_loss: 0.3008\n",
            "Epoch 12/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.3271 - val_accuracy: 0.9120 - val_loss: 0.3005\n",
            "Epoch 13/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.3474 - val_accuracy: 0.9120 - val_loss: 0.3003\n",
            "Epoch 14/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9282 - loss: 0.3272 - val_accuracy: 0.9120 - val_loss: 0.2995\n",
            "Epoch 15/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.3711 - val_accuracy: 0.9120 - val_loss: 0.2994\n",
            "Epoch 16/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.3197 - val_accuracy: 0.9120 - val_loss: 0.2997\n",
            "Epoch 17/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.3552 - val_accuracy: 0.9120 - val_loss: 0.3004\n",
            "Epoch 18/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.3143 - val_accuracy: 0.9120 - val_loss: 0.3007\n",
            "Epoch 19/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.3451 - val_accuracy: 0.9120 - val_loss: 0.3007\n",
            "Epoch 20/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.3269 - val_accuracy: 0.9120 - val_loss: 0.3023\n",
            "Epoch 21/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.2765 - val_accuracy: 0.9120 - val_loss: 0.3021\n",
            "Epoch 22/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.3869 - val_accuracy: 0.9120 - val_loss: 0.3017\n",
            "Epoch 23/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.3152 - val_accuracy: 0.9120 - val_loss: 0.3018\n",
            "Epoch 24/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9050 - loss: 0.3392 - val_accuracy: 0.9120 - val_loss: 0.3019\n",
            "Epoch 25/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.3035 - val_accuracy: 0.9120 - val_loss: 0.3010\n",
            "Model mlp_market training complete for niche 6.\n",
            "  Final training loss: 0.31029608845710754\n",
            "  Final validation loss: 0.3010155260562897\n",
            "  Final training accuracy: 0.917180597782135\n",
            "  Final validation accuracy: 0.9119718074798584\n",
            "Training model lstm for niche 6...\n",
            "Epoch 1/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7642 - loss: 0.6424 - val_accuracy: 0.9120 - val_loss: 0.5497\n",
            "Epoch 2/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.5022 - val_accuracy: 0.9120 - val_loss: 0.3150\n",
            "Epoch 3/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.3264 - val_accuracy: 0.9120 - val_loss: 0.2903\n",
            "Epoch 4/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9124 - loss: 0.3333 - val_accuracy: 0.9120 - val_loss: 0.2896\n",
            "Epoch 5/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.3346 - val_accuracy: 0.9120 - val_loss: 0.2892\n",
            "Epoch 6/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9214 - loss: 0.3098 - val_accuracy: 0.9120 - val_loss: 0.2865\n",
            "Epoch 7/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.3065 - val_accuracy: 0.9120 - val_loss: 0.2859\n",
            "Epoch 8/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9300 - loss: 0.2802 - val_accuracy: 0.9120 - val_loss: 0.2848\n",
            "Epoch 9/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9209 - loss: 0.3070 - val_accuracy: 0.9120 - val_loss: 0.2836\n",
            "Epoch 10/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9141 - loss: 0.3179 - val_accuracy: 0.9120 - val_loss: 0.2840\n",
            "Epoch 11/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9246 - loss: 0.2825 - val_accuracy: 0.9120 - val_loss: 0.2824\n",
            "Epoch 12/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9074 - loss: 0.3311 - val_accuracy: 0.9120 - val_loss: 0.2845\n",
            "Epoch 13/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9197 - loss: 0.3029 - val_accuracy: 0.9120 - val_loss: 0.2835\n",
            "Epoch 14/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9251 - loss: 0.2988 - val_accuracy: 0.9120 - val_loss: 0.2820\n",
            "Epoch 15/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9092 - loss: 0.3351 - val_accuracy: 0.9120 - val_loss: 0.2814\n",
            "Epoch 16/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9225 - loss: 0.2758 - val_accuracy: 0.9120 - val_loss: 0.2807\n",
            "Epoch 17/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9106 - loss: 0.3092 - val_accuracy: 0.9120 - val_loss: 0.2806\n",
            "Epoch 18/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.2919 - val_accuracy: 0.9120 - val_loss: 0.2797\n",
            "Epoch 19/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9029 - loss: 0.3228 - val_accuracy: 0.9120 - val_loss: 0.2811\n",
            "Epoch 20/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.3323 - val_accuracy: 0.9120 - val_loss: 0.2793\n",
            "Epoch 21/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.2794 - val_accuracy: 0.9120 - val_loss: 0.2784\n",
            "Epoch 22/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.2709 - val_accuracy: 0.9120 - val_loss: 0.2777\n",
            "Epoch 23/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9168 - loss: 0.2943 - val_accuracy: 0.9120 - val_loss: 0.2780\n",
            "Epoch 24/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9287 - loss: 0.2719 - val_accuracy: 0.9120 - val_loss: 0.2784\n",
            "Epoch 25/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.3365 - val_accuracy: 0.9120 - val_loss: 0.2774\n",
            "Epoch 26/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8959 - loss: 0.3396 - val_accuracy: 0.9120 - val_loss: 0.2777\n",
            "Epoch 27/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9220 - loss: 0.2850 - val_accuracy: 0.9120 - val_loss: 0.2775\n",
            "Epoch 28/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.2978 - val_accuracy: 0.9120 - val_loss: 0.2786\n",
            "Epoch 29/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9093 - loss: 0.3175 - val_accuracy: 0.9120 - val_loss: 0.2770\n",
            "Epoch 30/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9123 - loss: 0.2717 - val_accuracy: 0.9120 - val_loss: 0.2771\n",
            "Epoch 31/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9174 - loss: 0.2920 - val_accuracy: 0.9120 - val_loss: 0.2767\n",
            "Epoch 32/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9209 - loss: 0.2855 - val_accuracy: 0.9120 - val_loss: 0.2774\n",
            "Epoch 33/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.2996 - val_accuracy: 0.9120 - val_loss: 0.2770\n",
            "Epoch 34/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9176 - loss: 0.2822 - val_accuracy: 0.9120 - val_loss: 0.2763\n",
            "Epoch 35/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9097 - loss: 0.3069 - val_accuracy: 0.9120 - val_loss: 0.2769\n",
            "Epoch 36/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.2827 - val_accuracy: 0.9120 - val_loss: 0.2761\n",
            "Epoch 37/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9255 - loss: 0.2477 - val_accuracy: 0.9120 - val_loss: 0.2760\n",
            "Epoch 38/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9091 - loss: 0.3039 - val_accuracy: 0.9120 - val_loss: 0.2758\n",
            "Epoch 39/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9236 - loss: 0.2781 - val_accuracy: 0.9120 - val_loss: 0.2754\n",
            "Epoch 40/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9035 - loss: 0.3087 - val_accuracy: 0.9120 - val_loss: 0.2752\n",
            "Epoch 41/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9286 - loss: 0.2583 - val_accuracy: 0.9120 - val_loss: 0.2754\n",
            "Epoch 42/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.2674 - val_accuracy: 0.9120 - val_loss: 0.2753\n",
            "Epoch 43/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9033 - loss: 0.3085 - val_accuracy: 0.9120 - val_loss: 0.2757\n",
            "Epoch 44/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9119 - loss: 0.2942 - val_accuracy: 0.9120 - val_loss: 0.2750\n",
            "Epoch 45/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9289 - loss: 0.2585 - val_accuracy: 0.9120 - val_loss: 0.2750\n",
            "Epoch 46/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9202 - loss: 0.3034 - val_accuracy: 0.9120 - val_loss: 0.2751\n",
            "Epoch 47/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9104 - loss: 0.3051 - val_accuracy: 0.9120 - val_loss: 0.2746\n",
            "Epoch 48/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9125 - loss: 0.2943 - val_accuracy: 0.9120 - val_loss: 0.2742\n",
            "Epoch 49/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.2725 - val_accuracy: 0.9120 - val_loss: 0.2744\n",
            "Epoch 50/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9181 - loss: 0.2825 - val_accuracy: 0.9120 - val_loss: 0.2743\n",
            "Epoch 51/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.3184 - val_accuracy: 0.9120 - val_loss: 0.2765\n",
            "Epoch 52/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9166 - loss: 0.2871 - val_accuracy: 0.9120 - val_loss: 0.2749\n",
            "Epoch 53/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9189 - loss: 0.2924 - val_accuracy: 0.9120 - val_loss: 0.2747\n",
            "Epoch 54/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9112 - loss: 0.2946 - val_accuracy: 0.9120 - val_loss: 0.2751\n",
            "Epoch 55/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9100 - loss: 0.3018 - val_accuracy: 0.9120 - val_loss: 0.2737\n",
            "Epoch 56/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9255 - loss: 0.2540 - val_accuracy: 0.9120 - val_loss: 0.2745\n",
            "Epoch 57/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9120 - loss: 0.2986 - val_accuracy: 0.9120 - val_loss: 0.2737\n",
            "Epoch 58/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9243 - loss: 0.2787 - val_accuracy: 0.9120 - val_loss: 0.2728\n",
            "Epoch 59/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9194 - loss: 0.2807 - val_accuracy: 0.9120 - val_loss: 0.2739\n",
            "Epoch 60/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9071 - loss: 0.2927 - val_accuracy: 0.9120 - val_loss: 0.2742\n",
            "Epoch 61/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9152 - loss: 0.2559 - val_accuracy: 0.9120 - val_loss: 0.2734\n",
            "Epoch 62/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9186 - loss: 0.2854 - val_accuracy: 0.9120 - val_loss: 0.2733\n",
            "Epoch 63/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.2623 - val_accuracy: 0.9120 - val_loss: 0.2731\n",
            "Epoch 64/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9138 - loss: 0.3032 - val_accuracy: 0.9120 - val_loss: 0.2740\n",
            "Epoch 65/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9134 - loss: 0.2955 - val_accuracy: 0.9120 - val_loss: 0.2745\n",
            "Epoch 66/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 0.2818 - val_accuracy: 0.9120 - val_loss: 0.2757\n",
            "Epoch 67/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9308 - loss: 0.2355 - val_accuracy: 0.9120 - val_loss: 0.2735\n",
            "Epoch 68/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9111 - loss: 0.2759 - val_accuracy: 0.9120 - val_loss: 0.2736\n",
            "Model lstm training complete for niche 6.\n",
            "  Final training loss: 0.27231544256210327\n",
            "  Final validation loss: 0.2736116051673889\n",
            "  Final training accuracy: 0.917180597782135\n",
            "  Final validation accuracy: 0.9119718074798584\n",
            "Training model cnn for niche 6...\n",
            "Epoch 1/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4591 - loss: 0.7415 - val_accuracy: 0.8768 - val_loss: 0.5368\n",
            "Epoch 2/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.5029 - val_accuracy: 0.9120 - val_loss: 0.3798\n",
            "Epoch 3/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.3790 - val_accuracy: 0.9120 - val_loss: 0.3084\n",
            "Epoch 4/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9192 - loss: 0.3090 - val_accuracy: 0.9120 - val_loss: 0.2831\n",
            "Epoch 5/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9083 - loss: 0.3125 - val_accuracy: 0.9120 - val_loss: 0.2776\n",
            "Epoch 6/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.3394 - val_accuracy: 0.9120 - val_loss: 0.2762\n",
            "Epoch 7/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9092 - loss: 0.3111 - val_accuracy: 0.9120 - val_loss: 0.2754\n",
            "Epoch 8/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9147 - loss: 0.2835 - val_accuracy: 0.9120 - val_loss: 0.2746\n",
            "Epoch 9/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.2921 - val_accuracy: 0.9120 - val_loss: 0.2741\n",
            "Epoch 10/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9138 - loss: 0.2978 - val_accuracy: 0.9120 - val_loss: 0.2733\n",
            "Epoch 11/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9204 - loss: 0.2705 - val_accuracy: 0.9120 - val_loss: 0.2727\n",
            "Epoch 12/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9158 - loss: 0.2830 - val_accuracy: 0.9120 - val_loss: 0.2717\n",
            "Epoch 13/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9303 - loss: 0.2369 - val_accuracy: 0.9120 - val_loss: 0.2716\n",
            "Epoch 14/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.2962 - val_accuracy: 0.9120 - val_loss: 0.2709\n",
            "Epoch 15/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9218 - loss: 0.2719 - val_accuracy: 0.9120 - val_loss: 0.2707\n",
            "Epoch 16/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9190 - loss: 0.2749 - val_accuracy: 0.9120 - val_loss: 0.2706\n",
            "Epoch 17/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2877 - val_accuracy: 0.9120 - val_loss: 0.2705\n",
            "Epoch 18/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.2602 - val_accuracy: 0.9120 - val_loss: 0.2702\n",
            "Epoch 19/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2939 - val_accuracy: 0.9120 - val_loss: 0.2703\n",
            "Epoch 20/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9112 - loss: 0.2840 - val_accuracy: 0.9120 - val_loss: 0.2699\n",
            "Epoch 21/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2753 - val_accuracy: 0.9120 - val_loss: 0.2703\n",
            "Epoch 22/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.2979 - val_accuracy: 0.9120 - val_loss: 0.2695\n",
            "Epoch 23/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9227 - loss: 0.2755 - val_accuracy: 0.9120 - val_loss: 0.2694\n",
            "Epoch 24/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2782 - val_accuracy: 0.9120 - val_loss: 0.2697\n",
            "Epoch 25/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9254 - loss: 0.2487 - val_accuracy: 0.9120 - val_loss: 0.2699\n",
            "Epoch 26/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.2530 - val_accuracy: 0.9120 - val_loss: 0.2693\n",
            "Epoch 27/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9283 - loss: 0.2510 - val_accuracy: 0.9120 - val_loss: 0.2692\n",
            "Epoch 28/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9236 - loss: 0.2505 - val_accuracy: 0.9120 - val_loss: 0.2692\n",
            "Epoch 29/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9297 - loss: 0.2369 - val_accuracy: 0.9120 - val_loss: 0.2696\n",
            "Epoch 30/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2694 - val_accuracy: 0.9120 - val_loss: 0.2688\n",
            "Epoch 31/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2748 - val_accuracy: 0.9120 - val_loss: 0.2693\n",
            "Epoch 32/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2859 - val_accuracy: 0.9120 - val_loss: 0.2693\n",
            "Epoch 33/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2635 - val_accuracy: 0.9120 - val_loss: 0.2690\n",
            "Epoch 34/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.2231 - val_accuracy: 0.9120 - val_loss: 0.2686\n",
            "Epoch 35/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2512 - val_accuracy: 0.9120 - val_loss: 0.2683\n",
            "Epoch 36/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2845 - val_accuracy: 0.9120 - val_loss: 0.2691\n",
            "Epoch 37/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2531 - val_accuracy: 0.9120 - val_loss: 0.2693\n",
            "Epoch 38/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2538 - val_accuracy: 0.9120 - val_loss: 0.2692\n",
            "Epoch 39/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9299 - loss: 0.2501 - val_accuracy: 0.9120 - val_loss: 0.2689\n",
            "Epoch 40/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9265 - loss: 0.2421 - val_accuracy: 0.9120 - val_loss: 0.2685\n",
            "Epoch 41/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.2288 - val_accuracy: 0.9120 - val_loss: 0.2687\n",
            "Epoch 42/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9087 - loss: 0.2645 - val_accuracy: 0.9120 - val_loss: 0.2685\n",
            "Epoch 43/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8998 - loss: 0.2990 - val_accuracy: 0.9120 - val_loss: 0.2690\n",
            "Epoch 44/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9041 - loss: 0.2919 - val_accuracy: 0.9120 - val_loss: 0.2686\n",
            "Epoch 45/1000\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2653 - val_accuracy: 0.9120 - val_loss: 0.2692\n",
            "Model cnn training complete for niche 6.\n",
            "  Final training loss: 0.2622640132904053\n",
            "  Final validation loss: 0.269203782081604\n",
            "  Final training accuracy: 0.917180597782135\n",
            "  Final validation accuracy: 0.9119718074798584\n",
            "Training model random_forest for niche 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model mlp_financial for niche 2...\n",
            "Epoch 1/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.2236 - loss: 1.3119 - val_accuracy: 0.2535 - val_loss: 0.8401\n",
            "Epoch 2/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3733 - loss: 1.0211 - val_accuracy: 0.8169 - val_loss: 0.6552\n",
            "Epoch 3/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6585 - loss: 0.7166 - val_accuracy: 0.9296 - val_loss: 0.5492\n",
            "Epoch 4/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7383 - loss: 0.6228 - val_accuracy: 0.9296 - val_loss: 0.4681\n",
            "Epoch 5/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8021 - loss: 0.5125 - val_accuracy: 0.9296 - val_loss: 0.4114\n",
            "Epoch 6/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8630 - loss: 0.4491 - val_accuracy: 0.9296 - val_loss: 0.3751\n",
            "Epoch 7/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8886 - loss: 0.4297 - val_accuracy: 0.9296 - val_loss: 0.3522\n",
            "Epoch 8/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.3589 - val_accuracy: 0.9296 - val_loss: 0.3371\n",
            "Epoch 9/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9189 - loss: 0.3775 - val_accuracy: 0.9296 - val_loss: 0.3292\n",
            "Epoch 10/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9057 - loss: 0.3645 - val_accuracy: 0.9296 - val_loss: 0.3262\n",
            "Epoch 11/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9293 - loss: 0.3051 - val_accuracy: 0.9296 - val_loss: 0.3251\n",
            "Epoch 12/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 0.3543 - val_accuracy: 0.9296 - val_loss: 0.3243\n",
            "Epoch 13/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9338 - loss: 0.3475 - val_accuracy: 0.9296 - val_loss: 0.3235\n",
            "Epoch 14/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9338 - loss: 0.2942 - val_accuracy: 0.9296 - val_loss: 0.3230\n",
            "Epoch 15/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9396 - loss: 0.3282 - val_accuracy: 0.9296 - val_loss: 0.3229\n",
            "Epoch 16/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9224 - loss: 0.3174 - val_accuracy: 0.9296 - val_loss: 0.3221\n",
            "Epoch 17/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.2667 - val_accuracy: 0.9296 - val_loss: 0.3235\n",
            "Epoch 18/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9430 - loss: 0.3175 - val_accuracy: 0.9296 - val_loss: 0.3188\n",
            "Epoch 19/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9330 - loss: 0.3012 - val_accuracy: 0.9296 - val_loss: 0.3160\n",
            "Epoch 20/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9287 - loss: 0.3337 - val_accuracy: 0.9296 - val_loss: 0.3127\n",
            "Epoch 21/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.2778 - val_accuracy: 0.9296 - val_loss: 0.3122\n",
            "Epoch 22/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9380 - loss: 0.2971 - val_accuracy: 0.9296 - val_loss: 0.3119\n",
            "Epoch 23/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9411 - loss: 0.2858 - val_accuracy: 0.9296 - val_loss: 0.3094\n",
            "Epoch 24/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9544 - loss: 0.2470 - val_accuracy: 0.9296 - val_loss: 0.3105\n",
            "Epoch 25/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9426 - loss: 0.3125 - val_accuracy: 0.9296 - val_loss: 0.3059\n",
            "Epoch 26/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9358 - loss: 0.2982 - val_accuracy: 0.9296 - val_loss: 0.3043\n",
            "Epoch 27/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9198 - loss: 0.3654 - val_accuracy: 0.9296 - val_loss: 0.3009\n",
            "Epoch 28/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9335 - loss: 0.3044 - val_accuracy: 0.9296 - val_loss: 0.3026\n",
            "Epoch 29/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.2676 - val_accuracy: 0.9296 - val_loss: 0.3033\n",
            "Epoch 30/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.3160 - val_accuracy: 0.9296 - val_loss: 0.3010\n",
            "Epoch 31/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9325 - loss: 0.2784 - val_accuracy: 0.9296 - val_loss: 0.2982\n",
            "Epoch 32/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.2892 - val_accuracy: 0.9296 - val_loss: 0.2998\n",
            "Epoch 33/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.2586 - val_accuracy: 0.9296 - val_loss: 0.2996\n",
            "Epoch 34/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.2392 - val_accuracy: 0.9296 - val_loss: 0.2981\n",
            "Epoch 35/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.2785 - val_accuracy: 0.9296 - val_loss: 0.2980\n",
            "Epoch 36/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9270 - loss: 0.3138 - val_accuracy: 0.9296 - val_loss: 0.2940\n",
            "Epoch 37/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.2484 - val_accuracy: 0.9296 - val_loss: 0.2943\n",
            "Epoch 38/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.2667 - val_accuracy: 0.9296 - val_loss: 0.2940\n",
            "Epoch 39/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9216 - loss: 0.2981 - val_accuracy: 0.9296 - val_loss: 0.2949\n",
            "Epoch 40/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.2503 - val_accuracy: 0.9296 - val_loss: 0.2957\n",
            "Epoch 41/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9454 - loss: 0.2351 - val_accuracy: 0.9296 - val_loss: 0.2959\n",
            "Epoch 42/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.2271 - val_accuracy: 0.9296 - val_loss: 0.2947\n",
            "Epoch 43/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9441 - loss: 0.2523 - val_accuracy: 0.9296 - val_loss: 0.2916\n",
            "Epoch 44/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.2511 - val_accuracy: 0.9296 - val_loss: 0.2907\n",
            "Epoch 45/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9326 - loss: 0.2897 - val_accuracy: 0.9296 - val_loss: 0.2885\n",
            "Epoch 46/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.2385 - val_accuracy: 0.9296 - val_loss: 0.2890\n",
            "Epoch 47/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.2564 - val_accuracy: 0.9296 - val_loss: 0.2876\n",
            "Epoch 48/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.2501 - val_accuracy: 0.9296 - val_loss: 0.2884\n",
            "Epoch 49/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9232 - loss: 0.2814 - val_accuracy: 0.9296 - val_loss: 0.2908\n",
            "Epoch 50/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9282 - loss: 0.3060 - val_accuracy: 0.9296 - val_loss: 0.2904\n",
            "Epoch 51/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.2756 - val_accuracy: 0.9296 - val_loss: 0.2905\n",
            "Epoch 52/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9256 - loss: 0.2936 - val_accuracy: 0.9296 - val_loss: 0.2881\n",
            "Epoch 53/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.3016 - val_accuracy: 0.9296 - val_loss: 0.2885\n",
            "Epoch 54/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.2557 - val_accuracy: 0.9296 - val_loss: 0.2889\n",
            "Epoch 55/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.2153 - val_accuracy: 0.9296 - val_loss: 0.2901\n",
            "Epoch 56/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.2886 - val_accuracy: 0.9296 - val_loss: 0.2876\n",
            "Epoch 57/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9346 - loss: 0.2806 - val_accuracy: 0.9296 - val_loss: 0.2837\n",
            "Epoch 58/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9395 - loss: 0.2511 - val_accuracy: 0.9296 - val_loss: 0.2824\n",
            "Epoch 59/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.2366 - val_accuracy: 0.9296 - val_loss: 0.2822\n",
            "Epoch 60/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9476 - loss: 0.2014 - val_accuracy: 0.9296 - val_loss: 0.2844\n",
            "Epoch 61/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.2305 - val_accuracy: 0.9296 - val_loss: 0.2849\n",
            "Epoch 62/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.2736 - val_accuracy: 0.9296 - val_loss: 0.2860\n",
            "Epoch 63/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.2692 - val_accuracy: 0.9296 - val_loss: 0.2832\n",
            "Epoch 64/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9254 - loss: 0.3033 - val_accuracy: 0.9296 - val_loss: 0.2819\n",
            "Epoch 65/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.3393 - val_accuracy: 0.9296 - val_loss: 0.2783\n",
            "Epoch 66/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9438 - loss: 0.2683 - val_accuracy: 0.9296 - val_loss: 0.2775\n",
            "Epoch 67/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9386 - loss: 0.2589 - val_accuracy: 0.9296 - val_loss: 0.2777\n",
            "Epoch 68/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9429 - loss: 0.2939 - val_accuracy: 0.9296 - val_loss: 0.2777\n",
            "Epoch 69/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.2617 - val_accuracy: 0.9296 - val_loss: 0.2776\n",
            "Epoch 70/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.2481 - val_accuracy: 0.9296 - val_loss: 0.2769\n",
            "Epoch 71/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.2682 - val_accuracy: 0.9296 - val_loss: 0.2751\n",
            "Epoch 72/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.2651 - val_accuracy: 0.9296 - val_loss: 0.2744\n",
            "Epoch 73/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.2256 - val_accuracy: 0.9296 - val_loss: 0.2755\n",
            "Epoch 74/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9342 - loss: 0.2491 - val_accuracy: 0.9296 - val_loss: 0.2756\n",
            "Epoch 75/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9290 - loss: 0.2876 - val_accuracy: 0.9296 - val_loss: 0.2747\n",
            "Epoch 76/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2590 - val_accuracy: 0.9296 - val_loss: 0.2776\n",
            "Epoch 77/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9392 - loss: 0.2282 - val_accuracy: 0.9296 - val_loss: 0.2780\n",
            "Epoch 78/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.2466 - val_accuracy: 0.9296 - val_loss: 0.2763\n",
            "Epoch 79/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.2252 - val_accuracy: 0.9296 - val_loss: 0.2757\n",
            "Epoch 80/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.2170 - val_accuracy: 0.9296 - val_loss: 0.2773\n",
            "Epoch 81/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.2537 - val_accuracy: 0.9296 - val_loss: 0.2762\n",
            "Epoch 82/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9399 - loss: 0.2438 - val_accuracy: 0.9296 - val_loss: 0.2772\n",
            "Model mlp_financial training complete for niche 2.\n",
            "  Final training loss: 0.23640787601470947\n",
            "  Final validation loss: 0.2771787643432617\n",
            "  Final training accuracy: 0.9414893388748169\n",
            "  Final validation accuracy: 0.9295774698257446\n",
            "Training model mlp_market for niche 2...\n",
            "Epoch 1/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4221 - loss: 0.9204 - val_accuracy: 0.8803 - val_loss: 0.5927\n",
            "Epoch 2/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5940 - loss: 0.7470 - val_accuracy: 0.9225 - val_loss: 0.4958\n",
            "Epoch 3/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6610 - loss: 0.6432 - val_accuracy: 0.9225 - val_loss: 0.4353\n",
            "Epoch 4/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7811 - loss: 0.5413 - val_accuracy: 0.9225 - val_loss: 0.3947\n",
            "Epoch 5/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8186 - loss: 0.4976 - val_accuracy: 0.9296 - val_loss: 0.3643\n",
            "Epoch 6/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8616 - loss: 0.4678 - val_accuracy: 0.9296 - val_loss: 0.3407\n",
            "Epoch 7/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8825 - loss: 0.4334 - val_accuracy: 0.9296 - val_loss: 0.3232\n",
            "Epoch 8/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8964 - loss: 0.3956 - val_accuracy: 0.9296 - val_loss: 0.3105\n",
            "Epoch 9/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.3472 - val_accuracy: 0.9296 - val_loss: 0.3014\n",
            "Epoch 10/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9089 - loss: 0.3743 - val_accuracy: 0.9296 - val_loss: 0.2977\n",
            "Epoch 11/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9172 - loss: 0.3410 - val_accuracy: 0.9296 - val_loss: 0.2966\n",
            "Epoch 12/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.2933 - val_accuracy: 0.9296 - val_loss: 0.2957\n",
            "Epoch 13/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.3594 - val_accuracy: 0.9296 - val_loss: 0.2943\n",
            "Epoch 14/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9425 - loss: 0.3229 - val_accuracy: 0.9296 - val_loss: 0.2940\n",
            "Epoch 15/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9311 - loss: 0.3404 - val_accuracy: 0.9296 - val_loss: 0.2934\n",
            "Epoch 16/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9150 - loss: 0.3389 - val_accuracy: 0.9296 - val_loss: 0.2932\n",
            "Epoch 17/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.3082 - val_accuracy: 0.9296 - val_loss: 0.2938\n",
            "Epoch 18/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9538 - loss: 0.2660 - val_accuracy: 0.9296 - val_loss: 0.2928\n",
            "Epoch 19/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9385 - loss: 0.3205 - val_accuracy: 0.9296 - val_loss: 0.2908\n",
            "Epoch 20/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.2593 - val_accuracy: 0.9296 - val_loss: 0.2888\n",
            "Epoch 21/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9311 - loss: 0.3880 - val_accuracy: 0.9296 - val_loss: 0.2853\n",
            "Epoch 22/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9463 - loss: 0.2567 - val_accuracy: 0.9296 - val_loss: 0.2870\n",
            "Epoch 23/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.2797 - val_accuracy: 0.9296 - val_loss: 0.2899\n",
            "Epoch 24/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9312 - loss: 0.3586 - val_accuracy: 0.9296 - val_loss: 0.2865\n",
            "Epoch 25/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9298 - loss: 0.3444 - val_accuracy: 0.9296 - val_loss: 0.2848\n",
            "Epoch 26/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9339 - loss: 0.3097 - val_accuracy: 0.9296 - val_loss: 0.2840\n",
            "Epoch 27/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9344 - loss: 0.3081 - val_accuracy: 0.9296 - val_loss: 0.2849\n",
            "Epoch 28/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.2922 - val_accuracy: 0.9296 - val_loss: 0.2861\n",
            "Epoch 29/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9305 - loss: 0.3370 - val_accuracy: 0.9296 - val_loss: 0.2838\n",
            "Epoch 30/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9536 - loss: 0.2511 - val_accuracy: 0.9296 - val_loss: 0.2840\n",
            "Epoch 31/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9374 - loss: 0.2926 - val_accuracy: 0.9296 - val_loss: 0.2833\n",
            "Epoch 32/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9381 - loss: 0.3195 - val_accuracy: 0.9296 - val_loss: 0.2802\n",
            "Epoch 33/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.2971 - val_accuracy: 0.9296 - val_loss: 0.2776\n",
            "Epoch 34/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9429 - loss: 0.2659 - val_accuracy: 0.9296 - val_loss: 0.2782\n",
            "Epoch 35/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.2580 - val_accuracy: 0.9296 - val_loss: 0.2793\n",
            "Epoch 36/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9527 - loss: 0.2363 - val_accuracy: 0.9296 - val_loss: 0.2803\n",
            "Epoch 37/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9523 - loss: 0.2571 - val_accuracy: 0.9296 - val_loss: 0.2824\n",
            "Epoch 38/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9388 - loss: 0.3118 - val_accuracy: 0.9296 - val_loss: 0.2796\n",
            "Epoch 39/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.2716 - val_accuracy: 0.9296 - val_loss: 0.2798\n",
            "Epoch 40/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.2570 - val_accuracy: 0.9296 - val_loss: 0.2795\n",
            "Epoch 41/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.2496 - val_accuracy: 0.9296 - val_loss: 0.2783\n",
            "Epoch 42/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.2889 - val_accuracy: 0.9296 - val_loss: 0.2783\n",
            "Epoch 43/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.2890 - val_accuracy: 0.9296 - val_loss: 0.2783\n",
            "Model mlp_market training complete for niche 2.\n",
            "  Final training loss: 0.2621915936470032\n",
            "  Final validation loss: 0.2782925069332123\n",
            "  Final training accuracy: 0.9414893388748169\n",
            "  Final validation accuracy: 0.9295774698257446\n",
            "Training model lstm for niche 2...\n",
            "Epoch 1/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.3317 - loss: 0.7293 - val_accuracy: 0.6549 - val_loss: 0.6811\n",
            "Epoch 2/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7115 - loss: 0.6632 - val_accuracy: 0.9296 - val_loss: 0.6054\n",
            "Epoch 3/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9121 - loss: 0.5774 - val_accuracy: 0.9296 - val_loss: 0.4877\n",
            "Epoch 4/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.4533 - val_accuracy: 0.9296 - val_loss: 0.2914\n",
            "Epoch 5/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9412 - loss: 0.2839 - val_accuracy: 0.9296 - val_loss: 0.2597\n",
            "Epoch 6/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.2655 - val_accuracy: 0.9296 - val_loss: 0.2520\n",
            "Epoch 7/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9325 - loss: 0.3243 - val_accuracy: 0.9296 - val_loss: 0.2500\n",
            "Epoch 8/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.2329 - val_accuracy: 0.9296 - val_loss: 0.2517\n",
            "Epoch 9/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9405 - loss: 0.2679 - val_accuracy: 0.9296 - val_loss: 0.2501\n",
            "Epoch 10/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.2631 - val_accuracy: 0.9296 - val_loss: 0.2530\n",
            "Epoch 11/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9463 - loss: 0.2606 - val_accuracy: 0.9296 - val_loss: 0.2509\n",
            "Epoch 12/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9409 - loss: 0.2446 - val_accuracy: 0.9296 - val_loss: 0.2522\n",
            "Epoch 13/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9382 - loss: 0.2596 - val_accuracy: 0.9296 - val_loss: 0.2520\n",
            "Epoch 14/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9443 - loss: 0.2381 - val_accuracy: 0.9296 - val_loss: 0.2516\n",
            "Epoch 15/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.2363 - val_accuracy: 0.9296 - val_loss: 0.2516\n",
            "Epoch 16/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9400 - loss: 0.2444 - val_accuracy: 0.9296 - val_loss: 0.2529\n",
            "Epoch 17/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.2066 - val_accuracy: 0.9296 - val_loss: 0.2526\n",
            "Model lstm training complete for niche 2.\n",
            "  Final training loss: 0.24130527675151825\n",
            "  Final validation loss: 0.2525542676448822\n",
            "  Final training accuracy: 0.9414893388748169\n",
            "  Final validation accuracy: 0.9295774698257446\n",
            "Training model cnn for niche 2...\n",
            "Epoch 1/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5748 - loss: 0.6890 - val_accuracy: 0.8873 - val_loss: 0.5493\n",
            "Epoch 2/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7676 - loss: 0.5488 - val_accuracy: 0.9225 - val_loss: 0.4390\n",
            "Epoch 3/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8816 - loss: 0.4555 - val_accuracy: 0.9296 - val_loss: 0.3663\n",
            "Epoch 4/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9372 - loss: 0.3771 - val_accuracy: 0.9296 - val_loss: 0.3194\n",
            "Epoch 5/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.3375 - val_accuracy: 0.9296 - val_loss: 0.2917\n",
            "Epoch 6/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.3103 - val_accuracy: 0.9296 - val_loss: 0.2773\n",
            "Epoch 7/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9347 - loss: 0.2925 - val_accuracy: 0.9296 - val_loss: 0.2698\n",
            "Epoch 8/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9413 - loss: 0.2520 - val_accuracy: 0.9296 - val_loss: 0.2672\n",
            "Epoch 9/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9505 - loss: 0.2312 - val_accuracy: 0.9296 - val_loss: 0.2668\n",
            "Epoch 10/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.2700 - val_accuracy: 0.9296 - val_loss: 0.2671\n",
            "Epoch 11/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.2813 - val_accuracy: 0.9296 - val_loss: 0.2677\n",
            "Epoch 12/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9436 - loss: 0.2116 - val_accuracy: 0.9296 - val_loss: 0.2689\n",
            "Epoch 13/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9542 - loss: 0.2102 - val_accuracy: 0.9296 - val_loss: 0.2692\n",
            "Epoch 14/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9412 - loss: 0.2387 - val_accuracy: 0.9296 - val_loss: 0.2685\n",
            "Epoch 15/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.2600 - val_accuracy: 0.9296 - val_loss: 0.2687\n",
            "Epoch 16/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.2443 - val_accuracy: 0.9296 - val_loss: 0.2679\n",
            "Epoch 17/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9468 - loss: 0.2367 - val_accuracy: 0.9296 - val_loss: 0.2679\n",
            "Epoch 18/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.2159 - val_accuracy: 0.9296 - val_loss: 0.2673\n",
            "Epoch 19/1000\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 0.2197 - val_accuracy: 0.9296 - val_loss: 0.2673\n",
            "Model cnn training complete for niche 2.\n",
            "  Final training loss: 0.22536717355251312\n",
            "  Final validation loss: 0.2672853171825409\n",
            "  Final training accuracy: 0.9414893388748169\n",
            "  Final validation accuracy: 0.9295774698257446\n",
            "Training model random_forest for niche 2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model mlp_financial for niche 0...\n",
            "Epoch 1/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5194 - loss: 0.8110 - val_accuracy: 0.9018 - val_loss: 0.5114\n",
            "Epoch 2/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7588 - loss: 0.5756 - val_accuracy: 0.9055 - val_loss: 0.3928\n",
            "Epoch 3/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.4637 - val_accuracy: 0.9055 - val_loss: 0.3487\n",
            "Epoch 4/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.4329 - val_accuracy: 0.9055 - val_loss: 0.3347\n",
            "Epoch 5/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.4199 - val_accuracy: 0.9055 - val_loss: 0.3260\n",
            "Epoch 6/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8823 - loss: 0.4421 - val_accuracy: 0.9055 - val_loss: 0.3199\n",
            "Epoch 7/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.3719 - val_accuracy: 0.9055 - val_loss: 0.3160\n",
            "Epoch 8/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.4029 - val_accuracy: 0.9055 - val_loss: 0.3147\n",
            "Epoch 9/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9011 - loss: 0.3785 - val_accuracy: 0.9055 - val_loss: 0.3127\n",
            "Epoch 10/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.3451 - val_accuracy: 0.9055 - val_loss: 0.3107\n",
            "Epoch 11/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.3593 - val_accuracy: 0.9055 - val_loss: 0.3091\n",
            "Epoch 12/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.3726 - val_accuracy: 0.9055 - val_loss: 0.3076\n",
            "Epoch 13/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9145 - loss: 0.3328 - val_accuracy: 0.9055 - val_loss: 0.3062\n",
            "Epoch 14/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.3160 - val_accuracy: 0.9055 - val_loss: 0.3051\n",
            "Epoch 15/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.2938 - val_accuracy: 0.9055 - val_loss: 0.3056\n",
            "Epoch 16/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.3419 - val_accuracy: 0.9055 - val_loss: 0.3053\n",
            "Epoch 17/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9186 - loss: 0.3314 - val_accuracy: 0.9055 - val_loss: 0.3038\n",
            "Epoch 18/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8991 - loss: 0.3628 - val_accuracy: 0.9055 - val_loss: 0.3025\n",
            "Epoch 19/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.3588 - val_accuracy: 0.9055 - val_loss: 0.3004\n",
            "Epoch 20/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.3830 - val_accuracy: 0.9055 - val_loss: 0.2991\n",
            "Epoch 21/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9160 - loss: 0.3119 - val_accuracy: 0.9055 - val_loss: 0.2978\n",
            "Epoch 22/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.3295 - val_accuracy: 0.9055 - val_loss: 0.2975\n",
            "Epoch 23/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9219 - loss: 0.3149 - val_accuracy: 0.9055 - val_loss: 0.2970\n",
            "Epoch 24/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9089 - loss: 0.3346 - val_accuracy: 0.9055 - val_loss: 0.2967\n",
            "Epoch 25/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9098 - loss: 0.3030 - val_accuracy: 0.9055 - val_loss: 0.2952\n",
            "Epoch 26/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9112 - loss: 0.3055 - val_accuracy: 0.9055 - val_loss: 0.2940\n",
            "Epoch 27/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9034 - loss: 0.3432 - val_accuracy: 0.9055 - val_loss: 0.2938\n",
            "Epoch 28/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9223 - loss: 0.2928 - val_accuracy: 0.9055 - val_loss: 0.2938\n",
            "Epoch 29/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.3113 - val_accuracy: 0.9055 - val_loss: 0.2933\n",
            "Epoch 30/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9021 - loss: 0.3119 - val_accuracy: 0.9055 - val_loss: 0.2933\n",
            "Epoch 31/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 0.3392 - val_accuracy: 0.9055 - val_loss: 0.2925\n",
            "Epoch 32/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9160 - loss: 0.3082 - val_accuracy: 0.9055 - val_loss: 0.2923\n",
            "Epoch 33/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.3041 - val_accuracy: 0.9055 - val_loss: 0.2916\n",
            "Epoch 34/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.3208 - val_accuracy: 0.9055 - val_loss: 0.2912\n",
            "Epoch 35/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2962 - val_accuracy: 0.9055 - val_loss: 0.2913\n",
            "Epoch 36/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9057 - loss: 0.3105 - val_accuracy: 0.9055 - val_loss: 0.2910\n",
            "Epoch 37/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9067 - loss: 0.3038 - val_accuracy: 0.9055 - val_loss: 0.2905\n",
            "Epoch 38/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2877 - val_accuracy: 0.9055 - val_loss: 0.2908\n",
            "Epoch 39/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.2998 - val_accuracy: 0.9055 - val_loss: 0.2911\n",
            "Epoch 40/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.3067 - val_accuracy: 0.9055 - val_loss: 0.2907\n",
            "Epoch 41/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.3015 - val_accuracy: 0.9055 - val_loss: 0.2903\n",
            "Epoch 42/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9077 - loss: 0.3049 - val_accuracy: 0.9055 - val_loss: 0.2901\n",
            "Epoch 43/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.3028 - val_accuracy: 0.9055 - val_loss: 0.2896\n",
            "Epoch 44/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.3066 - val_accuracy: 0.9055 - val_loss: 0.2897\n",
            "Epoch 45/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.2916 - val_accuracy: 0.9055 - val_loss: 0.2893\n",
            "Epoch 46/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9150 - loss: 0.2843 - val_accuracy: 0.9055 - val_loss: 0.2884\n",
            "Epoch 47/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2900 - val_accuracy: 0.9055 - val_loss: 0.2879\n",
            "Epoch 48/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.2779 - val_accuracy: 0.9055 - val_loss: 0.2870\n",
            "Epoch 49/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2854 - val_accuracy: 0.9055 - val_loss: 0.2862\n",
            "Epoch 50/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.3095 - val_accuracy: 0.9055 - val_loss: 0.2863\n",
            "Epoch 51/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.3308 - val_accuracy: 0.9055 - val_loss: 0.2860\n",
            "Epoch 52/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.3086 - val_accuracy: 0.9055 - val_loss: 0.2857\n",
            "Epoch 53/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2842 - val_accuracy: 0.9055 - val_loss: 0.2861\n",
            "Epoch 54/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2880 - val_accuracy: 0.9055 - val_loss: 0.2858\n",
            "Epoch 55/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.3170 - val_accuracy: 0.9055 - val_loss: 0.2849\n",
            "Epoch 56/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.2613 - val_accuracy: 0.9055 - val_loss: 0.2846\n",
            "Epoch 57/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9116 - loss: 0.2909 - val_accuracy: 0.9055 - val_loss: 0.2842\n",
            "Epoch 58/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2774 - val_accuracy: 0.9055 - val_loss: 0.2840\n",
            "Epoch 59/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2738 - val_accuracy: 0.9055 - val_loss: 0.2843\n",
            "Epoch 60/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.3195 - val_accuracy: 0.9055 - val_loss: 0.2841\n",
            "Epoch 61/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9157 - loss: 0.2757 - val_accuracy: 0.9055 - val_loss: 0.2837\n",
            "Epoch 62/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2832 - val_accuracy: 0.9055 - val_loss: 0.2829\n",
            "Epoch 63/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9043 - loss: 0.3045 - val_accuracy: 0.9055 - val_loss: 0.2825\n",
            "Epoch 64/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.3274 - val_accuracy: 0.9055 - val_loss: 0.2814\n",
            "Epoch 65/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.2758 - val_accuracy: 0.9055 - val_loss: 0.2815\n",
            "Epoch 66/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.2775 - val_accuracy: 0.9055 - val_loss: 0.2816\n",
            "Epoch 67/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.3142 - val_accuracy: 0.9055 - val_loss: 0.2821\n",
            "Epoch 68/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2763 - val_accuracy: 0.9055 - val_loss: 0.2815\n",
            "Epoch 69/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.2910 - val_accuracy: 0.9055 - val_loss: 0.2811\n",
            "Epoch 70/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9125 - loss: 0.2795 - val_accuracy: 0.9055 - val_loss: 0.2809\n",
            "Epoch 71/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2846 - val_accuracy: 0.9055 - val_loss: 0.2810\n",
            "Epoch 72/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9048 - loss: 0.3003 - val_accuracy: 0.9055 - val_loss: 0.2814\n",
            "Epoch 73/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2864 - val_accuracy: 0.9055 - val_loss: 0.2815\n",
            "Epoch 74/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2758 - val_accuracy: 0.9055 - val_loss: 0.2810\n",
            "Epoch 75/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2731 - val_accuracy: 0.9055 - val_loss: 0.2813\n",
            "Epoch 76/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.3274 - val_accuracy: 0.9055 - val_loss: 0.2800\n",
            "Epoch 77/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.3029 - val_accuracy: 0.9055 - val_loss: 0.2803\n",
            "Epoch 78/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2836 - val_accuracy: 0.9055 - val_loss: 0.2801\n",
            "Epoch 79/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.3235 - val_accuracy: 0.9055 - val_loss: 0.2799\n",
            "Epoch 80/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.2920 - val_accuracy: 0.9055 - val_loss: 0.2800\n",
            "Epoch 81/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9263 - loss: 0.2572 - val_accuracy: 0.9055 - val_loss: 0.2798\n",
            "Epoch 82/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2886 - val_accuracy: 0.9055 - val_loss: 0.2808\n",
            "Epoch 83/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.2826 - val_accuracy: 0.9055 - val_loss: 0.2809\n",
            "Epoch 84/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2755 - val_accuracy: 0.9055 - val_loss: 0.2812\n",
            "Epoch 85/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.3162 - val_accuracy: 0.9055 - val_loss: 0.2815\n",
            "Epoch 86/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2814 - val_accuracy: 0.9055 - val_loss: 0.2814\n",
            "Epoch 87/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2803 - val_accuracy: 0.9055 - val_loss: 0.2816\n",
            "Epoch 88/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2634 - val_accuracy: 0.9055 - val_loss: 0.2809\n",
            "Epoch 89/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2560 - val_accuracy: 0.9055 - val_loss: 0.2804\n",
            "Epoch 90/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9196 - loss: 0.2665 - val_accuracy: 0.9055 - val_loss: 0.2803\n",
            "Epoch 91/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.3166 - val_accuracy: 0.9055 - val_loss: 0.2802\n",
            "Model mlp_financial training complete for niche 0.\n",
            "  Final training loss: 0.27478650212287903\n",
            "  Final validation loss: 0.28022301197052\n",
            "  Final training accuracy: 0.9126478433609009\n",
            "  Final validation accuracy: 0.9054545164108276\n",
            "Training model mlp_market for niche 0...\n",
            "Epoch 1/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6997 - loss: 0.6517 - val_accuracy: 0.9055 - val_loss: 0.5116\n",
            "Epoch 2/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8727 - loss: 0.4627 - val_accuracy: 0.9055 - val_loss: 0.4075\n",
            "Epoch 3/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.4081 - val_accuracy: 0.9055 - val_loss: 0.3625\n",
            "Epoch 4/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.3932 - val_accuracy: 0.9055 - val_loss: 0.3466\n",
            "Epoch 5/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.3584 - val_accuracy: 0.9055 - val_loss: 0.3375\n",
            "Epoch 6/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.3661 - val_accuracy: 0.9055 - val_loss: 0.3338\n",
            "Epoch 7/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.3594 - val_accuracy: 0.9055 - val_loss: 0.3317\n",
            "Epoch 8/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9057 - loss: 0.3674 - val_accuracy: 0.9055 - val_loss: 0.3297\n",
            "Epoch 9/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.3477 - val_accuracy: 0.9055 - val_loss: 0.3275\n",
            "Epoch 10/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.3262 - val_accuracy: 0.9055 - val_loss: 0.3267\n",
            "Epoch 11/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.3274 - val_accuracy: 0.9055 - val_loss: 0.3256\n",
            "Epoch 12/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9103 - loss: 0.3346 - val_accuracy: 0.9055 - val_loss: 0.3238\n",
            "Epoch 13/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.3418 - val_accuracy: 0.9055 - val_loss: 0.3224\n",
            "Epoch 14/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9121 - loss: 0.3229 - val_accuracy: 0.9055 - val_loss: 0.3198\n",
            "Epoch 15/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8983 - loss: 0.3588 - val_accuracy: 0.9055 - val_loss: 0.3178\n",
            "Epoch 16/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.3129 - val_accuracy: 0.9055 - val_loss: 0.3162\n",
            "Epoch 17/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.3313 - val_accuracy: 0.9055 - val_loss: 0.3150\n",
            "Epoch 18/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.3120 - val_accuracy: 0.9055 - val_loss: 0.3137\n",
            "Epoch 19/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2990 - val_accuracy: 0.9055 - val_loss: 0.3123\n",
            "Epoch 20/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9188 - loss: 0.3101 - val_accuracy: 0.9055 - val_loss: 0.3105\n",
            "Epoch 21/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9175 - loss: 0.2965 - val_accuracy: 0.9055 - val_loss: 0.3099\n",
            "Epoch 22/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9182 - loss: 0.3156 - val_accuracy: 0.9055 - val_loss: 0.3083\n",
            "Epoch 23/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9111 - loss: 0.3038 - val_accuracy: 0.9055 - val_loss: 0.3072\n",
            "Epoch 24/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9260 - loss: 0.2792 - val_accuracy: 0.9055 - val_loss: 0.3068\n",
            "Epoch 25/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9015 - loss: 0.3511 - val_accuracy: 0.9055 - val_loss: 0.3063\n",
            "Epoch 26/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.2654 - val_accuracy: 0.9055 - val_loss: 0.3065\n",
            "Epoch 27/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2976 - val_accuracy: 0.9055 - val_loss: 0.3056\n",
            "Epoch 28/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9014 - loss: 0.3145 - val_accuracy: 0.9055 - val_loss: 0.3049\n",
            "Epoch 29/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.3235 - val_accuracy: 0.9055 - val_loss: 0.3035\n",
            "Epoch 30/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9072 - loss: 0.3050 - val_accuracy: 0.9055 - val_loss: 0.3040\n",
            "Epoch 31/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9050 - loss: 0.3018 - val_accuracy: 0.9055 - val_loss: 0.3024\n",
            "Epoch 32/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.3165 - val_accuracy: 0.9055 - val_loss: 0.3015\n",
            "Epoch 33/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.3059 - val_accuracy: 0.9055 - val_loss: 0.3013\n",
            "Epoch 34/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.2642 - val_accuracy: 0.9055 - val_loss: 0.3011\n",
            "Epoch 35/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.3103 - val_accuracy: 0.9055 - val_loss: 0.2999\n",
            "Epoch 36/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9030 - loss: 0.3259 - val_accuracy: 0.9055 - val_loss: 0.2992\n",
            "Epoch 37/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.2976 - val_accuracy: 0.9055 - val_loss: 0.2981\n",
            "Epoch 38/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9081 - loss: 0.3150 - val_accuracy: 0.9055 - val_loss: 0.2969\n",
            "Epoch 39/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.2875 - val_accuracy: 0.9055 - val_loss: 0.2969\n",
            "Epoch 40/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.3003 - val_accuracy: 0.9055 - val_loss: 0.2976\n",
            "Epoch 41/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.3206 - val_accuracy: 0.9055 - val_loss: 0.2969\n",
            "Epoch 42/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9133 - loss: 0.3068 - val_accuracy: 0.9055 - val_loss: 0.2965\n",
            "Epoch 43/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9310 - loss: 0.2536 - val_accuracy: 0.9055 - val_loss: 0.2969\n",
            "Epoch 44/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2874 - val_accuracy: 0.9055 - val_loss: 0.2955\n",
            "Epoch 45/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2800 - val_accuracy: 0.9055 - val_loss: 0.2944\n",
            "Epoch 46/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.2906 - val_accuracy: 0.9055 - val_loss: 0.2933\n",
            "Epoch 47/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9191 - loss: 0.2763 - val_accuracy: 0.9055 - val_loss: 0.2920\n",
            "Epoch 48/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.2914 - val_accuracy: 0.9055 - val_loss: 0.2913\n",
            "Epoch 49/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2869 - val_accuracy: 0.9055 - val_loss: 0.2920\n",
            "Epoch 50/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2909 - val_accuracy: 0.9055 - val_loss: 0.2910\n",
            "Epoch 51/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9172 - loss: 0.2778 - val_accuracy: 0.9055 - val_loss: 0.2908\n",
            "Epoch 52/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2849 - val_accuracy: 0.9055 - val_loss: 0.2914\n",
            "Epoch 53/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.3015 - val_accuracy: 0.9055 - val_loss: 0.2901\n",
            "Epoch 54/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9176 - loss: 0.2818 - val_accuracy: 0.9055 - val_loss: 0.2892\n",
            "Epoch 55/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.2762 - val_accuracy: 0.9055 - val_loss: 0.2890\n",
            "Epoch 56/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.3034 - val_accuracy: 0.9055 - val_loss: 0.2881\n",
            "Epoch 57/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2833 - val_accuracy: 0.9055 - val_loss: 0.2877\n",
            "Epoch 58/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9033 - loss: 0.3099 - val_accuracy: 0.9055 - val_loss: 0.2875\n",
            "Epoch 59/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2633 - val_accuracy: 0.9055 - val_loss: 0.2861\n",
            "Epoch 60/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9067 - loss: 0.2988 - val_accuracy: 0.9055 - val_loss: 0.2853\n",
            "Epoch 61/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9004 - loss: 0.3041 - val_accuracy: 0.9055 - val_loss: 0.2850\n",
            "Epoch 62/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9018 - loss: 0.3029 - val_accuracy: 0.9055 - val_loss: 0.2849\n",
            "Epoch 63/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9080 - loss: 0.2889 - val_accuracy: 0.9055 - val_loss: 0.2845\n",
            "Epoch 64/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2716 - val_accuracy: 0.9055 - val_loss: 0.2861\n",
            "Epoch 65/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2974 - val_accuracy: 0.9055 - val_loss: 0.2847\n",
            "Epoch 66/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.3135 - val_accuracy: 0.9055 - val_loss: 0.2855\n",
            "Epoch 67/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2782 - val_accuracy: 0.9055 - val_loss: 0.2858\n",
            "Epoch 68/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.2628 - val_accuracy: 0.9055 - val_loss: 0.2848\n",
            "Epoch 69/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9176 - loss: 0.2874 - val_accuracy: 0.9055 - val_loss: 0.2833\n",
            "Epoch 70/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.2989 - val_accuracy: 0.9055 - val_loss: 0.2826\n",
            "Epoch 71/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2867 - val_accuracy: 0.9055 - val_loss: 0.2829\n",
            "Epoch 72/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.2926 - val_accuracy: 0.9055 - val_loss: 0.2827\n",
            "Epoch 73/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9185 - loss: 0.2896 - val_accuracy: 0.9055 - val_loss: 0.2825\n",
            "Epoch 74/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.2443 - val_accuracy: 0.9055 - val_loss: 0.2832\n",
            "Epoch 75/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.2683 - val_accuracy: 0.9055 - val_loss: 0.2826\n",
            "Epoch 76/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2819 - val_accuracy: 0.9055 - val_loss: 0.2832\n",
            "Epoch 77/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8922 - loss: 0.3172 - val_accuracy: 0.9055 - val_loss: 0.2835\n",
            "Epoch 78/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2843 - val_accuracy: 0.9055 - val_loss: 0.2827\n",
            "Epoch 79/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9163 - loss: 0.2621 - val_accuracy: 0.9055 - val_loss: 0.2822\n",
            "Epoch 80/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2805 - val_accuracy: 0.9055 - val_loss: 0.2823\n",
            "Epoch 81/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.3289 - val_accuracy: 0.9055 - val_loss: 0.2811\n",
            "Epoch 82/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2627 - val_accuracy: 0.9055 - val_loss: 0.2814\n",
            "Epoch 83/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2893 - val_accuracy: 0.9055 - val_loss: 0.2816\n",
            "Epoch 84/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2980 - val_accuracy: 0.9055 - val_loss: 0.2818\n",
            "Epoch 85/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.2904 - val_accuracy: 0.9055 - val_loss: 0.2823\n",
            "Epoch 86/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2726 - val_accuracy: 0.9055 - val_loss: 0.2822\n",
            "Epoch 87/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2897 - val_accuracy: 0.9055 - val_loss: 0.2815\n",
            "Epoch 88/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.2809 - val_accuracy: 0.9055 - val_loss: 0.2811\n",
            "Epoch 89/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.2910 - val_accuracy: 0.9055 - val_loss: 0.2802\n",
            "Epoch 90/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2836 - val_accuracy: 0.9055 - val_loss: 0.2806\n",
            "Epoch 91/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2762 - val_accuracy: 0.9055 - val_loss: 0.2802\n",
            "Epoch 92/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2616 - val_accuracy: 0.9055 - val_loss: 0.2802\n",
            "Epoch 93/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2753 - val_accuracy: 0.9055 - val_loss: 0.2799\n",
            "Epoch 94/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8979 - loss: 0.3099 - val_accuracy: 0.9055 - val_loss: 0.2792\n",
            "Epoch 95/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2591 - val_accuracy: 0.9055 - val_loss: 0.2801\n",
            "Epoch 96/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2718 - val_accuracy: 0.9055 - val_loss: 0.2797\n",
            "Epoch 97/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.2983 - val_accuracy: 0.9055 - val_loss: 0.2789\n",
            "Epoch 98/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 0.2560 - val_accuracy: 0.9055 - val_loss: 0.2782\n",
            "Epoch 99/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.2668 - val_accuracy: 0.9055 - val_loss: 0.2776\n",
            "Epoch 100/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9045 - loss: 0.2789 - val_accuracy: 0.9055 - val_loss: 0.2777\n",
            "Epoch 101/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2694 - val_accuracy: 0.9055 - val_loss: 0.2772\n",
            "Epoch 102/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2821 - val_accuracy: 0.9055 - val_loss: 0.2778\n",
            "Epoch 103/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.2442 - val_accuracy: 0.9055 - val_loss: 0.2778\n",
            "Epoch 104/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2644 - val_accuracy: 0.9055 - val_loss: 0.2785\n",
            "Epoch 105/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2651 - val_accuracy: 0.9055 - val_loss: 0.2770\n",
            "Epoch 106/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2959 - val_accuracy: 0.9055 - val_loss: 0.2772\n",
            "Epoch 107/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.2497 - val_accuracy: 0.9055 - val_loss: 0.2769\n",
            "Epoch 108/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2624 - val_accuracy: 0.9055 - val_loss: 0.2774\n",
            "Epoch 109/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.2740 - val_accuracy: 0.9055 - val_loss: 0.2765\n",
            "Epoch 110/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9028 - loss: 0.2992 - val_accuracy: 0.9055 - val_loss: 0.2759\n",
            "Epoch 111/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.2505 - val_accuracy: 0.9055 - val_loss: 0.2758\n",
            "Epoch 112/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.3101 - val_accuracy: 0.9055 - val_loss: 0.2761\n",
            "Epoch 113/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2501 - val_accuracy: 0.9055 - val_loss: 0.2762\n",
            "Epoch 114/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.2938 - val_accuracy: 0.9055 - val_loss: 0.2761\n",
            "Epoch 115/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.2869 - val_accuracy: 0.9055 - val_loss: 0.2765\n",
            "Epoch 116/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.2323 - val_accuracy: 0.9055 - val_loss: 0.2767\n",
            "Epoch 117/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2746 - val_accuracy: 0.9055 - val_loss: 0.2761\n",
            "Epoch 118/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9130 - loss: 0.2934 - val_accuracy: 0.9055 - val_loss: 0.2753\n",
            "Epoch 119/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2779 - val_accuracy: 0.9055 - val_loss: 0.2754\n",
            "Epoch 120/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2761 - val_accuracy: 0.9055 - val_loss: 0.2760\n",
            "Epoch 121/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2642 - val_accuracy: 0.9055 - val_loss: 0.2764\n",
            "Epoch 122/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2415 - val_accuracy: 0.9055 - val_loss: 0.2761\n",
            "Epoch 123/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.2516 - val_accuracy: 0.9055 - val_loss: 0.2762\n",
            "Epoch 124/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.2851 - val_accuracy: 0.9055 - val_loss: 0.2758\n",
            "Epoch 125/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.2723 - val_accuracy: 0.9055 - val_loss: 0.2747\n",
            "Epoch 126/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2614 - val_accuracy: 0.9055 - val_loss: 0.2748\n",
            "Epoch 127/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2604 - val_accuracy: 0.9055 - val_loss: 0.2750\n",
            "Epoch 128/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2870 - val_accuracy: 0.9055 - val_loss: 0.2752\n",
            "Epoch 129/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2779 - val_accuracy: 0.9055 - val_loss: 0.2756\n",
            "Epoch 130/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2557 - val_accuracy: 0.9055 - val_loss: 0.2749\n",
            "Epoch 131/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2750 - val_accuracy: 0.9055 - val_loss: 0.2748\n",
            "Epoch 132/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2634 - val_accuracy: 0.9055 - val_loss: 0.2751\n",
            "Epoch 133/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8979 - loss: 0.2863 - val_accuracy: 0.9055 - val_loss: 0.2743\n",
            "Epoch 134/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9285 - loss: 0.2421 - val_accuracy: 0.9055 - val_loss: 0.2741\n",
            "Epoch 135/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2694 - val_accuracy: 0.9055 - val_loss: 0.2742\n",
            "Epoch 136/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2590 - val_accuracy: 0.9055 - val_loss: 0.2744\n",
            "Epoch 137/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.2839 - val_accuracy: 0.9055 - val_loss: 0.2743\n",
            "Epoch 138/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9077 - loss: 0.2900 - val_accuracy: 0.9055 - val_loss: 0.2734\n",
            "Epoch 139/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2703 - val_accuracy: 0.9055 - val_loss: 0.2738\n",
            "Epoch 140/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2716 - val_accuracy: 0.9055 - val_loss: 0.2733\n",
            "Epoch 141/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.2748 - val_accuracy: 0.9055 - val_loss: 0.2737\n",
            "Epoch 142/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2664 - val_accuracy: 0.9055 - val_loss: 0.2741\n",
            "Epoch 143/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.2495 - val_accuracy: 0.9055 - val_loss: 0.2740\n",
            "Epoch 144/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2550 - val_accuracy: 0.9055 - val_loss: 0.2744\n",
            "Epoch 145/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2748 - val_accuracy: 0.9055 - val_loss: 0.2740\n",
            "Epoch 146/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2689 - val_accuracy: 0.9055 - val_loss: 0.2738\n",
            "Epoch 147/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9048 - loss: 0.2712 - val_accuracy: 0.9055 - val_loss: 0.2734\n",
            "Epoch 148/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2747 - val_accuracy: 0.9055 - val_loss: 0.2736\n",
            "Epoch 149/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2713 - val_accuracy: 0.9055 - val_loss: 0.2739\n",
            "Epoch 150/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9163 - loss: 0.2517 - val_accuracy: 0.9055 - val_loss: 0.2732\n",
            "Epoch 151/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2561 - val_accuracy: 0.9055 - val_loss: 0.2727\n",
            "Epoch 152/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9156 - loss: 0.2549 - val_accuracy: 0.9055 - val_loss: 0.2724\n",
            "Epoch 153/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9285 - loss: 0.2514 - val_accuracy: 0.9055 - val_loss: 0.2718\n",
            "Epoch 154/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2810 - val_accuracy: 0.9055 - val_loss: 0.2717\n",
            "Epoch 155/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9022 - loss: 0.2855 - val_accuracy: 0.9055 - val_loss: 0.2715\n",
            "Epoch 156/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2454 - val_accuracy: 0.9055 - val_loss: 0.2719\n",
            "Epoch 157/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.2337 - val_accuracy: 0.9055 - val_loss: 0.2713\n",
            "Epoch 158/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9236 - loss: 0.2475 - val_accuracy: 0.9055 - val_loss: 0.2711\n",
            "Epoch 159/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2593 - val_accuracy: 0.9055 - val_loss: 0.2709\n",
            "Epoch 160/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2539 - val_accuracy: 0.9055 - val_loss: 0.2715\n",
            "Epoch 161/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2773 - val_accuracy: 0.9055 - val_loss: 0.2710\n",
            "Epoch 162/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2716 - val_accuracy: 0.9055 - val_loss: 0.2712\n",
            "Epoch 163/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2498 - val_accuracy: 0.9055 - val_loss: 0.2712\n",
            "Epoch 164/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2578 - val_accuracy: 0.9055 - val_loss: 0.2711\n",
            "Epoch 165/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2746 - val_accuracy: 0.9055 - val_loss: 0.2713\n",
            "Epoch 166/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.2867 - val_accuracy: 0.9055 - val_loss: 0.2719\n",
            "Epoch 167/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.2876 - val_accuracy: 0.9055 - val_loss: 0.2710\n",
            "Epoch 168/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2710 - val_accuracy: 0.9055 - val_loss: 0.2718\n",
            "Epoch 169/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.3288 - val_accuracy: 0.9055 - val_loss: 0.2715\n",
            "Model mlp_market training complete for niche 0.\n",
            "  Final training loss: 0.2721712589263916\n",
            "  Final validation loss: 0.2715062201023102\n",
            "  Final training accuracy: 0.9126478433609009\n",
            "  Final validation accuracy: 0.9054545164108276\n",
            "Training model lstm for niche 0...\n",
            "Epoch 1/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.3562 - loss: 0.7119 - val_accuracy: 0.9055 - val_loss: 0.6417\n",
            "Epoch 2/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8481 - loss: 0.6205 - val_accuracy: 0.9055 - val_loss: 0.5295\n",
            "Epoch 3/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.4810 - val_accuracy: 0.9055 - val_loss: 0.3142\n",
            "Epoch 4/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.3896 - val_accuracy: 0.9055 - val_loss: 0.3098\n",
            "Epoch 5/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9188 - loss: 0.3203 - val_accuracy: 0.9055 - val_loss: 0.3086\n",
            "Epoch 6/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9161 - loss: 0.3438 - val_accuracy: 0.9055 - val_loss: 0.3100\n",
            "Epoch 7/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9128 - loss: 0.3267 - val_accuracy: 0.9055 - val_loss: 0.3060\n",
            "Epoch 8/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9002 - loss: 0.3513 - val_accuracy: 0.9055 - val_loss: 0.3115\n",
            "Epoch 9/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.3138 - val_accuracy: 0.9055 - val_loss: 0.3124\n",
            "Epoch 10/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9284 - loss: 0.3036 - val_accuracy: 0.9055 - val_loss: 0.3031\n",
            "Epoch 11/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9112 - loss: 0.3482 - val_accuracy: 0.9055 - val_loss: 0.3051\n",
            "Epoch 12/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9160 - loss: 0.3215 - val_accuracy: 0.9055 - val_loss: 0.3016\n",
            "Epoch 13/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9078 - loss: 0.3535 - val_accuracy: 0.9055 - val_loss: 0.3016\n",
            "Epoch 14/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9243 - loss: 0.3107 - val_accuracy: 0.9055 - val_loss: 0.3007\n",
            "Epoch 15/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9117 - loss: 0.3216 - val_accuracy: 0.9055 - val_loss: 0.3000\n",
            "Epoch 16/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9126 - loss: 0.3257 - val_accuracy: 0.9055 - val_loss: 0.2994\n",
            "Epoch 17/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9217 - loss: 0.3042 - val_accuracy: 0.9055 - val_loss: 0.3012\n",
            "Epoch 18/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9188 - loss: 0.3020 - val_accuracy: 0.9055 - val_loss: 0.2985\n",
            "Epoch 19/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.3226 - val_accuracy: 0.9055 - val_loss: 0.2982\n",
            "Epoch 20/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9140 - loss: 0.3114 - val_accuracy: 0.9055 - val_loss: 0.2975\n",
            "Epoch 21/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9155 - loss: 0.2950 - val_accuracy: 0.9055 - val_loss: 0.2982\n",
            "Epoch 22/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.3103 - val_accuracy: 0.9055 - val_loss: 0.2973\n",
            "Epoch 23/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9082 - loss: 0.3293 - val_accuracy: 0.9055 - val_loss: 0.2972\n",
            "Epoch 24/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9129 - loss: 0.3199 - val_accuracy: 0.9055 - val_loss: 0.2969\n",
            "Epoch 25/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9075 - loss: 0.3066 - val_accuracy: 0.9055 - val_loss: 0.2968\n",
            "Epoch 26/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9168 - loss: 0.3010 - val_accuracy: 0.9055 - val_loss: 0.2969\n",
            "Epoch 27/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9081 - loss: 0.3178 - val_accuracy: 0.9055 - val_loss: 0.2959\n",
            "Epoch 28/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9193 - loss: 0.2952 - val_accuracy: 0.9055 - val_loss: 0.2956\n",
            "Epoch 29/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9094 - loss: 0.3072 - val_accuracy: 0.9055 - val_loss: 0.2951\n",
            "Epoch 30/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9060 - loss: 0.3299 - val_accuracy: 0.9055 - val_loss: 0.2953\n",
            "Epoch 31/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9177 - loss: 0.2979 - val_accuracy: 0.9055 - val_loss: 0.2945\n",
            "Epoch 32/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9049 - loss: 0.3186 - val_accuracy: 0.9055 - val_loss: 0.2942\n",
            "Epoch 33/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 0.3172 - val_accuracy: 0.9055 - val_loss: 0.2944\n",
            "Epoch 34/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9201 - loss: 0.2963 - val_accuracy: 0.9055 - val_loss: 0.2941\n",
            "Epoch 35/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9024 - loss: 0.3204 - val_accuracy: 0.9055 - val_loss: 0.2937\n",
            "Epoch 36/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.2943 - val_accuracy: 0.9055 - val_loss: 0.2938\n",
            "Epoch 37/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9168 - loss: 0.3036 - val_accuracy: 0.9055 - val_loss: 0.2939\n",
            "Epoch 38/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9149 - loss: 0.2987 - val_accuracy: 0.9055 - val_loss: 0.2930\n",
            "Epoch 39/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.3204 - val_accuracy: 0.9055 - val_loss: 0.2942\n",
            "Epoch 40/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9086 - loss: 0.3121 - val_accuracy: 0.9055 - val_loss: 0.2932\n",
            "Epoch 41/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9122 - loss: 0.3090 - val_accuracy: 0.9055 - val_loss: 0.2925\n",
            "Epoch 42/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9105 - loss: 0.3103 - val_accuracy: 0.9055 - val_loss: 0.2925\n",
            "Epoch 43/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9145 - loss: 0.3005 - val_accuracy: 0.9055 - val_loss: 0.2916\n",
            "Epoch 44/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9139 - loss: 0.2984 - val_accuracy: 0.9055 - val_loss: 0.2914\n",
            "Epoch 45/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9118 - loss: 0.3083 - val_accuracy: 0.9055 - val_loss: 0.2912\n",
            "Epoch 46/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9161 - loss: 0.2775 - val_accuracy: 0.9055 - val_loss: 0.2908\n",
            "Epoch 47/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9179 - loss: 0.2907 - val_accuracy: 0.9055 - val_loss: 0.2904\n",
            "Epoch 48/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8908 - loss: 0.3545 - val_accuracy: 0.9055 - val_loss: 0.2901\n",
            "Epoch 49/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9192 - loss: 0.2935 - val_accuracy: 0.9055 - val_loss: 0.2900\n",
            "Epoch 50/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2942 - val_accuracy: 0.9055 - val_loss: 0.2897\n",
            "Epoch 51/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9181 - loss: 0.2769 - val_accuracy: 0.9055 - val_loss: 0.2895\n",
            "Epoch 52/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9325 - loss: 0.2515 - val_accuracy: 0.9055 - val_loss: 0.2894\n",
            "Epoch 53/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9206 - loss: 0.2793 - val_accuracy: 0.9055 - val_loss: 0.2895\n",
            "Epoch 54/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2777 - val_accuracy: 0.9055 - val_loss: 0.2889\n",
            "Epoch 55/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9167 - loss: 0.2912 - val_accuracy: 0.9055 - val_loss: 0.2888\n",
            "Epoch 56/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9055 - loss: 0.3003 - val_accuracy: 0.9055 - val_loss: 0.2886\n",
            "Epoch 57/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9060 - loss: 0.3170 - val_accuracy: 0.9055 - val_loss: 0.2885\n",
            "Epoch 58/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.2985 - val_accuracy: 0.9055 - val_loss: 0.2884\n",
            "Epoch 59/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9134 - loss: 0.2853 - val_accuracy: 0.9055 - val_loss: 0.2886\n",
            "Epoch 60/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.2619 - val_accuracy: 0.9055 - val_loss: 0.2887\n",
            "Epoch 61/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9191 - loss: 0.2773 - val_accuracy: 0.9055 - val_loss: 0.2880\n",
            "Epoch 62/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9218 - loss: 0.2765 - val_accuracy: 0.9055 - val_loss: 0.2879\n",
            "Epoch 63/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9219 - loss: 0.2742 - val_accuracy: 0.9055 - val_loss: 0.2879\n",
            "Epoch 64/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9086 - loss: 0.2998 - val_accuracy: 0.9055 - val_loss: 0.2876\n",
            "Epoch 65/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9252 - loss: 0.2679 - val_accuracy: 0.9055 - val_loss: 0.2875\n",
            "Epoch 66/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 0.2816 - val_accuracy: 0.9055 - val_loss: 0.2874\n",
            "Epoch 67/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9166 - loss: 0.2691 - val_accuracy: 0.9055 - val_loss: 0.2873\n",
            "Epoch 68/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.2605 - val_accuracy: 0.9055 - val_loss: 0.2873\n",
            "Epoch 69/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9138 - loss: 0.2795 - val_accuracy: 0.9055 - val_loss: 0.2870\n",
            "Epoch 70/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9194 - loss: 0.2739 - val_accuracy: 0.9055 - val_loss: 0.2869\n",
            "Epoch 71/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9093 - loss: 0.2812 - val_accuracy: 0.9055 - val_loss: 0.2870\n",
            "Epoch 72/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9199 - loss: 0.2690 - val_accuracy: 0.9055 - val_loss: 0.2865\n",
            "Epoch 73/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9048 - loss: 0.2948 - val_accuracy: 0.9055 - val_loss: 0.2864\n",
            "Epoch 74/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9167 - loss: 0.2947 - val_accuracy: 0.9055 - val_loss: 0.2862\n",
            "Epoch 75/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9118 - loss: 0.2879 - val_accuracy: 0.9055 - val_loss: 0.2861\n",
            "Epoch 76/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9138 - loss: 0.2790 - val_accuracy: 0.9055 - val_loss: 0.2858\n",
            "Epoch 77/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9142 - loss: 0.2797 - val_accuracy: 0.9055 - val_loss: 0.2857\n",
            "Epoch 78/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9088 - loss: 0.2946 - val_accuracy: 0.9055 - val_loss: 0.2860\n",
            "Epoch 79/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8963 - loss: 0.3163 - val_accuracy: 0.9055 - val_loss: 0.2854\n",
            "Epoch 80/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9127 - loss: 0.2951 - val_accuracy: 0.9055 - val_loss: 0.2853\n",
            "Epoch 81/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9101 - loss: 0.2972 - val_accuracy: 0.9055 - val_loss: 0.2852\n",
            "Epoch 82/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9055 - loss: 0.2867 - val_accuracy: 0.9055 - val_loss: 0.2855\n",
            "Epoch 83/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.2882 - val_accuracy: 0.9055 - val_loss: 0.2848\n",
            "Epoch 84/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9149 - loss: 0.2792 - val_accuracy: 0.9055 - val_loss: 0.2847\n",
            "Epoch 85/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9196 - loss: 0.2652 - val_accuracy: 0.9055 - val_loss: 0.2847\n",
            "Epoch 86/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9141 - loss: 0.2665 - val_accuracy: 0.9055 - val_loss: 0.2845\n",
            "Epoch 87/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9252 - loss: 0.2575 - val_accuracy: 0.9055 - val_loss: 0.2844\n",
            "Epoch 88/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9028 - loss: 0.3001 - val_accuracy: 0.9055 - val_loss: 0.2844\n",
            "Epoch 89/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9133 - loss: 0.2834 - val_accuracy: 0.9055 - val_loss: 0.2842\n",
            "Epoch 90/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9229 - loss: 0.2513 - val_accuracy: 0.9055 - val_loss: 0.2841\n",
            "Epoch 91/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9117 - loss: 0.2846 - val_accuracy: 0.9055 - val_loss: 0.2842\n",
            "Epoch 92/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.2593 - val_accuracy: 0.9055 - val_loss: 0.2842\n",
            "Epoch 93/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9031 - loss: 0.2930 - val_accuracy: 0.9055 - val_loss: 0.2845\n",
            "Epoch 94/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9058 - loss: 0.3041 - val_accuracy: 0.9055 - val_loss: 0.2837\n",
            "Epoch 95/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9240 - loss: 0.2610 - val_accuracy: 0.9055 - val_loss: 0.2836\n",
            "Epoch 96/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9119 - loss: 0.2817 - val_accuracy: 0.9055 - val_loss: 0.2835\n",
            "Epoch 97/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.3061 - val_accuracy: 0.9055 - val_loss: 0.2835\n",
            "Epoch 98/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9221 - loss: 0.2766 - val_accuracy: 0.9055 - val_loss: 0.2835\n",
            "Epoch 99/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9095 - loss: 0.2969 - val_accuracy: 0.9055 - val_loss: 0.2835\n",
            "Epoch 100/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9121 - loss: 0.2824 - val_accuracy: 0.9055 - val_loss: 0.2837\n",
            "Epoch 101/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9060 - loss: 0.2975 - val_accuracy: 0.9055 - val_loss: 0.2835\n",
            "Epoch 102/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9178 - loss: 0.2690 - val_accuracy: 0.9055 - val_loss: 0.2835\n",
            "Epoch 103/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9093 - loss: 0.2871 - val_accuracy: 0.9055 - val_loss: 0.2832\n",
            "Epoch 104/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2477 - val_accuracy: 0.9055 - val_loss: 0.2832\n",
            "Epoch 105/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2730 - val_accuracy: 0.9055 - val_loss: 0.2830\n",
            "Epoch 106/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.2644 - val_accuracy: 0.9055 - val_loss: 0.2829\n",
            "Epoch 107/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9101 - loss: 0.2819 - val_accuracy: 0.9055 - val_loss: 0.2830\n",
            "Epoch 108/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.2986 - val_accuracy: 0.9055 - val_loss: 0.2829\n",
            "Epoch 109/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8972 - loss: 0.3041 - val_accuracy: 0.9055 - val_loss: 0.2829\n",
            "Epoch 110/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9058 - loss: 0.2903 - val_accuracy: 0.9055 - val_loss: 0.2829\n",
            "Epoch 111/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9112 - loss: 0.2884 - val_accuracy: 0.9055 - val_loss: 0.2829\n",
            "Epoch 112/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9105 - loss: 0.2795 - val_accuracy: 0.9055 - val_loss: 0.2829\n",
            "Epoch 113/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9004 - loss: 0.3001 - val_accuracy: 0.9055 - val_loss: 0.2831\n",
            "Epoch 114/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9097 - loss: 0.2811 - val_accuracy: 0.9055 - val_loss: 0.2827\n",
            "Epoch 115/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9144 - loss: 0.2668 - val_accuracy: 0.9055 - val_loss: 0.2828\n",
            "Epoch 116/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9050 - loss: 0.2870 - val_accuracy: 0.9055 - val_loss: 0.2828\n",
            "Epoch 117/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9195 - loss: 0.2663 - val_accuracy: 0.9055 - val_loss: 0.2826\n",
            "Epoch 118/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9174 - loss: 0.2759 - val_accuracy: 0.9055 - val_loss: 0.2825\n",
            "Epoch 119/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9115 - loss: 0.2910 - val_accuracy: 0.9055 - val_loss: 0.2825\n",
            "Epoch 120/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9089 - loss: 0.2860 - val_accuracy: 0.9055 - val_loss: 0.2823\n",
            "Epoch 121/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9209 - loss: 0.2747 - val_accuracy: 0.9055 - val_loss: 0.2823\n",
            "Epoch 122/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9059 - loss: 0.2802 - val_accuracy: 0.9055 - val_loss: 0.2825\n",
            "Epoch 123/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2811 - val_accuracy: 0.9055 - val_loss: 0.2823\n",
            "Epoch 124/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2512 - val_accuracy: 0.9055 - val_loss: 0.2822\n",
            "Epoch 125/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2816 - val_accuracy: 0.9055 - val_loss: 0.2824\n",
            "Epoch 126/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9134 - loss: 0.2651 - val_accuracy: 0.9055 - val_loss: 0.2822\n",
            "Epoch 127/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9015 - loss: 0.2912 - val_accuracy: 0.9055 - val_loss: 0.2823\n",
            "Epoch 128/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9155 - loss: 0.2683 - val_accuracy: 0.9055 - val_loss: 0.2820\n",
            "Epoch 129/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2786 - val_accuracy: 0.9055 - val_loss: 0.2821\n",
            "Epoch 130/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8867 - loss: 0.3341 - val_accuracy: 0.9055 - val_loss: 0.2821\n",
            "Epoch 131/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9179 - loss: 0.2602 - val_accuracy: 0.9055 - val_loss: 0.2818\n",
            "Epoch 132/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9166 - loss: 0.2746 - val_accuracy: 0.9055 - val_loss: 0.2819\n",
            "Epoch 133/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2818 - val_accuracy: 0.9055 - val_loss: 0.2818\n",
            "Epoch 134/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9044 - loss: 0.2889 - val_accuracy: 0.9055 - val_loss: 0.2820\n",
            "Epoch 135/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2517 - val_accuracy: 0.9055 - val_loss: 0.2824\n",
            "Epoch 136/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2941 - val_accuracy: 0.9055 - val_loss: 0.2821\n",
            "Epoch 137/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8923 - loss: 0.3135 - val_accuracy: 0.9055 - val_loss: 0.2819\n",
            "Epoch 138/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2874 - val_accuracy: 0.9055 - val_loss: 0.2828\n",
            "Epoch 139/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8926 - loss: 0.3093 - val_accuracy: 0.9055 - val_loss: 0.2847\n",
            "Epoch 140/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9198 - loss: 0.2621 - val_accuracy: 0.9055 - val_loss: 0.2821\n",
            "Epoch 141/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9031 - loss: 0.2988 - val_accuracy: 0.9055 - val_loss: 0.2821\n",
            "Model lstm training complete for niche 0.\n",
            "  Final training loss: 0.2726812958717346\n",
            "  Final validation loss: 0.2821107804775238\n",
            "  Final training accuracy: 0.9126478433609009\n",
            "  Final validation accuracy: 0.9054545164108276\n",
            "Training model cnn for niche 0...\n",
            "Epoch 1/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4796 - loss: 0.7360 - val_accuracy: 0.8873 - val_loss: 0.5514\n",
            "Epoch 2/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8451 - loss: 0.5171 - val_accuracy: 0.9055 - val_loss: 0.4103\n",
            "Epoch 3/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.3832 - val_accuracy: 0.9055 - val_loss: 0.3330\n",
            "Epoch 4/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8966 - loss: 0.3466 - val_accuracy: 0.9055 - val_loss: 0.3042\n",
            "Epoch 5/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.3050 - val_accuracy: 0.9055 - val_loss: 0.2954\n",
            "Epoch 6/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9228 - loss: 0.2664 - val_accuracy: 0.9055 - val_loss: 0.2932\n",
            "Epoch 7/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9004 - loss: 0.3108 - val_accuracy: 0.9055 - val_loss: 0.2920\n",
            "Epoch 8/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9058 - loss: 0.2950 - val_accuracy: 0.9055 - val_loss: 0.2912\n",
            "Epoch 9/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9192 - loss: 0.2832 - val_accuracy: 0.9055 - val_loss: 0.2905\n",
            "Epoch 10/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.2949 - val_accuracy: 0.9055 - val_loss: 0.2898\n",
            "Epoch 11/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9121 - loss: 0.2884 - val_accuracy: 0.9055 - val_loss: 0.2889\n",
            "Epoch 12/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8973 - loss: 0.3117 - val_accuracy: 0.9055 - val_loss: 0.2882\n",
            "Epoch 13/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2705 - val_accuracy: 0.9055 - val_loss: 0.2876\n",
            "Epoch 14/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9276 - loss: 0.2501 - val_accuracy: 0.9055 - val_loss: 0.2870\n",
            "Epoch 15/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2627 - val_accuracy: 0.9055 - val_loss: 0.2865\n",
            "Epoch 16/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9188 - loss: 0.2614 - val_accuracy: 0.9055 - val_loss: 0.2859\n",
            "Epoch 17/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.2695 - val_accuracy: 0.9055 - val_loss: 0.2854\n",
            "Epoch 18/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2516 - val_accuracy: 0.9055 - val_loss: 0.2852\n",
            "Epoch 19/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.3146 - val_accuracy: 0.9055 - val_loss: 0.2844\n",
            "Epoch 20/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2711 - val_accuracy: 0.9055 - val_loss: 0.2840\n",
            "Epoch 21/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.2582 - val_accuracy: 0.9055 - val_loss: 0.2839\n",
            "Epoch 22/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2692 - val_accuracy: 0.9055 - val_loss: 0.2833\n",
            "Epoch 23/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9082 - loss: 0.2872 - val_accuracy: 0.9055 - val_loss: 0.2827\n",
            "Epoch 24/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9302 - loss: 0.2385 - val_accuracy: 0.9055 - val_loss: 0.2823\n",
            "Epoch 25/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2541 - val_accuracy: 0.9055 - val_loss: 0.2820\n",
            "Epoch 26/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2571 - val_accuracy: 0.9055 - val_loss: 0.2817\n",
            "Epoch 27/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.2613 - val_accuracy: 0.9055 - val_loss: 0.2803\n",
            "Epoch 28/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.2453 - val_accuracy: 0.9055 - val_loss: 0.2804\n",
            "Epoch 29/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2570 - val_accuracy: 0.9055 - val_loss: 0.2804\n",
            "Epoch 30/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9172 - loss: 0.2670 - val_accuracy: 0.9055 - val_loss: 0.2793\n",
            "Epoch 31/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9112 - loss: 0.2840 - val_accuracy: 0.9055 - val_loss: 0.2791\n",
            "Epoch 32/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.2441 - val_accuracy: 0.9055 - val_loss: 0.2786\n",
            "Epoch 33/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9118 - loss: 0.2813 - val_accuracy: 0.9055 - val_loss: 0.2778\n",
            "Epoch 34/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.2764 - val_accuracy: 0.9055 - val_loss: 0.2779\n",
            "Epoch 35/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9058 - loss: 0.2858 - val_accuracy: 0.9055 - val_loss: 0.2771\n",
            "Epoch 36/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.2855 - val_accuracy: 0.9055 - val_loss: 0.2769\n",
            "Epoch 37/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9080 - loss: 0.2830 - val_accuracy: 0.9055 - val_loss: 0.2765\n",
            "Epoch 38/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9044 - loss: 0.2834 - val_accuracy: 0.9055 - val_loss: 0.2765\n",
            "Epoch 39/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.2666 - val_accuracy: 0.9055 - val_loss: 0.2763\n",
            "Epoch 40/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9113 - loss: 0.2656 - val_accuracy: 0.9055 - val_loss: 0.2760\n",
            "Epoch 41/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.2572 - val_accuracy: 0.9055 - val_loss: 0.2757\n",
            "Epoch 42/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9122 - loss: 0.2610 - val_accuracy: 0.9055 - val_loss: 0.2751\n",
            "Epoch 43/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9080 - loss: 0.2750 - val_accuracy: 0.9055 - val_loss: 0.2748\n",
            "Epoch 44/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9119 - loss: 0.2653 - val_accuracy: 0.9055 - val_loss: 0.2746\n",
            "Epoch 45/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9169 - loss: 0.2599 - val_accuracy: 0.9055 - val_loss: 0.2745\n",
            "Epoch 46/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.2740 - val_accuracy: 0.9055 - val_loss: 0.2743\n",
            "Epoch 47/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.2641 - val_accuracy: 0.9055 - val_loss: 0.2742\n",
            "Epoch 48/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9038 - loss: 0.2761 - val_accuracy: 0.9055 - val_loss: 0.2740\n",
            "Epoch 49/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9220 - loss: 0.2608 - val_accuracy: 0.9055 - val_loss: 0.2739\n",
            "Epoch 50/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.2599 - val_accuracy: 0.9055 - val_loss: 0.2734\n",
            "Epoch 51/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.2577 - val_accuracy: 0.9055 - val_loss: 0.2730\n",
            "Epoch 52/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.2784 - val_accuracy: 0.9055 - val_loss: 0.2726\n",
            "Epoch 53/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.2591 - val_accuracy: 0.9055 - val_loss: 0.2723\n",
            "Epoch 54/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9116 - loss: 0.2597 - val_accuracy: 0.9055 - val_loss: 0.2720\n",
            "Epoch 55/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.2649 - val_accuracy: 0.9055 - val_loss: 0.2716\n",
            "Epoch 56/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.2811 - val_accuracy: 0.9055 - val_loss: 0.2717\n",
            "Epoch 57/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9325 - loss: 0.2221 - val_accuracy: 0.9055 - val_loss: 0.2719\n",
            "Epoch 58/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.2743 - val_accuracy: 0.9055 - val_loss: 0.2711\n",
            "Epoch 59/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.2826 - val_accuracy: 0.9055 - val_loss: 0.2711\n",
            "Epoch 60/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9145 - loss: 0.2628 - val_accuracy: 0.9055 - val_loss: 0.2715\n",
            "Epoch 61/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9077 - loss: 0.2864 - val_accuracy: 0.9055 - val_loss: 0.2711\n",
            "Epoch 62/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2723 - val_accuracy: 0.9055 - val_loss: 0.2711\n",
            "Epoch 63/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.2569 - val_accuracy: 0.9055 - val_loss: 0.2705\n",
            "Epoch 64/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9097 - loss: 0.2554 - val_accuracy: 0.9055 - val_loss: 0.2700\n",
            "Epoch 65/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2551 - val_accuracy: 0.9055 - val_loss: 0.2706\n",
            "Epoch 66/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.2865 - val_accuracy: 0.9055 - val_loss: 0.2697\n",
            "Epoch 67/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2529 - val_accuracy: 0.9055 - val_loss: 0.2698\n",
            "Epoch 68/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9021 - loss: 0.2762 - val_accuracy: 0.9055 - val_loss: 0.2695\n",
            "Epoch 69/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9087 - loss: 0.2751 - val_accuracy: 0.9055 - val_loss: 0.2694\n",
            "Epoch 70/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.2486 - val_accuracy: 0.9055 - val_loss: 0.2690\n",
            "Epoch 71/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9225 - loss: 0.2389 - val_accuracy: 0.9055 - val_loss: 0.2692\n",
            "Epoch 72/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2563 - val_accuracy: 0.9055 - val_loss: 0.2691\n",
            "Epoch 73/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.2554 - val_accuracy: 0.9055 - val_loss: 0.2690\n",
            "Epoch 74/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9033 - loss: 0.2915 - val_accuracy: 0.9055 - val_loss: 0.2687\n",
            "Epoch 75/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9083 - loss: 0.2715 - val_accuracy: 0.9055 - val_loss: 0.2691\n",
            "Epoch 76/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.2633 - val_accuracy: 0.9055 - val_loss: 0.2689\n",
            "Epoch 77/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.2842 - val_accuracy: 0.9055 - val_loss: 0.2681\n",
            "Epoch 78/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2712 - val_accuracy: 0.9055 - val_loss: 0.2690\n",
            "Epoch 79/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2620 - val_accuracy: 0.9055 - val_loss: 0.2682\n",
            "Epoch 80/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9178 - loss: 0.2609 - val_accuracy: 0.9055 - val_loss: 0.2676\n",
            "Epoch 81/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2690 - val_accuracy: 0.9055 - val_loss: 0.2676\n",
            "Epoch 82/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2735 - val_accuracy: 0.9055 - val_loss: 0.2674\n",
            "Epoch 83/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.2738 - val_accuracy: 0.9055 - val_loss: 0.2678\n",
            "Epoch 84/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2464 - val_accuracy: 0.9055 - val_loss: 0.2681\n",
            "Epoch 85/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2584 - val_accuracy: 0.9055 - val_loss: 0.2675\n",
            "Epoch 86/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9066 - loss: 0.2683 - val_accuracy: 0.9055 - val_loss: 0.2667\n",
            "Epoch 87/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2771 - val_accuracy: 0.9055 - val_loss: 0.2678\n",
            "Epoch 88/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9111 - loss: 0.2577 - val_accuracy: 0.9055 - val_loss: 0.2665\n",
            "Epoch 89/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2529 - val_accuracy: 0.9055 - val_loss: 0.2667\n",
            "Epoch 90/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2732 - val_accuracy: 0.9055 - val_loss: 0.2670\n",
            "Epoch 91/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.2809 - val_accuracy: 0.9055 - val_loss: 0.2665\n",
            "Epoch 92/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2667 - val_accuracy: 0.9055 - val_loss: 0.2661\n",
            "Epoch 93/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2443 - val_accuracy: 0.9055 - val_loss: 0.2656\n",
            "Epoch 94/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2591 - val_accuracy: 0.9055 - val_loss: 0.2659\n",
            "Epoch 95/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9321 - loss: 0.2172 - val_accuracy: 0.9055 - val_loss: 0.2663\n",
            "Epoch 96/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.2631 - val_accuracy: 0.9055 - val_loss: 0.2655\n",
            "Epoch 97/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2588 - val_accuracy: 0.9055 - val_loss: 0.2658\n",
            "Epoch 98/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9067 - loss: 0.2729 - val_accuracy: 0.9055 - val_loss: 0.2654\n",
            "Epoch 99/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.2544 - val_accuracy: 0.9055 - val_loss: 0.2651\n",
            "Epoch 100/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9090 - loss: 0.2831 - val_accuracy: 0.9055 - val_loss: 0.2648\n",
            "Epoch 101/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2362 - val_accuracy: 0.9055 - val_loss: 0.2657\n",
            "Epoch 102/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2541 - val_accuracy: 0.9055 - val_loss: 0.2655\n",
            "Epoch 103/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2531 - val_accuracy: 0.9055 - val_loss: 0.2650\n",
            "Epoch 104/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2469 - val_accuracy: 0.9055 - val_loss: 0.2652\n",
            "Epoch 105/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.3087 - val_accuracy: 0.9055 - val_loss: 0.2650\n",
            "Epoch 106/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.2838 - val_accuracy: 0.9055 - val_loss: 0.2651\n",
            "Epoch 107/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.2869 - val_accuracy: 0.9055 - val_loss: 0.2652\n",
            "Epoch 108/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.2668 - val_accuracy: 0.9055 - val_loss: 0.2653\n",
            "Epoch 109/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.2727 - val_accuracy: 0.9055 - val_loss: 0.2646\n",
            "Epoch 110/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.2630 - val_accuracy: 0.9055 - val_loss: 0.2652\n",
            "Epoch 111/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2462 - val_accuracy: 0.9055 - val_loss: 0.2647\n",
            "Epoch 112/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2447 - val_accuracy: 0.9055 - val_loss: 0.2649\n",
            "Epoch 113/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.2638 - val_accuracy: 0.9055 - val_loss: 0.2648\n",
            "Epoch 114/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 0.2930 - val_accuracy: 0.9055 - val_loss: 0.2632\n",
            "Epoch 115/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2613 - val_accuracy: 0.9055 - val_loss: 0.2639\n",
            "Epoch 116/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9034 - loss: 0.2868 - val_accuracy: 0.9055 - val_loss: 0.2636\n",
            "Epoch 117/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2781 - val_accuracy: 0.9055 - val_loss: 0.2636\n",
            "Epoch 118/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9214 - loss: 0.2480 - val_accuracy: 0.9055 - val_loss: 0.2632\n",
            "Epoch 119/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 0.2660 - val_accuracy: 0.9055 - val_loss: 0.2630\n",
            "Epoch 120/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2516 - val_accuracy: 0.9055 - val_loss: 0.2634\n",
            "Epoch 121/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9087 - loss: 0.2714 - val_accuracy: 0.9055 - val_loss: 0.2630\n",
            "Epoch 122/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2548 - val_accuracy: 0.9055 - val_loss: 0.2636\n",
            "Epoch 123/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2553 - val_accuracy: 0.9055 - val_loss: 0.2630\n",
            "Epoch 124/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2657 - val_accuracy: 0.9055 - val_loss: 0.2634\n",
            "Epoch 125/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2696 - val_accuracy: 0.9055 - val_loss: 0.2631\n",
            "Epoch 126/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2553 - val_accuracy: 0.9055 - val_loss: 0.2634\n",
            "Epoch 127/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.2677 - val_accuracy: 0.9055 - val_loss: 0.2631\n",
            "Epoch 128/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2487 - val_accuracy: 0.9055 - val_loss: 0.2628\n",
            "Epoch 129/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2649 - val_accuracy: 0.9055 - val_loss: 0.2627\n",
            "Epoch 130/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.2577 - val_accuracy: 0.9055 - val_loss: 0.2620\n",
            "Epoch 131/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2315 - val_accuracy: 0.9055 - val_loss: 0.2625\n",
            "Epoch 132/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2628 - val_accuracy: 0.9055 - val_loss: 0.2626\n",
            "Epoch 133/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2581 - val_accuracy: 0.9055 - val_loss: 0.2624\n",
            "Epoch 134/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 0.2521 - val_accuracy: 0.9055 - val_loss: 0.2626\n",
            "Epoch 135/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2397 - val_accuracy: 0.9055 - val_loss: 0.2625\n",
            "Epoch 136/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.2687 - val_accuracy: 0.9055 - val_loss: 0.2619\n",
            "Epoch 137/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9043 - loss: 0.2786 - val_accuracy: 0.9055 - val_loss: 0.2621\n",
            "Epoch 138/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.2402 - val_accuracy: 0.9055 - val_loss: 0.2630\n",
            "Epoch 139/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2635 - val_accuracy: 0.9055 - val_loss: 0.2617\n",
            "Epoch 140/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2647 - val_accuracy: 0.9055 - val_loss: 0.2617\n",
            "Epoch 141/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2416 - val_accuracy: 0.9055 - val_loss: 0.2623\n",
            "Epoch 142/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.2497 - val_accuracy: 0.9055 - val_loss: 0.2622\n",
            "Epoch 143/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.2806 - val_accuracy: 0.9055 - val_loss: 0.2623\n",
            "Epoch 144/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9036 - loss: 0.2689 - val_accuracy: 0.9055 - val_loss: 0.2625\n",
            "Epoch 145/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9258 - loss: 0.2263 - val_accuracy: 0.9055 - val_loss: 0.2616\n",
            "Epoch 146/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.2703 - val_accuracy: 0.9055 - val_loss: 0.2616\n",
            "Epoch 147/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9086 - loss: 0.2781 - val_accuracy: 0.9055 - val_loss: 0.2610\n",
            "Epoch 148/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2740 - val_accuracy: 0.9055 - val_loss: 0.2613\n",
            "Epoch 149/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.2655 - val_accuracy: 0.9055 - val_loss: 0.2613\n",
            "Epoch 150/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.2758 - val_accuracy: 0.9055 - val_loss: 0.2614\n",
            "Epoch 151/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2629 - val_accuracy: 0.9055 - val_loss: 0.2607\n",
            "Epoch 152/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2543 - val_accuracy: 0.9055 - val_loss: 0.2606\n",
            "Epoch 153/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2555 - val_accuracy: 0.9055 - val_loss: 0.2612\n",
            "Epoch 154/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.2616 - val_accuracy: 0.9055 - val_loss: 0.2609\n",
            "Epoch 155/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2785 - val_accuracy: 0.9055 - val_loss: 0.2609\n",
            "Epoch 156/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2515 - val_accuracy: 0.9055 - val_loss: 0.2610\n",
            "Epoch 157/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9157 - loss: 0.2521 - val_accuracy: 0.9055 - val_loss: 0.2606\n",
            "Epoch 158/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9022 - loss: 0.2657 - val_accuracy: 0.9055 - val_loss: 0.2603\n",
            "Epoch 159/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.2662 - val_accuracy: 0.9055 - val_loss: 0.2603\n",
            "Epoch 160/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2855 - val_accuracy: 0.9055 - val_loss: 0.2606\n",
            "Epoch 161/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.2900 - val_accuracy: 0.9055 - val_loss: 0.2611\n",
            "Epoch 162/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.2336 - val_accuracy: 0.9055 - val_loss: 0.2615\n",
            "Epoch 163/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2682 - val_accuracy: 0.9055 - val_loss: 0.2600\n",
            "Epoch 164/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.2561 - val_accuracy: 0.9055 - val_loss: 0.2608\n",
            "Epoch 165/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2621 - val_accuracy: 0.9055 - val_loss: 0.2605\n",
            "Epoch 166/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2558 - val_accuracy: 0.9055 - val_loss: 0.2607\n",
            "Epoch 167/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2537 - val_accuracy: 0.9055 - val_loss: 0.2605\n",
            "Epoch 168/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.2831 - val_accuracy: 0.9055 - val_loss: 0.2601\n",
            "Epoch 169/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2400 - val_accuracy: 0.9055 - val_loss: 0.2608\n",
            "Epoch 170/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.2747 - val_accuracy: 0.9055 - val_loss: 0.2605\n",
            "Epoch 171/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2568 - val_accuracy: 0.9055 - val_loss: 0.2611\n",
            "Epoch 172/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2344 - val_accuracy: 0.9055 - val_loss: 0.2608\n",
            "Epoch 173/1000\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2636 - val_accuracy: 0.9055 - val_loss: 0.2606\n",
            "Model cnn training complete for niche 0.\n",
            "  Final training loss: 0.2581509053707123\n",
            "  Final validation loss: 0.2606010437011719\n",
            "  Final training accuracy: 0.9126478433609009\n",
            "  Final validation accuracy: 0.9054545164108276\n",
            "Training model random_forest for niche 0...\n",
            "Training model mlp_financial for niche 7...\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8543 - loss: 0.4717 - val_accuracy: 0.9539 - val_loss: 0.3509\n",
            "Epoch 2/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9024 - loss: 0.4022 - val_accuracy: 0.9539 - val_loss: 0.2910\n",
            "Epoch 3/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 0.3455 - val_accuracy: 0.9539 - val_loss: 0.2571\n",
            "Epoch 4/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.3441 - val_accuracy: 0.9539 - val_loss: 0.2416\n",
            "Epoch 5/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.3330 - val_accuracy: 0.9539 - val_loss: 0.2318\n",
            "Epoch 6/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.2820 - val_accuracy: 0.9539 - val_loss: 0.2249\n",
            "Epoch 7/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.3272 - val_accuracy: 0.9539 - val_loss: 0.2227\n",
            "Epoch 8/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.3101 - val_accuracy: 0.9539 - val_loss: 0.2212\n",
            "Epoch 9/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.2757 - val_accuracy: 0.9539 - val_loss: 0.2179\n",
            "Epoch 10/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.3284 - val_accuracy: 0.9539 - val_loss: 0.2156\n",
            "Epoch 11/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.3210 - val_accuracy: 0.9539 - val_loss: 0.2141\n",
            "Epoch 12/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9370 - loss: 0.3209 - val_accuracy: 0.9539 - val_loss: 0.2136\n",
            "Epoch 13/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 0.3123 - val_accuracy: 0.9539 - val_loss: 0.2131\n",
            "Epoch 14/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9295 - loss: 0.3020 - val_accuracy: 0.9539 - val_loss: 0.2119\n",
            "Epoch 15/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.2999 - val_accuracy: 0.9539 - val_loss: 0.2107\n",
            "Epoch 16/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9372 - loss: 0.2691 - val_accuracy: 0.9539 - val_loss: 0.2118\n",
            "Epoch 17/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.3037 - val_accuracy: 0.9539 - val_loss: 0.2097\n",
            "Epoch 18/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.2604 - val_accuracy: 0.9539 - val_loss: 0.2079\n",
            "Epoch 19/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.3317 - val_accuracy: 0.9539 - val_loss: 0.2065\n",
            "Epoch 20/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.2715 - val_accuracy: 0.9539 - val_loss: 0.2047\n",
            "Epoch 21/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9223 - loss: 0.3390 - val_accuracy: 0.9539 - val_loss: 0.2041\n",
            "Epoch 22/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.2993 - val_accuracy: 0.9539 - val_loss: 0.2028\n",
            "Epoch 23/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.2778 - val_accuracy: 0.9539 - val_loss: 0.2005\n",
            "Epoch 24/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.2530 - val_accuracy: 0.9539 - val_loss: 0.1991\n",
            "Epoch 25/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.2902 - val_accuracy: 0.9539 - val_loss: 0.1994\n",
            "Epoch 26/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.2621 - val_accuracy: 0.9539 - val_loss: 0.1982\n",
            "Epoch 27/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.2793 - val_accuracy: 0.9539 - val_loss: 0.1972\n",
            "Epoch 28/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.2554 - val_accuracy: 0.9539 - val_loss: 0.1959\n",
            "Epoch 29/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.2331 - val_accuracy: 0.9539 - val_loss: 0.1952\n",
            "Epoch 30/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.2381 - val_accuracy: 0.9539 - val_loss: 0.1948\n",
            "Epoch 31/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.2884 - val_accuracy: 0.9539 - val_loss: 0.1949\n",
            "Epoch 32/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.2254 - val_accuracy: 0.9539 - val_loss: 0.1957\n",
            "Epoch 33/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9237 - loss: 0.3064 - val_accuracy: 0.9539 - val_loss: 0.1951\n",
            "Epoch 34/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.2187 - val_accuracy: 0.9539 - val_loss: 0.1939\n",
            "Epoch 35/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.2353 - val_accuracy: 0.9539 - val_loss: 0.1944\n",
            "Epoch 36/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.2659 - val_accuracy: 0.9539 - val_loss: 0.1960\n",
            "Epoch 37/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9419 - loss: 0.2816 - val_accuracy: 0.9539 - val_loss: 0.1951\n",
            "Epoch 38/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9400 - loss: 0.2756 - val_accuracy: 0.9539 - val_loss: 0.1949\n",
            "Epoch 39/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.2631 - val_accuracy: 0.9539 - val_loss: 0.1951\n",
            "Epoch 40/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.2630 - val_accuracy: 0.9539 - val_loss: 0.1948\n",
            "Epoch 41/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.2689 - val_accuracy: 0.9539 - val_loss: 0.1939\n",
            "Epoch 42/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2494 - val_accuracy: 0.9539 - val_loss: 0.1942\n",
            "Epoch 43/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.2436 - val_accuracy: 0.9539 - val_loss: 0.1932\n",
            "Epoch 44/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.2496 - val_accuracy: 0.9539 - val_loss: 0.1929\n",
            "Epoch 45/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.2253 - val_accuracy: 0.9539 - val_loss: 0.1922\n",
            "Epoch 46/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.2319 - val_accuracy: 0.9539 - val_loss: 0.1910\n",
            "Epoch 47/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.2704 - val_accuracy: 0.9539 - val_loss: 0.1908\n",
            "Epoch 48/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.2533 - val_accuracy: 0.9539 - val_loss: 0.1909\n",
            "Epoch 49/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.2756 - val_accuracy: 0.9539 - val_loss: 0.1911\n",
            "Epoch 50/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.2524 - val_accuracy: 0.9539 - val_loss: 0.1906\n",
            "Epoch 51/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9606 - loss: 0.1956 - val_accuracy: 0.9539 - val_loss: 0.1901\n",
            "Epoch 52/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.2247 - val_accuracy: 0.9539 - val_loss: 0.1911\n",
            "Epoch 53/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.2586 - val_accuracy: 0.9539 - val_loss: 0.1917\n",
            "Epoch 54/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.2441 - val_accuracy: 0.9539 - val_loss: 0.1922\n",
            "Epoch 55/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2664 - val_accuracy: 0.9539 - val_loss: 0.1928\n",
            "Epoch 56/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.2240 - val_accuracy: 0.9539 - val_loss: 0.1932\n",
            "Epoch 57/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1865 - val_accuracy: 0.9539 - val_loss: 0.1922\n",
            "Epoch 58/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.2317 - val_accuracy: 0.9539 - val_loss: 0.1928\n",
            "Epoch 59/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9308 - loss: 0.2655 - val_accuracy: 0.9539 - val_loss: 0.1931\n",
            "Epoch 60/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.2085 - val_accuracy: 0.9539 - val_loss: 0.1917\n",
            "Epoch 61/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.2721 - val_accuracy: 0.9539 - val_loss: 0.1917\n",
            "Model mlp_financial training complete for niche 7.\n",
            "  Final training loss: 0.24305561184883118\n",
            "  Final validation loss: 0.19167670607566833\n",
            "  Final training accuracy: 0.9387417435646057\n",
            "  Final validation accuracy: 0.9539473652839661\n",
            "Training model mlp_market for niche 7...\n",
            "Epoch 1/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6064 - loss: 0.6742 - val_accuracy: 0.9605 - val_loss: 0.4527\n",
            "Epoch 2/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.5480 - val_accuracy: 0.9539 - val_loss: 0.3603\n",
            "Epoch 3/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 0.4481 - val_accuracy: 0.9539 - val_loss: 0.2995\n",
            "Epoch 4/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.3920 - val_accuracy: 0.9539 - val_loss: 0.2594\n",
            "Epoch 5/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.3571 - val_accuracy: 0.9539 - val_loss: 0.2347\n",
            "Epoch 6/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.3596 - val_accuracy: 0.9539 - val_loss: 0.2171\n",
            "Epoch 7/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9194 - loss: 0.3254 - val_accuracy: 0.9539 - val_loss: 0.2061\n",
            "Epoch 8/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9303 - loss: 0.3568 - val_accuracy: 0.9539 - val_loss: 0.2009\n",
            "Epoch 9/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.3156 - val_accuracy: 0.9539 - val_loss: 0.1959\n",
            "Epoch 10/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.3269 - val_accuracy: 0.9539 - val_loss: 0.1944\n",
            "Epoch 11/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.3559 - val_accuracy: 0.9539 - val_loss: 0.1929\n",
            "Epoch 12/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9276 - loss: 0.3030 - val_accuracy: 0.9539 - val_loss: 0.1905\n",
            "Epoch 13/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.2647 - val_accuracy: 0.9539 - val_loss: 0.1888\n",
            "Epoch 14/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.3519 - val_accuracy: 0.9539 - val_loss: 0.1899\n",
            "Epoch 15/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.3194 - val_accuracy: 0.9539 - val_loss: 0.1900\n",
            "Epoch 16/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.3070 - val_accuracy: 0.9539 - val_loss: 0.1898\n",
            "Epoch 17/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.3120 - val_accuracy: 0.9539 - val_loss: 0.1910\n",
            "Epoch 18/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.3086 - val_accuracy: 0.9539 - val_loss: 0.1906\n",
            "Epoch 19/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.2717 - val_accuracy: 0.9539 - val_loss: 0.1901\n",
            "Epoch 20/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.3266 - val_accuracy: 0.9539 - val_loss: 0.1908\n",
            "Epoch 21/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.3106 - val_accuracy: 0.9539 - val_loss: 0.1898\n",
            "Epoch 22/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.2631 - val_accuracy: 0.9539 - val_loss: 0.1887\n",
            "Epoch 23/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9476 - loss: 0.2544 - val_accuracy: 0.9539 - val_loss: 0.1883\n",
            "Epoch 24/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2719 - val_accuracy: 0.9539 - val_loss: 0.1904\n",
            "Epoch 25/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.3329 - val_accuracy: 0.9539 - val_loss: 0.1901\n",
            "Epoch 26/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.2861 - val_accuracy: 0.9539 - val_loss: 0.1897\n",
            "Epoch 27/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9448 - loss: 0.2728 - val_accuracy: 0.9539 - val_loss: 0.1899\n",
            "Epoch 28/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.2630 - val_accuracy: 0.9539 - val_loss: 0.1896\n",
            "Epoch 29/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9448 - loss: 0.2653 - val_accuracy: 0.9539 - val_loss: 0.1891\n",
            "Epoch 30/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9331 - loss: 0.2970 - val_accuracy: 0.9539 - val_loss: 0.1884\n",
            "Epoch 31/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.3127 - val_accuracy: 0.9539 - val_loss: 0.1883\n",
            "Epoch 32/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.2761 - val_accuracy: 0.9539 - val_loss: 0.1885\n",
            "Epoch 33/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.2600 - val_accuracy: 0.9539 - val_loss: 0.1884\n",
            "Epoch 34/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.2593 - val_accuracy: 0.9539 - val_loss: 0.1880\n",
            "Epoch 35/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.2557 - val_accuracy: 0.9539 - val_loss: 0.1876\n",
            "Epoch 36/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.2856 - val_accuracy: 0.9539 - val_loss: 0.1875\n",
            "Epoch 37/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.2671 - val_accuracy: 0.9539 - val_loss: 0.1884\n",
            "Epoch 38/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.2468 - val_accuracy: 0.9539 - val_loss: 0.1888\n",
            "Epoch 39/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.2699 - val_accuracy: 0.9539 - val_loss: 0.1886\n",
            "Epoch 40/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.2231 - val_accuracy: 0.9539 - val_loss: 0.1880\n",
            "Epoch 41/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2745 - val_accuracy: 0.9539 - val_loss: 0.1893\n",
            "Epoch 42/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9371 - loss: 0.2607 - val_accuracy: 0.9539 - val_loss: 0.1882\n",
            "Epoch 43/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.2911 - val_accuracy: 0.9539 - val_loss: 0.1867\n",
            "Epoch 44/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9342 - loss: 0.2561 - val_accuracy: 0.9539 - val_loss: 0.1858\n",
            "Epoch 45/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.2571 - val_accuracy: 0.9539 - val_loss: 0.1862\n",
            "Epoch 46/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.2502 - val_accuracy: 0.9539 - val_loss: 0.1867\n",
            "Epoch 47/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.2449 - val_accuracy: 0.9539 - val_loss: 0.1872\n",
            "Epoch 48/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.3001 - val_accuracy: 0.9539 - val_loss: 0.1888\n",
            "Epoch 49/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.2532 - val_accuracy: 0.9539 - val_loss: 0.1874\n",
            "Epoch 50/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.2290 - val_accuracy: 0.9539 - val_loss: 0.1865\n",
            "Epoch 51/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2943 - val_accuracy: 0.9539 - val_loss: 0.1864\n",
            "Epoch 52/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9373 - loss: 0.2700 - val_accuracy: 0.9539 - val_loss: 0.1851\n",
            "Epoch 53/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.2795 - val_accuracy: 0.9539 - val_loss: 0.1853\n",
            "Epoch 54/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.2080 - val_accuracy: 0.9539 - val_loss: 0.1845\n",
            "Epoch 55/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.2584 - val_accuracy: 0.9539 - val_loss: 0.1847\n",
            "Epoch 56/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.2293 - val_accuracy: 0.9539 - val_loss: 0.1863\n",
            "Epoch 57/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.2642 - val_accuracy: 0.9539 - val_loss: 0.1854\n",
            "Epoch 58/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.2244 - val_accuracy: 0.9539 - val_loss: 0.1844\n",
            "Epoch 59/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.2297 - val_accuracy: 0.9539 - val_loss: 0.1843\n",
            "Epoch 60/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.2500 - val_accuracy: 0.9539 - val_loss: 0.1836\n",
            "Epoch 61/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.2439 - val_accuracy: 0.9539 - val_loss: 0.1830\n",
            "Epoch 62/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.2532 - val_accuracy: 0.9539 - val_loss: 0.1828\n",
            "Epoch 63/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9441 - loss: 0.2491 - val_accuracy: 0.9539 - val_loss: 0.1830\n",
            "Epoch 64/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.2278 - val_accuracy: 0.9539 - val_loss: 0.1829\n",
            "Epoch 65/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.2712 - val_accuracy: 0.9539 - val_loss: 0.1828\n",
            "Epoch 66/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9362 - loss: 0.2476 - val_accuracy: 0.9539 - val_loss: 0.1827\n",
            "Epoch 67/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9389 - loss: 0.2535 - val_accuracy: 0.9539 - val_loss: 0.1826\n",
            "Epoch 68/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.2477 - val_accuracy: 0.9539 - val_loss: 0.1822\n",
            "Epoch 69/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.2218 - val_accuracy: 0.9539 - val_loss: 0.1820\n",
            "Epoch 70/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.2746 - val_accuracy: 0.9539 - val_loss: 0.1818\n",
            "Epoch 71/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.2503 - val_accuracy: 0.9539 - val_loss: 0.1813\n",
            "Epoch 72/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.2477 - val_accuracy: 0.9539 - val_loss: 0.1809\n",
            "Epoch 73/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9367 - loss: 0.2566 - val_accuracy: 0.9539 - val_loss: 0.1815\n",
            "Epoch 74/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.2365 - val_accuracy: 0.9539 - val_loss: 0.1812\n",
            "Epoch 75/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.2159 - val_accuracy: 0.9539 - val_loss: 0.1823\n",
            "Epoch 76/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.2513 - val_accuracy: 0.9539 - val_loss: 0.1825\n",
            "Epoch 77/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9336 - loss: 0.2697 - val_accuracy: 0.9539 - val_loss: 0.1824\n",
            "Epoch 78/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.2139 - val_accuracy: 0.9539 - val_loss: 0.1818\n",
            "Epoch 79/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.2452 - val_accuracy: 0.9539 - val_loss: 0.1810\n",
            "Epoch 80/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2703 - val_accuracy: 0.9539 - val_loss: 0.1810\n",
            "Epoch 81/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.2827 - val_accuracy: 0.9539 - val_loss: 0.1811\n",
            "Epoch 82/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 0.2216 - val_accuracy: 0.9539 - val_loss: 0.1819\n",
            "Model mlp_market training complete for niche 7.\n",
            "  Final training loss: 0.2248622626066208\n",
            "  Final validation loss: 0.18188565969467163\n",
            "  Final training accuracy: 0.9387417435646057\n",
            "  Final validation accuracy: 0.9539473652839661\n",
            "Training model lstm for niche 7...\n",
            "Epoch 1/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6752 - loss: 0.6653 - val_accuracy: 0.9539 - val_loss: 0.5962\n",
            "Epoch 2/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9202 - loss: 0.5845 - val_accuracy: 0.9539 - val_loss: 0.5041\n",
            "Epoch 3/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9333 - loss: 0.4950 - val_accuracy: 0.9539 - val_loss: 0.3788\n",
            "Epoch 4/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9437 - loss: 0.3623 - val_accuracy: 0.9539 - val_loss: 0.2297\n",
            "Epoch 5/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9406 - loss: 0.2954 - val_accuracy: 0.9539 - val_loss: 0.2031\n",
            "Epoch 6/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9302 - loss: 0.2954 - val_accuracy: 0.9539 - val_loss: 0.2097\n",
            "Epoch 7/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9293 - loss: 0.3254 - val_accuracy: 0.9539 - val_loss: 0.1982\n",
            "Epoch 8/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.2371 - val_accuracy: 0.9539 - val_loss: 0.1927\n",
            "Epoch 9/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.3100 - val_accuracy: 0.9539 - val_loss: 0.1962\n",
            "Epoch 10/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9397 - loss: 0.2896 - val_accuracy: 0.9539 - val_loss: 0.1852\n",
            "Epoch 11/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9278 - loss: 0.3063 - val_accuracy: 0.9539 - val_loss: 0.1840\n",
            "Epoch 12/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.2396 - val_accuracy: 0.9539 - val_loss: 0.1774\n",
            "Epoch 13/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9395 - loss: 0.2691 - val_accuracy: 0.9539 - val_loss: 0.1947\n",
            "Epoch 14/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.3144 - val_accuracy: 0.9539 - val_loss: 0.1829\n",
            "Epoch 15/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.3219 - val_accuracy: 0.9539 - val_loss: 0.1791\n",
            "Epoch 16/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9498 - loss: 0.2384 - val_accuracy: 0.9539 - val_loss: 0.1776\n",
            "Epoch 17/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9427 - loss: 0.2629 - val_accuracy: 0.9539 - val_loss: 0.1853\n",
            "Epoch 18/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9306 - loss: 0.2974 - val_accuracy: 0.9539 - val_loss: 0.1797\n",
            "Epoch 19/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9294 - loss: 0.3138 - val_accuracy: 0.9539 - val_loss: 0.1789\n",
            "Epoch 20/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9568 - loss: 0.2320 - val_accuracy: 0.9539 - val_loss: 0.1756\n",
            "Epoch 21/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9247 - loss: 0.3162 - val_accuracy: 0.9539 - val_loss: 0.1765\n",
            "Epoch 22/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9603 - loss: 0.2003 - val_accuracy: 0.9539 - val_loss: 0.1752\n",
            "Epoch 23/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.2775 - val_accuracy: 0.9539 - val_loss: 0.1778\n",
            "Epoch 24/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9328 - loss: 0.2616 - val_accuracy: 0.9539 - val_loss: 0.1723\n",
            "Epoch 25/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.2448 - val_accuracy: 0.9539 - val_loss: 0.1754\n",
            "Epoch 26/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9411 - loss: 0.2383 - val_accuracy: 0.9539 - val_loss: 0.1748\n",
            "Epoch 27/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9432 - loss: 0.2460 - val_accuracy: 0.9539 - val_loss: 0.1732\n",
            "Epoch 28/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.2691 - val_accuracy: 0.9539 - val_loss: 0.1727\n",
            "Epoch 29/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.2445 - val_accuracy: 0.9539 - val_loss: 0.1721\n",
            "Epoch 30/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9262 - loss: 0.3036 - val_accuracy: 0.9539 - val_loss: 0.1768\n",
            "Epoch 31/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.2522 - val_accuracy: 0.9539 - val_loss: 0.1709\n",
            "Epoch 32/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9343 - loss: 0.2721 - val_accuracy: 0.9539 - val_loss: 0.1733\n",
            "Epoch 33/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.3011 - val_accuracy: 0.9539 - val_loss: 0.1771\n",
            "Epoch 34/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9445 - loss: 0.2436 - val_accuracy: 0.9539 - val_loss: 0.1716\n",
            "Epoch 35/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9535 - loss: 0.2075 - val_accuracy: 0.9539 - val_loss: 0.1718\n",
            "Epoch 36/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.3266 - val_accuracy: 0.9539 - val_loss: 0.1734\n",
            "Epoch 37/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9394 - loss: 0.2450 - val_accuracy: 0.9539 - val_loss: 0.1719\n",
            "Epoch 38/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.2600 - val_accuracy: 0.9539 - val_loss: 0.1732\n",
            "Epoch 39/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9521 - loss: 0.1957 - val_accuracy: 0.9539 - val_loss: 0.1726\n",
            "Epoch 40/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9283 - loss: 0.2813 - val_accuracy: 0.9539 - val_loss: 0.1721\n",
            "Epoch 41/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 0.2506 - val_accuracy: 0.9539 - val_loss: 0.1676\n",
            "Epoch 42/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9323 - loss: 0.2869 - val_accuracy: 0.9539 - val_loss: 0.1738\n",
            "Epoch 43/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.2493 - val_accuracy: 0.9539 - val_loss: 0.1708\n",
            "Epoch 44/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.2236 - val_accuracy: 0.9539 - val_loss: 0.1707\n",
            "Epoch 45/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9485 - loss: 0.2499 - val_accuracy: 0.9539 - val_loss: 0.1723\n",
            "Epoch 46/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.2659 - val_accuracy: 0.9539 - val_loss: 0.1787\n",
            "Epoch 47/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9374 - loss: 0.2436 - val_accuracy: 0.9539 - val_loss: 0.1689\n",
            "Epoch 48/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9473 - loss: 0.2453 - val_accuracy: 0.9539 - val_loss: 0.1689\n",
            "Epoch 49/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9409 - loss: 0.2405 - val_accuracy: 0.9539 - val_loss: 0.1757\n",
            "Epoch 50/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9566 - loss: 0.2134 - val_accuracy: 0.9539 - val_loss: 0.1695\n",
            "Epoch 51/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9346 - loss: 0.2439 - val_accuracy: 0.9539 - val_loss: 0.1715\n",
            "Model lstm training complete for niche 7.\n",
            "  Final training loss: 0.2412586361169815\n",
            "  Final validation loss: 0.1715441197156906\n",
            "  Final training accuracy: 0.9387417435646057\n",
            "  Final validation accuracy: 0.9539473652839661\n",
            "Training model cnn for niche 7...\n",
            "Epoch 1/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6464 - loss: 0.6433 - val_accuracy: 0.9539 - val_loss: 0.5092\n",
            "Epoch 2/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.5010 - val_accuracy: 0.9539 - val_loss: 0.4015\n",
            "Epoch 3/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.4167 - val_accuracy: 0.9539 - val_loss: 0.3249\n",
            "Epoch 4/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.3517 - val_accuracy: 0.9539 - val_loss: 0.2780\n",
            "Epoch 5/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9248 - loss: 0.3306 - val_accuracy: 0.9539 - val_loss: 0.2465\n",
            "Epoch 6/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9374 - loss: 0.2882 - val_accuracy: 0.9539 - val_loss: 0.2252\n",
            "Epoch 7/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.2462 - val_accuracy: 0.9539 - val_loss: 0.2098\n",
            "Epoch 8/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.2761 - val_accuracy: 0.9539 - val_loss: 0.2028\n",
            "Epoch 9/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9402 - loss: 0.2372 - val_accuracy: 0.9539 - val_loss: 0.1975\n",
            "Epoch 10/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9429 - loss: 0.2416 - val_accuracy: 0.9539 - val_loss: 0.1952\n",
            "Epoch 11/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9292 - loss: 0.2775 - val_accuracy: 0.9539 - val_loss: 0.1929\n",
            "Epoch 12/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9476 - loss: 0.2248 - val_accuracy: 0.9539 - val_loss: 0.1908\n",
            "Epoch 13/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9391 - loss: 0.2388 - val_accuracy: 0.9539 - val_loss: 0.1894\n",
            "Epoch 14/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9390 - loss: 0.2380 - val_accuracy: 0.9539 - val_loss: 0.1883\n",
            "Epoch 15/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.2148 - val_accuracy: 0.9539 - val_loss: 0.1873\n",
            "Epoch 16/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 0.2551 - val_accuracy: 0.9539 - val_loss: 0.1864\n",
            "Epoch 17/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9387 - loss: 0.2260 - val_accuracy: 0.9539 - val_loss: 0.1853\n",
            "Epoch 18/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.2495 - val_accuracy: 0.9539 - val_loss: 0.1847\n",
            "Epoch 19/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.1963 - val_accuracy: 0.9539 - val_loss: 0.1837\n",
            "Epoch 20/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.2112 - val_accuracy: 0.9539 - val_loss: 0.1829\n",
            "Epoch 21/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9361 - loss: 0.2459 - val_accuracy: 0.9539 - val_loss: 0.1826\n",
            "Epoch 22/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.2059 - val_accuracy: 0.9539 - val_loss: 0.1822\n",
            "Epoch 23/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.2300 - val_accuracy: 0.9539 - val_loss: 0.1813\n",
            "Epoch 24/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9551 - loss: 0.1885 - val_accuracy: 0.9539 - val_loss: 0.1806\n",
            "Epoch 25/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.2315 - val_accuracy: 0.9539 - val_loss: 0.1816\n",
            "Epoch 26/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.2246 - val_accuracy: 0.9539 - val_loss: 0.1815\n",
            "Epoch 27/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9526 - loss: 0.1870 - val_accuracy: 0.9539 - val_loss: 0.1802\n",
            "Epoch 28/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9308 - loss: 0.2431 - val_accuracy: 0.9539 - val_loss: 0.1806\n",
            "Epoch 29/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.2184 - val_accuracy: 0.9539 - val_loss: 0.1794\n",
            "Epoch 30/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.2325 - val_accuracy: 0.9539 - val_loss: 0.1806\n",
            "Epoch 31/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.2010 - val_accuracy: 0.9539 - val_loss: 0.1797\n",
            "Epoch 32/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2911 - val_accuracy: 0.9539 - val_loss: 0.1809\n",
            "Epoch 33/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.2300 - val_accuracy: 0.9539 - val_loss: 0.1794\n",
            "Epoch 34/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.2223 - val_accuracy: 0.9539 - val_loss: 0.1795\n",
            "Epoch 35/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.1861 - val_accuracy: 0.9539 - val_loss: 0.1784\n",
            "Epoch 36/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.2004 - val_accuracy: 0.9539 - val_loss: 0.1792\n",
            "Epoch 37/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1912 - val_accuracy: 0.9539 - val_loss: 0.1787\n",
            "Epoch 38/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.2123 - val_accuracy: 0.9539 - val_loss: 0.1785\n",
            "Epoch 39/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.2190 - val_accuracy: 0.9539 - val_loss: 0.1779\n",
            "Epoch 40/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.2279 - val_accuracy: 0.9539 - val_loss: 0.1778\n",
            "Epoch 41/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.2343 - val_accuracy: 0.9539 - val_loss: 0.1765\n",
            "Epoch 42/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.2054 - val_accuracy: 0.9539 - val_loss: 0.1757\n",
            "Epoch 43/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9280 - loss: 0.2666 - val_accuracy: 0.9539 - val_loss: 0.1759\n",
            "Epoch 44/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.2379 - val_accuracy: 0.9539 - val_loss: 0.1751\n",
            "Epoch 45/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9454 - loss: 0.1978 - val_accuracy: 0.9539 - val_loss: 0.1749\n",
            "Epoch 46/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.2076 - val_accuracy: 0.9539 - val_loss: 0.1743\n",
            "Epoch 47/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9411 - loss: 0.2003 - val_accuracy: 0.9539 - val_loss: 0.1741\n",
            "Epoch 48/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9461 - loss: 0.1989 - val_accuracy: 0.9539 - val_loss: 0.1747\n",
            "Epoch 49/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.2289 - val_accuracy: 0.9539 - val_loss: 0.1752\n",
            "Epoch 50/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.2169 - val_accuracy: 0.9539 - val_loss: 0.1771\n",
            "Epoch 51/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9371 - loss: 0.2237 - val_accuracy: 0.9539 - val_loss: 0.1762\n",
            "Epoch 52/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.2242 - val_accuracy: 0.9539 - val_loss: 0.1759\n",
            "Epoch 53/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.2108 - val_accuracy: 0.9539 - val_loss: 0.1754\n",
            "Epoch 54/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.2052 - val_accuracy: 0.9539 - val_loss: 0.1751\n",
            "Epoch 55/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.2214 - val_accuracy: 0.9539 - val_loss: 0.1745\n",
            "Epoch 56/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1880 - val_accuracy: 0.9539 - val_loss: 0.1748\n",
            "Epoch 57/1000\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.2111 - val_accuracy: 0.9539 - val_loss: 0.1748\n",
            "Model cnn training complete for niche 7.\n",
            "  Final training loss: 0.22149913012981415\n",
            "  Final validation loss: 0.17484799027442932\n",
            "  Final training accuracy: 0.9387417435646057\n",
            "  Final validation accuracy: 0.9539473652839661\n",
            "Training model random_forest for niche 7...\n",
            "Training model mlp_financial for niche 4...\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4230 - loss: 0.8937 - val_accuracy: 0.6328 - val_loss: 0.7063\n",
            "Epoch 2/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4834 - loss: 0.8271 - val_accuracy: 0.8750 - val_loss: 0.5959\n",
            "Epoch 3/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6403 - loss: 0.6667 - val_accuracy: 0.9375 - val_loss: 0.5181\n",
            "Epoch 4/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7514 - loss: 0.5892 - val_accuracy: 0.9375 - val_loss: 0.4624\n",
            "Epoch 5/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.5349 - val_accuracy: 0.9375 - val_loss: 0.4173\n",
            "Epoch 6/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8552 - loss: 0.5013 - val_accuracy: 0.9375 - val_loss: 0.3787\n",
            "Epoch 7/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.4492 - val_accuracy: 0.9375 - val_loss: 0.3450\n",
            "Epoch 8/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8859 - loss: 0.4224 - val_accuracy: 0.9375 - val_loss: 0.3130\n",
            "Epoch 9/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8980 - loss: 0.3710 - val_accuracy: 0.9375 - val_loss: 0.2892\n",
            "Epoch 10/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.3457 - val_accuracy: 0.9375 - val_loss: 0.2729\n",
            "Epoch 11/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9281 - loss: 0.3657 - val_accuracy: 0.9375 - val_loss: 0.2622\n",
            "Epoch 12/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.3536 - val_accuracy: 0.9375 - val_loss: 0.2538\n",
            "Epoch 13/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9248 - loss: 0.3839 - val_accuracy: 0.9375 - val_loss: 0.2485\n",
            "Epoch 14/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.3285 - val_accuracy: 0.9375 - val_loss: 0.2438\n",
            "Epoch 15/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9236 - loss: 0.3218 - val_accuracy: 0.9375 - val_loss: 0.2407\n",
            "Epoch 16/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9332 - loss: 0.2904 - val_accuracy: 0.9375 - val_loss: 0.2392\n",
            "Epoch 17/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9311 - loss: 0.3429 - val_accuracy: 0.9375 - val_loss: 0.2387\n",
            "Epoch 18/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9221 - loss: 0.3515 - val_accuracy: 0.9375 - val_loss: 0.2382\n",
            "Epoch 19/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.3742 - val_accuracy: 0.9375 - val_loss: 0.2384\n",
            "Epoch 20/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.2827 - val_accuracy: 0.9375 - val_loss: 0.2383\n",
            "Epoch 21/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.2832 - val_accuracy: 0.9375 - val_loss: 0.2385\n",
            "Epoch 22/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.2270 - val_accuracy: 0.9375 - val_loss: 0.2387\n",
            "Epoch 23/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.3331 - val_accuracy: 0.9375 - val_loss: 0.2397\n",
            "Epoch 24/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.3114 - val_accuracy: 0.9375 - val_loss: 0.2400\n",
            "Epoch 25/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.2605 - val_accuracy: 0.9375 - val_loss: 0.2402\n",
            "Epoch 26/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.2831 - val_accuracy: 0.9375 - val_loss: 0.2406\n",
            "Epoch 27/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.2543 - val_accuracy: 0.9375 - val_loss: 0.2410\n",
            "Epoch 28/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.2855 - val_accuracy: 0.9375 - val_loss: 0.2417\n",
            "Model mlp_financial training complete for niche 4.\n",
            "  Final training loss: 0.2606606185436249\n",
            "  Final validation loss: 0.24171607196331024\n",
            "  Final training accuracy: 0.9409449100494385\n",
            "  Final validation accuracy: 0.9375\n",
            "Training model mlp_market for niche 4...\n",
            "Epoch 1/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6363 - loss: 0.6835 - val_accuracy: 0.8672 - val_loss: 0.5516\n",
            "Epoch 2/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7702 - loss: 0.5588 - val_accuracy: 0.9375 - val_loss: 0.4678\n",
            "Epoch 3/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.5162 - val_accuracy: 0.9375 - val_loss: 0.4051\n",
            "Epoch 4/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8752 - loss: 0.4480 - val_accuracy: 0.9375 - val_loss: 0.3572\n",
            "Epoch 5/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8776 - loss: 0.4313 - val_accuracy: 0.9375 - val_loss: 0.3209\n",
            "Epoch 6/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9186 - loss: 0.3606 - val_accuracy: 0.9375 - val_loss: 0.2944\n",
            "Epoch 7/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9314 - loss: 0.3326 - val_accuracy: 0.9375 - val_loss: 0.2754\n",
            "Epoch 8/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.3610 - val_accuracy: 0.9375 - val_loss: 0.2640\n",
            "Epoch 9/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9402 - loss: 0.3111 - val_accuracy: 0.9375 - val_loss: 0.2555\n",
            "Epoch 10/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 0.3085 - val_accuracy: 0.9375 - val_loss: 0.2514\n",
            "Epoch 11/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9436 - loss: 0.2604 - val_accuracy: 0.9375 - val_loss: 0.2482\n",
            "Epoch 12/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9507 - loss: 0.2616 - val_accuracy: 0.9375 - val_loss: 0.2466\n",
            "Epoch 13/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.2759 - val_accuracy: 0.9375 - val_loss: 0.2460\n",
            "Epoch 14/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.2560 - val_accuracy: 0.9375 - val_loss: 0.2457\n",
            "Epoch 15/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9331 - loss: 0.2789 - val_accuracy: 0.9375 - val_loss: 0.2462\n",
            "Epoch 16/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.2755 - val_accuracy: 0.9375 - val_loss: 0.2470\n",
            "Epoch 17/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.2897 - val_accuracy: 0.9375 - val_loss: 0.2472\n",
            "Epoch 18/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.2687 - val_accuracy: 0.9375 - val_loss: 0.2478\n",
            "Epoch 19/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9564 - loss: 0.2219 - val_accuracy: 0.9375 - val_loss: 0.2487\n",
            "Epoch 20/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.2428 - val_accuracy: 0.9375 - val_loss: 0.2494\n",
            "Epoch 21/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.2671 - val_accuracy: 0.9375 - val_loss: 0.2508\n",
            "Epoch 22/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9187 - loss: 0.3011 - val_accuracy: 0.9375 - val_loss: 0.2523\n",
            "Epoch 23/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.2979 - val_accuracy: 0.9375 - val_loss: 0.2526\n",
            "Epoch 24/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.2296 - val_accuracy: 0.9375 - val_loss: 0.2537\n",
            "Model mlp_market training complete for niche 4.\n",
            "  Final training loss: 0.23666000366210938\n",
            "  Final validation loss: 0.2537004351615906\n",
            "  Final training accuracy: 0.9389764070510864\n",
            "  Final validation accuracy: 0.9375\n",
            "Training model lstm for niche 4...\n",
            "Epoch 1/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5304 - loss: 0.6935 - val_accuracy: 0.7656 - val_loss: 0.6424\n",
            "Epoch 2/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7870 - loss: 0.6221 - val_accuracy: 0.8984 - val_loss: 0.5719\n",
            "Epoch 3/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9342 - loss: 0.5403 - val_accuracy: 0.9375 - val_loss: 0.4732\n",
            "Epoch 4/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9242 - loss: 0.4473 - val_accuracy: 0.9375 - val_loss: 0.3222\n",
            "Epoch 5/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9268 - loss: 0.3213 - val_accuracy: 0.9375 - val_loss: 0.2576\n",
            "Epoch 6/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9513 - loss: 0.2152 - val_accuracy: 0.9375 - val_loss: 0.2507\n",
            "Epoch 7/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9253 - loss: 0.2644 - val_accuracy: 0.9375 - val_loss: 0.2333\n",
            "Epoch 8/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9520 - loss: 0.2186 - val_accuracy: 0.9375 - val_loss: 0.2348\n",
            "Epoch 9/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1983 - val_accuracy: 0.9375 - val_loss: 0.2313\n",
            "Epoch 10/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9574 - loss: 0.2024 - val_accuracy: 0.9375 - val_loss: 0.2251\n",
            "Epoch 11/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 0.2312 - val_accuracy: 0.9375 - val_loss: 0.2255\n",
            "Epoch 12/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.2133 - val_accuracy: 0.9375 - val_loss: 0.2219\n",
            "Epoch 13/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9311 - loss: 0.2638 - val_accuracy: 0.9375 - val_loss: 0.2175\n",
            "Epoch 14/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9335 - loss: 0.2582 - val_accuracy: 0.9375 - val_loss: 0.2159\n",
            "Epoch 15/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.2223 - val_accuracy: 0.9375 - val_loss: 0.2191\n",
            "Epoch 16/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9435 - loss: 0.2156 - val_accuracy: 0.9375 - val_loss: 0.2167\n",
            "Epoch 17/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9564 - loss: 0.2016 - val_accuracy: 0.9375 - val_loss: 0.2207\n",
            "Epoch 18/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9493 - loss: 0.1921 - val_accuracy: 0.9375 - val_loss: 0.2181\n",
            "Epoch 19/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9378 - loss: 0.2436 - val_accuracy: 0.9375 - val_loss: 0.2180\n",
            "Epoch 20/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9294 - loss: 0.2679 - val_accuracy: 0.9375 - val_loss: 0.2187\n",
            "Epoch 21/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.1903 - val_accuracy: 0.9375 - val_loss: 0.2222\n",
            "Epoch 22/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.2283 - val_accuracy: 0.9375 - val_loss: 0.2206\n",
            "Epoch 23/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.2340 - val_accuracy: 0.9375 - val_loss: 0.2209\n",
            "Epoch 24/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.2109 - val_accuracy: 0.9375 - val_loss: 0.2211\n",
            "Model lstm training complete for niche 4.\n",
            "  Final training loss: 0.22355173528194427\n",
            "  Final validation loss: 0.22105081379413605\n",
            "  Final training accuracy: 0.9409449100494385\n",
            "  Final validation accuracy: 0.9375\n",
            "Training model cnn for niche 4...\n",
            "Epoch 1/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4117 - loss: 0.7983 - val_accuracy: 0.6562 - val_loss: 0.6559\n",
            "Epoch 2/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6858 - loss: 0.6463 - val_accuracy: 0.9141 - val_loss: 0.5238\n",
            "Epoch 3/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8527 - loss: 0.5198 - val_accuracy: 0.9375 - val_loss: 0.4263\n",
            "Epoch 4/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.3945 - val_accuracy: 0.9375 - val_loss: 0.3569\n",
            "Epoch 5/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9339 - loss: 0.3434 - val_accuracy: 0.9375 - val_loss: 0.3104\n",
            "Epoch 6/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.3110 - val_accuracy: 0.9375 - val_loss: 0.2791\n",
            "Epoch 7/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.3029 - val_accuracy: 0.9375 - val_loss: 0.2609\n",
            "Epoch 8/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9321 - loss: 0.2790 - val_accuracy: 0.9375 - val_loss: 0.2498\n",
            "Epoch 9/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9413 - loss: 0.2496 - val_accuracy: 0.9375 - val_loss: 0.2428\n",
            "Epoch 10/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9376 - loss: 0.2624 - val_accuracy: 0.9375 - val_loss: 0.2388\n",
            "Epoch 11/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9407 - loss: 0.2397 - val_accuracy: 0.9375 - val_loss: 0.2359\n",
            "Epoch 12/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9306 - loss: 0.2709 - val_accuracy: 0.9375 - val_loss: 0.2341\n",
            "Epoch 13/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.2098 - val_accuracy: 0.9375 - val_loss: 0.2325\n",
            "Epoch 14/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9314 - loss: 0.2454 - val_accuracy: 0.9375 - val_loss: 0.2317\n",
            "Epoch 15/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9302 - loss: 0.2642 - val_accuracy: 0.9375 - val_loss: 0.2309\n",
            "Epoch 16/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1949 - val_accuracy: 0.9375 - val_loss: 0.2302\n",
            "Epoch 17/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9399 - loss: 0.2312 - val_accuracy: 0.9375 - val_loss: 0.2295\n",
            "Epoch 18/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.2049 - val_accuracy: 0.9375 - val_loss: 0.2290\n",
            "Epoch 19/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.2095 - val_accuracy: 0.9375 - val_loss: 0.2286\n",
            "Epoch 20/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.2159 - val_accuracy: 0.9375 - val_loss: 0.2281\n",
            "Epoch 21/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2691 - val_accuracy: 0.9375 - val_loss: 0.2276\n",
            "Epoch 22/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9544 - loss: 0.1769 - val_accuracy: 0.9375 - val_loss: 0.2277\n",
            "Epoch 23/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9330 - loss: 0.2443 - val_accuracy: 0.9375 - val_loss: 0.2276\n",
            "Epoch 24/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9488 - loss: 0.1949 - val_accuracy: 0.9375 - val_loss: 0.2272\n",
            "Epoch 25/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.1853 - val_accuracy: 0.9375 - val_loss: 0.2270\n",
            "Epoch 26/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.2121 - val_accuracy: 0.9375 - val_loss: 0.2269\n",
            "Epoch 27/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9301 - loss: 0.2323 - val_accuracy: 0.9375 - val_loss: 0.2269\n",
            "Epoch 28/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.2261 - val_accuracy: 0.9375 - val_loss: 0.2268\n",
            "Epoch 29/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9403 - loss: 0.2144 - val_accuracy: 0.9375 - val_loss: 0.2268\n",
            "Epoch 30/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.2291 - val_accuracy: 0.9375 - val_loss: 0.2268\n",
            "Epoch 31/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9540 - loss: 0.1809 - val_accuracy: 0.9375 - val_loss: 0.2266\n",
            "Epoch 32/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.2190 - val_accuracy: 0.9375 - val_loss: 0.2267\n",
            "Epoch 33/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1813 - val_accuracy: 0.9375 - val_loss: 0.2267\n",
            "Epoch 34/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9426 - loss: 0.2110 - val_accuracy: 0.9375 - val_loss: 0.2268\n",
            "Epoch 35/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.2260 - val_accuracy: 0.9375 - val_loss: 0.2269\n",
            "Epoch 36/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.2371 - val_accuracy: 0.9375 - val_loss: 0.2267\n",
            "Epoch 37/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9338 - loss: 0.2124 - val_accuracy: 0.9375 - val_loss: 0.2264\n",
            "Epoch 38/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.2374 - val_accuracy: 0.9375 - val_loss: 0.2265\n",
            "Epoch 39/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9387 - loss: 0.1983 - val_accuracy: 0.9375 - val_loss: 0.2268\n",
            "Epoch 40/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.1958 - val_accuracy: 0.9375 - val_loss: 0.2270\n",
            "Epoch 41/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.1784 - val_accuracy: 0.9375 - val_loss: 0.2273\n",
            "Epoch 42/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.1919 - val_accuracy: 0.9375 - val_loss: 0.2272\n",
            "Epoch 43/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1858 - val_accuracy: 0.9375 - val_loss: 0.2277\n",
            "Epoch 44/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.2210 - val_accuracy: 0.9375 - val_loss: 0.2275\n",
            "Epoch 45/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9319 - loss: 0.2164 - val_accuracy: 0.9375 - val_loss: 0.2274\n",
            "Epoch 46/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.2239 - val_accuracy: 0.9375 - val_loss: 0.2275\n",
            "Epoch 47/1000\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.1975 - val_accuracy: 0.9375 - val_loss: 0.2278\n",
            "Model cnn training complete for niche 4.\n",
            "  Final training loss: 0.19519203901290894\n",
            "  Final validation loss: 0.22783218324184418\n",
            "  Final training accuracy: 0.9409449100494385\n",
            "  Final validation accuracy: 0.9375\n",
            "Training model random_forest for niche 4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance for niche 5:\n",
            "  mlp_financial: Loss = 0.3920454978942871, Accuracy = 0.8336673378944397\n",
            "  mlp_market: Loss = 0.39028647541999817, Accuracy = 0.8336673378944397\n",
            "  lstm: Loss = 0.38179877400398254, Accuracy = 0.8336673378944397\n",
            "  cnn: Loss = 0.3797968626022339, Accuracy = 0.8336673378944397\n",
            "  random_forest: Loss = 0.9972323522438671, Accuracy = 0.811623246492986\n",
            "Performance for niche 9:\n",
            "  mlp_financial: Loss = 0.2208152413368225, Accuracy = 0.936898410320282\n",
            "  mlp_market: Loss = 0.22084541618824005, Accuracy = 0.936898410320282\n",
            "  lstm: Loss = 0.21994584798812866, Accuracy = 0.936898410320282\n",
            "  cnn: Loss = 0.2186799943447113, Accuracy = 0.936898410320282\n",
            "  random_forest: Loss = 0.5052295267083335, Accuracy = 0.9251336898395722\n",
            "Performance for niche 3:\n",
            "  mlp_financial: Loss = 0.19348062574863434, Accuracy = 0.9527027010917664\n",
            "  mlp_market: Loss = 0.19330738484859467, Accuracy = 0.9527027010917664\n",
            "  lstm: Loss = 0.1951143741607666, Accuracy = 0.9527027010917664\n",
            "  cnn: Loss = 0.18855132162570953, Accuracy = 0.9527027010917664\n",
            "  random_forest: Loss = 0.7280199051687616, Accuracy = 0.9527027027027027\n",
            "Performance for niche 1:\n",
            "  mlp_financial: Loss = 0.1406833529472351, Accuracy = 0.977886974811554\n",
            "  mlp_market: Loss = 0.13267584145069122, Accuracy = 0.977886974811554\n",
            "  lstm: Loss = 0.11044933646917343, Accuracy = 0.977886974811554\n",
            "  cnn: Loss = 0.10885659605264664, Accuracy = 0.977886974811554\n",
            "  random_forest: Loss = 0.5944440667749943, Accuracy = 0.9680589680589681\n",
            "Performance for niche 8:\n",
            "  mlp_financial: Loss = 0.33578044176101685, Accuracy = 0.9021164178848267\n",
            "  mlp_market: Loss = 0.3167242407798767, Accuracy = 0.9021164178848267\n",
            "  lstm: Loss = 0.31079354882240295, Accuracy = 0.9021164178848267\n",
            "  cnn: Loss = 0.3006710708141327, Accuracy = 0.9021164178848267\n",
            "  random_forest: Loss = 0.44845698302350484, Accuracy = 0.9021164021164021\n",
            "Performance for niche 6:\n",
            "  mlp_financial: Loss = 0.27095136046409607, Accuracy = 0.9146141409873962\n",
            "  mlp_market: Loss = 0.28710582852363586, Accuracy = 0.9146141409873962\n",
            "  lstm: Loss = 0.26832884550094604, Accuracy = 0.9146141409873962\n",
            "  cnn: Loss = 0.2648767828941345, Accuracy = 0.9146141409873962\n",
            "  random_forest: Loss = 0.7490301042782366, Accuracy = 0.9080459770114943\n",
            "Performance for niche 2:\n",
            "  mlp_financial: Loss = 0.19902774691581726, Accuracy = 0.9537953734397888\n",
            "  mlp_market: Loss = 0.2008408159017563, Accuracy = 0.9537953734397888\n",
            "  lstm: Loss = 0.18402113020420074, Accuracy = 0.9537953734397888\n",
            "  cnn: Loss = 0.18977005779743195, Accuracy = 0.9537953734397888\n",
            "  random_forest: Loss = 0.48055483128730664, Accuracy = 0.9372937293729373\n",
            "Performance for niche 0:\n",
            "  mlp_financial: Loss = 0.2578231692314148, Accuracy = 0.9237288236618042\n",
            "  mlp_market: Loss = 0.2522384822368622, Accuracy = 0.9237288236618042\n",
            "  lstm: Loss = 0.2502298653125763, Accuracy = 0.9237288236618042\n",
            "  cnn: Loss = 0.24962827563285828, Accuracy = 0.9237288236618042\n",
            "  random_forest: Loss = 0.7150441689029653, Accuracy = 0.911864406779661\n",
            "Performance for niche 7:\n",
            "  mlp_financial: Loss = 0.23495563864707947, Accuracy = 0.944615364074707\n",
            "  mlp_market: Loss = 0.22865551710128784, Accuracy = 0.944615364074707\n",
            "  lstm: Loss = 0.21254335343837738, Accuracy = 0.944615364074707\n",
            "  cnn: Loss = 0.20909930765628815, Accuracy = 0.944615364074707\n",
            "  random_forest: Loss = 0.8046323323421821, Accuracy = 0.9415384615384615\n",
            "Performance for niche 4:\n",
            "  mlp_financial: Loss = 0.33521339297294617, Accuracy = 0.9084249138832092\n",
            "  mlp_market: Loss = 0.35584792494773865, Accuracy = 0.9084249138832092\n",
            "  lstm: Loss = 0.3999708294868469, Accuracy = 0.9084249138832092\n",
            "  cnn: Loss = 0.30649298429489136, Accuracy = 0.9084249138832092\n",
            "  random_forest: Loss = 0.9934155787348361, Accuracy = 0.9084249084249084\n",
            "Best performing model for niche 5: cnn with performance: [0.3797968626022339, 0.8336673378944397]\n",
            "Best performing model for niche 9: cnn with performance: [0.2186799943447113, 0.936898410320282]\n",
            "Best performing model for niche 3: cnn with performance: [0.18855132162570953, 0.9527027010917664]\n",
            "Best performing model for niche 1: cnn with performance: [0.10885659605264664, 0.977886974811554]\n",
            "Best performing model for niche 8: cnn with performance: [0.3006710708141327, 0.9021164178848267]\n",
            "Best performing model for niche 6: cnn with performance: [0.2648767828941345, 0.9146141409873962]\n",
            "Best performing model for niche 2: lstm with performance: [0.18402113020420074, 0.9537953734397888]\n",
            "Best performing model for niche 0: cnn with performance: [0.24962827563285828, 0.9237288236618042]\n",
            "Best performing model for niche 7: cnn with performance: [0.20909930765628815, 0.944615364074707]\n",
            "Best performing model for niche 4: cnn with performance: [0.30649298429489136, 0.9084249138832092]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('./dataset_transformed.csv')\n",
        "epoch = 1000\n",
        "l2_penalty = 0.001\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "df.dropna(subset=['status', 'funding_total_usd', 'country_code'], inplace=True)\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoders = {}\n",
        "for column in ['category_list', 'country_code', 'state_code', 'region', 'city', 'first_funding_at', 'last_funding_at', 'founded_at']:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column].astype(str))\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Convert 'status' to binary classification (1 for operating, 0 for closed)\n",
        "df['status'] = df['status'].apply(lambda x: 0 if x == 'closed' else 1)\n",
        "\n",
        "# Handle 'funding_total_usd' column (convert '-' to 0 and convert to float)\n",
        "df['funding_total_usd'] = df['funding_total_usd'].replace('-', 0).astype(float)\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=['status'])\n",
        "y = df['status']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "print(\"The transformed input-values are:\\n\\n\", X)\n",
        "\n",
        "def build_model(input_dim, focus='general', model_type='mlp'):\n",
        "    model = Sequential()\n",
        "\n",
        "    if model_type == 'mlp':\n",
        "        if focus == 'financial':\n",
        "            model.add(Dense(30, activation='relu', input_dim=input_dim, kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "            model.add(Dense(15, activation='relu', kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "        elif focus == 'market':\n",
        "            model.add(Dense(20, activation='relu', input_dim=input_dim, kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "            model.add(Dense(15, activation='relu', kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "        elif focus == 'team':\n",
        "            model.add(Dense(14, activation='relu', input_dim=input_dim, kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "            model.add(Dense(9, activation='relu', kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "        elif focus == 'innovation':\n",
        "            model.add(Dense(18, activation='relu', input_dim=input_dim, kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "            model.add(Dense(11, activation='relu', kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "        else:\n",
        "            model.add(Dense(17, activation='relu', input_dim=input_dim, kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "            model.add(Dense(10, activation='relu', kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "            model.add(Dropout(0.5))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    elif model_type == 'lstm':\n",
        "        model.add(tf.keras.layers.Reshape((input_dim, 1), input_shape=(input_dim,)))\n",
        "        model.add(LSTM(15, activation='relu', input_shape=(input_dim, 1)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    elif model_type == 'cnn':\n",
        "        model.add(tf.keras.layers.Reshape((input_dim, 1), input_shape=(input_dim,)))\n",
        "        model.add(Conv1D(13, 2, activation='relu', input_shape=(input_dim, 1), kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_random_forest():\n",
        "    return RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "\n",
        "# Define different market niches (e.g., by category_list)\n",
        "market_niches = df['category_list'].unique()\n",
        "\n",
        "# Prepare a dictionary to store models for each market niche\n",
        "niche_models = {}\n",
        "for niche in market_niches:\n",
        "    niche_indices = df['category_list'] == niche\n",
        "    X_niche = X[niche_indices]\n",
        "    y_niche = y[niche_indices]\n",
        "\n",
        "    # Check if there are enough samples to split\n",
        "    if len(X_niche) < 10:\n",
        "        print(f\"Skipping niche {niche} due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    # Split the data for training and testing\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_niche, y_niche, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Initialize models for each focus and type\n",
        "    niche_models[niche] = {\n",
        "        'mlp_financial': build_model(X_train.shape[1], focus='financial', model_type='mlp'),\n",
        "        'mlp_market': build_model(X_train.shape[1], focus='market', model_type='mlp'),\n",
        "        'lstm': build_model(X_train.shape[1], model_type='lstm'),\n",
        "        'cnn': build_model(X_train.shape[1], model_type='cnn'),\n",
        "        'random_forest': build_random_forest()\n",
        "    }\n",
        "\n",
        "    # Train each model\n",
        "    for model_name, model in niche_models[niche].items():\n",
        "        print(f\"Training model {model_name} for niche {niche}...\")\n",
        "        if model_name == 'random_forest':\n",
        "            model.fit(X_train, y_train)\n",
        "        else:\n",
        "            checkpoint_path = f\"model_checkpoints/{niche}_{model_name}_checkpoint.weights.h5\"\n",
        "            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "            checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "            history = model.fit(X_train, y_train, epochs=epoch, batch_size=30, validation_split=0.2, verbose=1, callbacks=[checkpoint, early_stopping])\n",
        "            print(f\"Model {model_name} training complete for niche {niche}.\")\n",
        "            print(f\"  Final training loss: {history.history['loss'][-1]}\")\n",
        "            print(f\"  Final validation loss: {history.history['val_loss'][-1]}\")\n",
        "            print(f\"  Final training accuracy: {history.history['accuracy'][-1]}\")\n",
        "            print(f\"  Final validation accuracy: {history.history['val_accuracy'][-1]}\")\n",
        "\n",
        "# Evaluate models on the test set for each niche\n",
        "niche_performance = {}\n",
        "\n",
        "for niche, models in niche_models.items():\n",
        "    niche_indices = df['category_list'] == niche\n",
        "    X_niche = X[niche_indices]\n",
        "    y_niche = y[niche_indices]\n",
        "\n",
        "    if len(X_niche) < 10:\n",
        "        continue\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_niche, y_niche, test_size=0.3, random_state=42)\n",
        "\n",
        "    niche_performance[niche] = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        if model_name == 'random_forest':\n",
        "            y_pred = model.predict_proba(X_test)[:, 1]\n",
        "            eval_result = [log_loss(y_test, y_pred), accuracy_score(y_test, model.predict(X_test))]\n",
        "        else:\n",
        "            eval_result = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "        niche_performance[niche][model_name] = eval_result\n",
        "\n",
        "# Print performance for each niche\n",
        "for niche, performance in niche_performance.items():\n",
        "    print(f\"Performance for niche {niche}:\")\n",
        "    for model_name, result in performance.items():\n",
        "        print(f\"  {model_name}: Loss = {result[0]}, Accuracy = {result[1]}\")\n",
        "\n",
        "# Compare specialized models with the baseline for each niche\n",
        "best_models = {}\n",
        "\n",
        "for niche, performance in niche_performance.items():\n",
        "    best_model_name = min(performance, key=lambda k: performance[k][0])  # assuming lower loss is better\n",
        "    best_models[niche] = best_model_name\n",
        "\n",
        "    print(f\"Best performing model for niche {niche}: {best_model_name} with performance: {performance[best_model_name]}\")\n",
        "\n",
        "# Save the best models\n",
        "for niche, best_model_name in best_models.items():\n",
        "    best_model = niche_models[niche][best_model_name]\n",
        "    if best_model_name == 'random_forest':\n",
        "        joblib.dump(best_model, f'best_model_{niche}.pkl')\n",
        "    else:\n",
        "        best_model.save(f'best_model_{niche}.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uke-C3qGKxXj",
        "outputId": "0e9151fb-7add-4850-9dfb-08ea13b44b08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\affan\\Needfit Agency\\LeapstartAi\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5642 - val_accuracy: 0.9189 - val_loss: 0.2941\n",
            "Epoch 2/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.3242 - val_accuracy: 0.9189 - val_loss: 0.2862\n",
            "Epoch 3/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.3092 - val_accuracy: 0.9189 - val_loss: 0.2795\n",
            "Epoch 4/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.2865 - val_accuracy: 0.9189 - val_loss: 0.2748\n",
            "Epoch 5/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2862 - val_accuracy: 0.9189 - val_loss: 0.2709\n",
            "Epoch 6/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2684 - val_accuracy: 0.9189 - val_loss: 0.2687\n",
            "Epoch 7/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2642 - val_accuracy: 0.9189 - val_loss: 0.2666\n",
            "Epoch 8/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2804 - val_accuracy: 0.9189 - val_loss: 0.2668\n",
            "Epoch 9/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2572 - val_accuracy: 0.9189 - val_loss: 0.2645\n",
            "Epoch 10/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2739 - val_accuracy: 0.9189 - val_loss: 0.2644\n",
            "Epoch 11/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2694 - val_accuracy: 0.9189 - val_loss: 0.2630\n",
            "Epoch 12/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2700 - val_accuracy: 0.9189 - val_loss: 0.2633\n",
            "Epoch 13/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2661 - val_accuracy: 0.9189 - val_loss: 0.2620\n",
            "Epoch 14/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.2435 - val_accuracy: 0.9189 - val_loss: 0.2614\n",
            "Epoch 15/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.2487 - val_accuracy: 0.9189 - val_loss: 0.2606\n",
            "Epoch 16/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2408 - val_accuracy: 0.9189 - val_loss: 0.2594\n",
            "Epoch 17/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2469 - val_accuracy: 0.9189 - val_loss: 0.2588\n",
            "Epoch 18/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9240 - loss: 0.2543 - val_accuracy: 0.9189 - val_loss: 0.2594\n",
            "Epoch 19/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2439 - val_accuracy: 0.9189 - val_loss: 0.2588\n",
            "Epoch 20/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.2440 - val_accuracy: 0.9189 - val_loss: 0.2580\n",
            "Epoch 21/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9285 - loss: 0.2434 - val_accuracy: 0.9189 - val_loss: 0.2584\n",
            "Epoch 22/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2481 - val_accuracy: 0.9189 - val_loss: 0.2594\n",
            "Epoch 23/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2590 - val_accuracy: 0.9189 - val_loss: 0.2588\n",
            "Epoch 24/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2414 - val_accuracy: 0.9189 - val_loss: 0.2574\n",
            "Epoch 25/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2446 - val_accuracy: 0.9189 - val_loss: 0.2576\n",
            "Epoch 26/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2373 - val_accuracy: 0.9189 - val_loss: 0.2574\n",
            "Epoch 27/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2454 - val_accuracy: 0.9189 - val_loss: 0.2566\n",
            "Epoch 28/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2450 - val_accuracy: 0.9189 - val_loss: 0.2565\n",
            "Epoch 29/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2466 - val_accuracy: 0.9189 - val_loss: 0.2574\n",
            "Epoch 30/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2492 - val_accuracy: 0.9189 - val_loss: 0.2569\n",
            "Epoch 31/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.2582 - val_accuracy: 0.9189 - val_loss: 0.2578\n",
            "Epoch 32/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2468 - val_accuracy: 0.9189 - val_loss: 0.2569\n",
            "Epoch 33/1000\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.2387 - val_accuracy: 0.9189 - val_loss: 0.2565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.23782697319984436\n",
            "Test Accuracy: 0.9277201294898987\n",
            "MLP model training complete and saved.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('./dataset_transformed.csv')\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "df.dropna(subset=['status', 'funding_total_usd', 'country_code'], inplace=True)\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoders = {}\n",
        "for column in ['category_list', 'country_code', 'state_code', 'region', 'city', 'first_funding_at', 'last_funding_at', 'founded_at']:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column].astype(str))\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Convert 'status' to binary classification (1 for operating, 0 for closed)\n",
        "df['status'] = df['status'].apply(lambda x: 0 if x == 'closed' else 1)\n",
        "\n",
        "# Handle 'funding_total_usd' column (convert '-' to 0 and convert to float)\n",
        "df['funding_total_usd'] = df['funding_total_usd'].replace('-', 0).astype(float)\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=['status'])\n",
        "y = df['status']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
        "\n",
        "# Define the MLP model\n",
        "def build_mlp_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(20, activation='relu', input_dim=input_dim , kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(25, activation='relu' , kernel_regularizer=regularizers.l2(l2_penalty)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Split the data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build and train the MLP model\n",
        "mlp_model = build_mlp_model(X_train.shape[1])\n",
        "\n",
        "# Define callbacks for early stopping and model checkpointing\n",
        "checkpoint_path = \"./mlp_model_checkpoint.weights.h5\"\n",
        "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = mlp_model.fit(X_train, y_train, epochs=epoch, batch_size=32, validation_split=0.2, verbose=1, callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = mlp_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Save the final model\n",
        "mlp_model.save('mlp_model.h5')\n",
        "\n",
        "print(\"MLP model training complete and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f6YrsaSNLdBY"
      },
      "outputs": [],
      "source": [
        "df_software = df[df['category_list'] == label_encoders['category_list'].transform(['Apps'])[0]]\n",
        "\n",
        "# Split the \"Software\" category data into training and test sets\n",
        "df_train_software, df_test_software = train_test_split(df_software, test_size=0.3, random_state=56)\n",
        "\n",
        "# Save the test dataset to a CSV file\n",
        "test_software_file_path = './test_software_dataset.csv'\n",
        "df_test_software.to_csv(test_software_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS33hemKLP9q",
        "outputId": "ec2070a3-8170-4796-aa2c-93746f5b0e4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating :\n",
            "General - Test Loss: 0.11649259924888611, Test Accuracy: 0.8835074007511139\n",
            "Specialized - Test Loss: 0.02478424645960331, Test Accuracy: 0.9752157535403967\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating :\")\n",
        "# Load the models\n",
        "model_1 = tf.keras.models.load_model('./mlp_model.h5')\n",
        "model_2 = tf.keras.models.load_model('./best_model_1.h5')\n",
        "\n",
        "# Load label encoders and scaler\n",
        "label_encoders = joblib.load('./label_encoders.pkl')\n",
        "scaler = joblib.load('./scaler.pkl')\n",
        "\n",
        "# Load test dataset\n",
        "df_test = pd.read_csv('./test_software_dataset.csv')\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "df_test.dropna(subset=['status', 'funding_total_usd', 'country_code'], inplace=True)\n",
        "\n",
        "# Encode categorical columns using the existing label encoders\n",
        "for column in ['category_list', 'country_code', 'state_code', 'region', 'city', 'first_funding_at', 'last_funding_at', 'founded_at']:\n",
        "    le = label_encoders[column]\n",
        "    df_test[column] = df_test[column].astype(str)\n",
        "    df_test[column] = df_test[column].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
        "\n",
        "# Convert 'status' to binary classification (1 for operating, 0 for closed)\n",
        "df_test['status'] = df_test['status'].apply(lambda x: 0 if x == 'closed' else 1)\n",
        "\n",
        "# Handle 'funding_total_usd' column (convert '-' to 0 and convert to float)\n",
        "df_test['funding_total_usd'] = df_test['funding_total_usd'].replace('-', 0).astype(float)\n",
        "\n",
        "# Features and target\n",
        "X_test = df_test.drop(columns=['status'])\n",
        "y_test = df_test['status']\n",
        "\n",
        "# Standardize the features\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Evaluate model_1\n",
        "loss_1, accuracy_1 = model_1.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"General - Test Loss: {loss_1}, Test Accuracy: { 1 - loss_1}\")\n",
        "\n",
        "# Evaluate model_2\n",
        "loss_2, accuracy_2 = model_2.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Specialized - Test Loss: {loss_2}, Test Accuracy: {1 - loss_2}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
